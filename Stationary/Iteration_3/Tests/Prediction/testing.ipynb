{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13950fdc",
   "metadata": {},
   "source": [
    "# Imports and Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca6cac49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Null values:  localityName           0\n",
      "price                  0\n",
      "carpetArea          3764\n",
      "floorNumber            0\n",
      "totalFloorNumber       0\n",
      "transactionType        0\n",
      "furnished             37\n",
      "bedrooms               0\n",
      "bathrooms              0\n",
      "ageofcons           2571\n",
      "dtype: int64 \n",
      "\n",
      "Test Set Null values:  localityName          0\n",
      "price                 0\n",
      "carpetArea          977\n",
      "floorNumber           0\n",
      "totalFloorNumber      0\n",
      "transactionType       0\n",
      "furnished            14\n",
      "bedrooms              0\n",
      "bathrooms             0\n",
      "ageofcons           693\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "# from ydata_profiling import ProfileReport\n",
    "import numpy as np\n",
    "\n",
    "dtype_mapping = {\n",
    "    'propertyId': pd.StringDtype(),\n",
    "    'localityName': 'category',\n",
    "    'landMarks': pd.StringDtype(),\n",
    "    'locality': pd.StringDtype(),\n",
    "    'price': pd.Int64Dtype(),\n",
    "    'nameOfSociety': pd.StringDtype(),\n",
    "    'projectName': pd.StringDtype(),\n",
    "    'carpetArea': pd.Int64Dtype(),\n",
    "    'coveredArea': pd.Int64Dtype(),\n",
    "    'carpetAreaSqft': pd.Int64Dtype(),\n",
    "    'possessionStatus': pd.StringDtype(),\n",
    "    'developerName': pd.StringDtype(),\n",
    "    'flooringType': pd.StringDtype(),\n",
    "    'floorNumber': pd.Int64Dtype(),\n",
    "    'unitCountonFloor': pd.Int64Dtype(),\n",
    "    'totalFloorNumber': pd.Int64Dtype(),\n",
    "    'electricityStatus': pd.StringDtype(),\n",
    "    'waterStatus': pd.StringDtype(),\n",
    "    'longitude': pd.Float64Dtype(),\n",
    "    'latitude': pd.Float64Dtype(),\n",
    "    'transactionType': 'category',\n",
    "    'facing': pd.StringDtype(),\n",
    "    'ownershipType': pd.StringDtype(),\n",
    "    'carParking': pd.StringDtype(),\n",
    "    'furnished': 'category',\n",
    "    'bedrooms': pd.Int64Dtype(),\n",
    "    'bathrooms': pd.Int64Dtype(),\n",
    "    'numberOfBalconied': pd.Int64Dtype(),\n",
    "    'propertyType': 'category',\n",
    "    'additionalRooms': pd.StringDtype(),\n",
    "    'bookingAmountExact': pd.Int64Dtype(),\n",
    "    'maintenanceChargesFrequency': 'category',\n",
    "    'maintenanceCharges': pd.Int64Dtype(),\n",
    "    'ageofcons': 'category',\n",
    "    'isVerified': 'category',\n",
    "    'listingTypeDesc': 'category',\n",
    "    'premiumProperty': pd.BooleanDtype(),\n",
    "    'noOfLifts': pd.Int64Dtype(),\n",
    "    'propertyAmenities': pd.StringDtype(),\n",
    "    'facilitiesDesc': pd.StringDtype(),\n",
    "    'uuid': pd.StringDtype(),\n",
    "    'flooringType_Vitrified': pd.BooleanDtype(),\n",
    "    'flooringType_CeramicTiles': pd.BooleanDtype(),\n",
    "    'flooringType_Marble': pd.BooleanDtype(),\n",
    "    'flooringType_NormalTilesKotahStone': pd.BooleanDtype(),\n",
    "    'flooringType_Granite': pd.BooleanDtype(),\n",
    "    'flooringType_Wooden': pd.BooleanDtype(),\n",
    "    'flooringType_Mosaic': pd.BooleanDtype(),\n",
    "    'flooringType_Marbonite': pd.BooleanDtype(),\n",
    "    'additionalRoom_PujaRoom': pd.BooleanDtype(),\n",
    "    'additionalRoom_Study': pd.BooleanDtype(),\n",
    "    'additionalRoom_Store': pd.BooleanDtype(),\n",
    "    'additionalRoom_ServantRoom': pd.BooleanDtype(),\n",
    "    'carParking_Open': pd.Int64Dtype(),\n",
    "    'carParking_Covered': pd.Int64Dtype(),\n",
    "    'ReservedParking': pd.BooleanDtype(),\n",
    "}\n",
    "\n",
    "COLUMNS_TO_DROP = [\n",
    "    'coveredArea',\n",
    "    'ReservedParking',\n",
    "] + [\n",
    "        'unitCountonFloor',\n",
    "        'electricityStatus',\n",
    "        'waterStatus',\n",
    "        'facing',\n",
    "        'bookingAmountExact',\n",
    "        'isVerified',\n",
    "        'listingTypeDesc',\n",
    "        'maintenanceCharges',\n",
    "        'maintenanceChargesFrequency',\n",
    "        'latitude',\n",
    "        'longitude',\n",
    "        'carParking_Open',\n",
    "        'carParking_Covered',\n",
    "        'numberOfBalconied',\n",
    "        'premiumProperty',\n",
    "        'projectName',\n",
    "        'nameOfSociety',\n",
    "        'url',\n",
    "        # 'uuid',\n",
    "        'carpetAreaSqft',\n",
    "        'noOfLifts',\n",
    "        'ownershipType',\n",
    "        'possessionStatus',\n",
    "        'propertyType',\n",
    "\n",
    "        'flooringType_Vitrified',\n",
    "        'flooringType_CeramicTiles',\n",
    "        'flooringType_Marble',\n",
    "        'flooringType_NormalTilesKotahStone',\n",
    "        'flooringType_Granite',\n",
    "        'flooringType_Wooden',\n",
    "        'flooringType_Mosaic',\n",
    "        'flooringType_Marbonite',\n",
    "\n",
    "        'additionalRoom_PujaRoom',\n",
    "        'additionalRoom_Study',\n",
    "        'additionalRoom_Store',\n",
    "        'additionalRoom_ServantRoom',\n",
    "        \n",
    "        'landMarks', \n",
    "        'locality', \n",
    "        'developerName',]\n",
    "\n",
    "################################################################################\n",
    "# ONLY USING THE RAW SETs, NOT IMPUTED SET\n",
    "################################################################################\n",
    "df_train = pd.read_csv(\n",
    "    '../../Data/train.csv',\n",
    "    dtype = dtype_mapping,\n",
    "    index_col=0\n",
    ")\n",
    "df_train.drop(COLUMNS_TO_DROP, axis=1, inplace=True)\n",
    "\n",
    "df_test = pd.read_csv(\n",
    "    '../../Data/test.csv',\n",
    "    dtype = dtype_mapping,\n",
    "    index_col=0\n",
    ")\n",
    "df_test.drop(COLUMNS_TO_DROP, axis=1, inplace=True)\n",
    "\n",
    "################################################################################\n",
    "# DROPPING ALL ROWS WITH MISSING VALUES\n",
    "################################################################################\n",
    "\n",
    "print(\"Train Set Null values: \", df_train.isna().sum(), '\\n')\n",
    "print(\"Test Set Null values: \", df_test.isna().sum(), '\\n')\n",
    "\n",
    "df_train.dropna(axis=0, inplace=True)\n",
    "df_test.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6b5830",
   "metadata": {},
   "source": [
    "# Python Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdcab94",
   "metadata": {},
   "source": [
    "## Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04111b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "# Assume that df_train and df_test are your already cleaned and imputed datasets.\n",
    "X_train = df_train.drop(\"price\", axis=1)\n",
    "y_train = df_train[\"price\"]\n",
    "\n",
    "# List of numeric features\n",
    "numeric_cols = [\n",
    "    \"carpetArea\",\n",
    "    \"floorNumber\",\n",
    "    \"totalFloorNumber\",\n",
    "    \"bedrooms\",\n",
    "    \"bathrooms\",\n",
    "]\n",
    "\n",
    "# For the two features that will be encoded differently:\n",
    "cat_diff_cols = [\"localityName\", \"transactionType\"]\n",
    "\n",
    "ordinal_cols = [\"furnished\", \"ageofcons\"]\n",
    "\n",
    "furnished_order = ['Unfurnished', 'Semi-Furnished', 'Furnished']\n",
    "ordinal_transformer_furnished = Pipeline(\n",
    "    steps=[\n",
    "        (\"ordinal\", OrdinalEncoder(categories=[furnished_order])),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Here we create a pipeline that first ordinal-encodes then scales the result.\n",
    "age_order = [\n",
    "    'Under Construction',  # first: youngest / newest state\n",
    "    'New Construction',\n",
    "    'Less than 5 years',\n",
    "    '5 to 10 years',\n",
    "    '10 to 15 years',\n",
    "    '15 to 20 years',\n",
    "    'Above 20 years'       # last: oldest\n",
    "]\n",
    "ordinal_transformer_ageofcons = Pipeline(\n",
    "    steps=[\n",
    "        (\"ordinal\", OrdinalEncoder(categories=[age_order])),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c9f1d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_preprocessor_gb = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_cols),\n",
    "        (\"passthrough\", \"passthrough\", cat_diff_cols),\n",
    "        (\"ord-furnished\", ordinal_transformer_furnished, [\"furnished\"]),\n",
    "        # (\"ord-reservedparking\", ordinal_transformer_rs, [\"ReservedParking\"]),\n",
    "        (\"ord-ageofcons\", ordinal_transformer_ageofcons, [\"ageofcons\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tree_pipeline_gb = Pipeline(steps=[(\"preprocessor\", tree_preprocessor_gb)])\n",
    "# Now transform the training features for the tree models:\n",
    "X_train_gb = tree_pipeline_gb.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fee111a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test features saved to test_data_x.json\n",
      "Test target shape: (3469,)\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have df_test loaded and cleaned similarly to df_train\n",
    "# Make sure it has the same columns as the original X_train before preprocessing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# --- Configuration ---\n",
    "TEST_DATA_JSON_PATH = \"test_data_x.json\"\n",
    "\n",
    "X_test = df_test.drop(\"price\", axis=1)\n",
    "y_test = df_test[\"price\"].astype(float) # Ensure y_test is float for metrics\n",
    "\n",
    "# --- Save X_test to JSON for Node.js ---\n",
    "# Convert categoricals to strings for JSON compatibility\n",
    "X_test_json = X_test.copy()\n",
    "for col in X_test_json.select_dtypes(include='category').columns:\n",
    "     X_test_json[col] = X_test_json[col].astype(str)\n",
    "\n",
    "# Use 'records' orientation for an array of objects\n",
    "X_test_json.to_json(TEST_DATA_JSON_PATH, orient='records', indent=4)\n",
    "\n",
    "print(f\"Test features saved to {TEST_DATA_JSON_PATH}\")\n",
    "print(f\"Test target shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d8f80a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05594b79",
   "metadata": {},
   "source": [
    "# Web ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec075d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Selenium ONNX Runtime Web prediction...\n",
      "Serving HTTP on http://localhost:8008/ from directory '.'...\n",
      "Loading test data from test_data_x.json...\n",
      "Loaded 3469 test samples.\n",
      "Setting up Chrome WebDriver...\n",
      "WebDriver initialized.\n",
      "Navigating to http://localhost:8008/inference_page.html...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [05/May/2025 17:18:46] \"GET /inference_page.html HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/May/2025 17:18:46] \"GET /node_modules/onnxruntime-web/dist/ort.min.js HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML page loaded and initial JS ready.\n",
      "Executing inference function in browser...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [05/May/2025 17:18:46] code 404, message File not found\n",
      "127.0.0.1 - - [05/May/2025 17:18:46] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [05/May/2025 17:18:47] \"GET /node_modules/onnxruntime-web/dist/ort-wasm-simd-threaded.jsep.mjs HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/May/2025 17:18:47] \"GET /node_modules/onnxruntime-web/dist/ort-wasm-simd-threaded.jsep.wasm HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/May/2025 17:18:47] \"GET /prediction_pipeline_iteration_3.onnx HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Browser inference execution time: 4.41s\n",
      "Received 3469 predictions back from browser.\n",
      "Saving browser predictions to c:\\Aditya Joshi\\PuneHousePricePrediction\\Stationary\\Iteration_3\\Tests\\Prediction\\onnx_browser_predictions.json...\n",
      "Browser predictions saved successfully.\n",
      "Closing browser...\n",
      "Browser closed.\n",
      "Shutting down HTTP server...\n",
      "HTTP server stopped.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import http.server\n",
    "import socketserver\n",
    "import threading # To run the server in the background\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "# from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# --- Configuration ---\n",
    "TEST_DATA_JSON_PATH = \"test_data_x.json\"\n",
    "PREDICTIONS_BROWSER_PATH = \"onnx_browser_predictions.json\"\n",
    "HTML_PAGE_FILENAME = \"inference_page.html\"\n",
    "SERVER_PORT = 8008 # Choose an available port\n",
    "SERVER_ADDRESS = \"localhost\"\n",
    "\n",
    "# --- Simple HTTP Server Setup ---\n",
    "class Handler(http.server.SimpleHTTPRequestHandler):\n",
    "    # Optional: Prevent caching to ensure fresh loads during testing\n",
    "    def end_headers(self):\n",
    "        self.send_header('Cache-Control', 'no-store, no-cache, must-revalidate')\n",
    "        self.send_header('Pragma', 'no-cache')\n",
    "        self.send_header('Expires', '0')\n",
    "        super().end_headers()\n",
    "\n",
    "def start_http_server(port, directory=\".\"):\n",
    "    \"\"\"Starts a simple HTTP server in a background thread.\"\"\"\n",
    "    os.chdir(directory) # Serve files from the specified directory\n",
    "    httpd = socketserver.TCPServer((\"\", port), Handler)\n",
    "    print(f\"Serving HTTP on http://{SERVER_ADDRESS}:{port}/ from directory '{directory}'...\")\n",
    "    server_thread = threading.Thread(target=httpd.serve_forever, daemon=True)\n",
    "    server_thread.start()\n",
    "    return httpd, server_thread\n",
    "\n",
    "# --- Main Selenium Logic ---\n",
    "def run_selenium_prediction():\n",
    "    print(\"Starting Selenium ONNX Runtime Web prediction...\")\n",
    "    driver = None\n",
    "    httpd = None\n",
    "    server_thread = None\n",
    "    original_cwd = os.getcwd() # Remember original directory\n",
    "\n",
    "    try:\n",
    "        # 0. Start HTTP Server\n",
    "        # Determine the correct directory to serve from. It should be the one\n",
    "        # where relative paths in inference_page.html make sense.\n",
    "        # Assuming the script runs where node_modules and PipelinesAndModels are accessible\n",
    "        # If not, adjust the directory path.\n",
    "        serve_directory = \".\"\n",
    "        httpd, server_thread = start_http_server(SERVER_PORT, serve_directory)\n",
    "        time.sleep(1) # Give server a moment to start\n",
    "\n",
    "        # 1. Load Test Data\n",
    "        print(f\"Loading test data from {TEST_DATA_JSON_PATH}...\")\n",
    "        test_data_path = os.path.join(original_cwd, TEST_DATA_JSON_PATH) # Use absolute path if needed\n",
    "        if not os.path.exists(test_data_path):\n",
    "            raise FileNotFoundError(f\"Test data file not found: {test_data_path}\")\n",
    "        with open(test_data_path, 'r') as f:\n",
    "            test_data = json.load(f)\n",
    "        print(f\"Loaded {len(test_data)} test samples.\")\n",
    "\n",
    "        # 2. Setup Selenium WebDriver\n",
    "        print(\"Setting up Chrome WebDriver...\")\n",
    "        chrome_options = ChromeOptions()\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        chrome_options.add_argument(\"--disable-gpu\")\n",
    "        chrome_options.add_argument(\"--no-sandbox\")\n",
    "        chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        # Optional: Increase timeout if model loading is slow\n",
    "        # chrome_options.page_load_strategy = 'normal' # Default\n",
    "        # service = ChromeService(ChromeDriverManager().install())\n",
    "        driver = webdriver.Chrome(options=chrome_options)\n",
    "        # Set a script timeout in case JS execution hangs\n",
    "        driver.set_script_timeout(120) # 120 seconds, adjust as needed\n",
    "        print(\"WebDriver initialized.\")\n",
    "\n",
    "        # 3. Load the HTML Page via HTTP\n",
    "        page_url = f\"http://{SERVER_ADDRESS}:{SERVER_PORT}/{HTML_PAGE_FILENAME}\"\n",
    "        print(f\"Navigating to {page_url}...\")\n",
    "        driver.get(page_url)\n",
    "        # Wait for the \"Ready for data.\" status, indicating JS has loaded initially\n",
    "        # Using Selenium's explicit waits is more robust than time.sleep\n",
    "        from selenium.webdriver.support.ui import WebDriverWait\n",
    "        from selenium.webdriver.support import expected_conditions as EC\n",
    "        from selenium.webdriver.common.by import By\n",
    "\n",
    "        WebDriverWait(driver, 30).until(\n",
    "            EC.text_to_be_present_in_element((By.ID, 'status'), 'Ready for data.')\n",
    "        )\n",
    "        print(\"HTML page loaded and initial JS ready.\")\n",
    "\n",
    "        # 4. Execute Inference Function in Browser Context\n",
    "        print(\"Executing inference function in browser...\")\n",
    "        start_time = time.time()\n",
    "        js_script = \"return await runInferenceInBrowser(arguments[0]);\"\n",
    "        # Use execute_async_script if the JS function is truly async and long-running,\n",
    "        # but execute_script often works fine if the await resolves within the timeout.\n",
    "        predictions_or_error = driver.execute_script(js_script, test_data)\n",
    "        browser_time = time.time() - start_time\n",
    "        print(f\"Browser inference execution time: {browser_time:.2f}s\")\n",
    "\n",
    "        # 5. Check for Errors returned from JS\n",
    "        if isinstance(predictions_or_error, dict) and 'error' in predictions_or_error:\n",
    "             print(\"Error received from browser JavaScript:\")\n",
    "             print(f\"  Message: {predictions_or_error.get('error')}\")\n",
    "             print(f\"  Stack: {predictions_or_error.get('stack')}\")\n",
    "             raise RuntimeError(\"JavaScript execution failed in browser.\")\n",
    "\n",
    "        if not isinstance(predictions_or_error, list):\n",
    "             raise TypeError(f\"Expected a list of predictions from browser, got: {type(predictions_or_error)}\")\n",
    "\n",
    "        print(f\"Received {len(predictions_or_error)} predictions back from browser.\")\n",
    "\n",
    "        # 6. Save Predictions\n",
    "        output_path = os.path.join(original_cwd, PREDICTIONS_BROWSER_PATH)\n",
    "        print(f\"Saving browser predictions to {output_path}...\")\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(predictions_or_error, f, indent=2)\n",
    "        print(\"Browser predictions saved successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during Selenium browser prediction: {e}\")\n",
    "        raise\n",
    "\n",
    "    finally:\n",
    "        # 7. Close Browser\n",
    "        if driver:\n",
    "            print(\"Closing browser...\")\n",
    "            driver.quit()\n",
    "            print(\"Browser closed.\")\n",
    "        # 8. Stop HTTP Server\n",
    "        if httpd:\n",
    "            print(\"Shutting down HTTP server...\")\n",
    "            httpd.shutdown() # Stop the server loop\n",
    "            httpd.server_close() # Release the port\n",
    "            if server_thread:\n",
    "                server_thread.join(timeout=5) # Wait for thread to finish\n",
    "            print(\"HTTP server stopped.\")\n",
    "        os.chdir(original_cwd) # Change back to original directory\n",
    "\n",
    "\n",
    "run_selenium_prediction()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25de649c",
   "metadata": {},
   "source": [
    "# Comparison: Python vs Node.js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daee56b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting comparison with detailed error analysis (including API)...\n",
      "Loading test data features from test_data_x.json...\n",
      "Loaded X_test shape: (3469, 9), y_test shape: (3469,)\n",
      "Loading Scikit-learn pipeline from ../../PipelinesAndModels/Prediction/prediction_pipeline_iteration_3.pkl...\n",
      "Pipeline loaded successfully.\n",
      "Loading ONNX model from ../../PipelinesAndModels/Prediction/prediction_pipeline_iteration_3.onnx...\n",
      "Generating predictions with Scikit-learn pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Aditya Joshi\\PuneHousePricePrediction\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Aditya Joshi\\PuneHousePricePrediction\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-learn prediction time: 0.39s\n",
      "Generating predictions with ONNX Runtime (Python)...\n",
      "  Processed 100 / 3469 samples...\n",
      "  Processed 200 / 3469 samples...\n",
      "  Processed 300 / 3469 samples...\n",
      "  Processed 400 / 3469 samples...\n",
      "  Processed 500 / 3469 samples...\n",
      "  Processed 600 / 3469 samples...\n",
      "  Processed 700 / 3469 samples...\n",
      "  Processed 800 / 3469 samples...\n",
      "  Processed 900 / 3469 samples...\n",
      "  Processed 1000 / 3469 samples...\n",
      "  Processed 1100 / 3469 samples...\n",
      "  Processed 1200 / 3469 samples...\n",
      "  Processed 1300 / 3469 samples...\n",
      "  Processed 1400 / 3469 samples...\n",
      "  Processed 1500 / 3469 samples...\n",
      "  Processed 1600 / 3469 samples...\n",
      "  Processed 1700 / 3469 samples...\n",
      "  Processed 1800 / 3469 samples...\n",
      "  Processed 1900 / 3469 samples...\n",
      "  Processed 2000 / 3469 samples...\n",
      "  Processed 2100 / 3469 samples...\n",
      "  Processed 2200 / 3469 samples...\n",
      "  Processed 2300 / 3469 samples...\n",
      "  Processed 2400 / 3469 samples...\n",
      "  Processed 2500 / 3469 samples...\n",
      "  Processed 2600 / 3469 samples...\n",
      "  Processed 2700 / 3469 samples...\n",
      "  Processed 2800 / 3469 samples...\n",
      "  Processed 2900 / 3469 samples...\n",
      "  Processed 3000 / 3469 samples...\n",
      "  Processed 3100 / 3469 samples...\n",
      "  Processed 3200 / 3469 samples...\n",
      "  Processed 3300 / 3469 samples...\n",
      "  Processed 3400 / 3469 samples...\n",
      "ONNX (Python) prediction time: 1.93s\n",
      "Loading predictions from Node.js ONNX run (onnx_js_predictions.json)...\n",
      "Loaded 3469 Node.js predictions.\n",
      "Loading predictions from Browser ONNX run (onnx_browser_predictions.json)...\n",
      "Loaded 3469 Browser predictions.\n",
      "Generating predictions via Live API (https://phpp-api.adityajoshi.in/predict)...\n",
      "  Processed 50 / 3469 samples via API... (Errors: 0, Time: 40.1s)\n",
      "  Processed 100 / 3469 samples via API... (Errors: 0, Time: 80.1s)\n",
      "  Processed 150 / 3469 samples via API... (Errors: 0, Time: 121.2s)\n",
      "  Processed 200 / 3469 samples via API... (Errors: 0, Time: 161.3s)\n",
      "  Processed 250 / 3469 samples via API... (Errors: 0, Time: 201.6s)\n",
      "  Processed 300 / 3469 samples via API... (Errors: 0, Time: 241.6s)\n",
      "  Processed 350 / 3469 samples via API... (Errors: 0, Time: 281.7s)\n",
      "  Processed 400 / 3469 samples via API... (Errors: 0, Time: 321.6s)\n",
      "  Processed 450 / 3469 samples via API... (Errors: 0, Time: 361.6s)\n",
      "  Processed 500 / 3469 samples via API... (Errors: 0, Time: 401.7s)\n",
      "  Processed 550 / 3469 samples via API... (Errors: 0, Time: 442.8s)\n",
      "  Processed 600 / 3469 samples via API... (Errors: 0, Time: 482.7s)\n",
      "  Processed 650 / 3469 samples via API... (Errors: 0, Time: 522.7s)\n",
      "  Processed 700 / 3469 samples via API... (Errors: 0, Time: 562.4s)\n",
      "Error calling API for row 747: HTTPSConnectionPool(host='phpp-api.adityajoshi.in', port=443): Max retries exceeded with url: /predict (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000025E4B29D940>: Failed to resolve 'phpp-api.adityajoshi.in' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  Processed 750 / 3469 samples via API... (Errors: 1, Time: 614.5s)\n",
      "  Processed 800 / 3469 samples via API... (Errors: 1, Time: 654.3s)\n",
      "  Processed 850 / 3469 samples via API... (Errors: 1, Time: 694.2s)\n",
      "  Processed 900 / 3469 samples via API... (Errors: 1, Time: 734.0s)\n",
      "  Processed 950 / 3469 samples via API... (Errors: 1, Time: 773.8s)\n",
      "  Processed 1000 / 3469 samples via API... (Errors: 1, Time: 813.7s)\n",
      "  Processed 1050 / 3469 samples via API... (Errors: 1, Time: 853.4s)\n",
      "  Processed 1100 / 3469 samples via API... (Errors: 1, Time: 893.1s)\n",
      "  Processed 1150 / 3469 samples via API... (Errors: 1, Time: 933.1s)\n",
      "  Processed 1200 / 3469 samples via API... (Errors: 1, Time: 972.9s)\n",
      "  Processed 1250 / 3469 samples via API... (Errors: 1, Time: 1012.9s)\n",
      "  Processed 1300 / 3469 samples via API... (Errors: 1, Time: 1052.6s)\n",
      "  Processed 1350 / 3469 samples via API... (Errors: 1, Time: 1092.3s)\n",
      "  Processed 1400 / 3469 samples via API... (Errors: 1, Time: 1132.2s)\n",
      "  Processed 1450 / 3469 samples via API... (Errors: 1, Time: 1172.0s)\n",
      "  Processed 1500 / 3469 samples via API... (Errors: 1, Time: 1212.3s)\n",
      "  Processed 1550 / 3469 samples via API... (Errors: 1, Time: 1252.4s)\n",
      "  Processed 1600 / 3469 samples via API... (Errors: 1, Time: 1292.2s)\n",
      "  Processed 1650 / 3469 samples via API... (Errors: 1, Time: 1331.9s)\n",
      "  Processed 1700 / 3469 samples via API... (Errors: 1, Time: 1372.0s)\n",
      "  Processed 1750 / 3469 samples via API... (Errors: 1, Time: 1411.8s)\n",
      "  Processed 1800 / 3469 samples via API... (Errors: 1, Time: 1451.5s)\n",
      "  Processed 1850 / 3469 samples via API... (Errors: 1, Time: 1492.3s)\n",
      "  Processed 1900 / 3469 samples via API... (Errors: 1, Time: 1532.3s)\n",
      "  Processed 1950 / 3469 samples via API... (Errors: 1, Time: 1572.0s)\n",
      "  Processed 2000 / 3469 samples via API... (Errors: 1, Time: 1611.8s)\n",
      "  Processed 2050 / 3469 samples via API... (Errors: 1, Time: 1651.5s)\n",
      "  Processed 2100 / 3469 samples via API... (Errors: 1, Time: 1691.4s)\n",
      "  Processed 2150 / 3469 samples via API... (Errors: 1, Time: 1731.1s)\n",
      "  Processed 2200 / 3469 samples via API... (Errors: 1, Time: 1770.9s)\n",
      "  Processed 2250 / 3469 samples via API... (Errors: 1, Time: 1811.1s)\n",
      "  Processed 2300 / 3469 samples via API... (Errors: 1, Time: 1859.9s)\n",
      "  Processed 2350 / 3469 samples via API... (Errors: 1, Time: 1899.6s)\n",
      "  Processed 2400 / 3469 samples via API... (Errors: 1, Time: 1939.4s)\n",
      "  Processed 2450 / 3469 samples via API... (Errors: 1, Time: 1980.0s)\n",
      "  Processed 2500 / 3469 samples via API... (Errors: 1, Time: 2019.7s)\n",
      "  Processed 2550 / 3469 samples via API... (Errors: 1, Time: 2059.4s)\n",
      "  Processed 2600 / 3469 samples via API... (Errors: 1, Time: 2099.1s)\n",
      "  Processed 2650 / 3469 samples via API... (Errors: 1, Time: 2138.9s)\n",
      "  Processed 2700 / 3469 samples via API... (Errors: 1, Time: 2178.8s)\n",
      "  Processed 2750 / 3469 samples via API... (Errors: 1, Time: 2218.9s)\n",
      "  Processed 2800 / 3469 samples via API... (Errors: 1, Time: 2258.9s)\n",
      "  Processed 2850 / 3469 samples via API... (Errors: 1, Time: 2299.0s)\n",
      "  Processed 2900 / 3469 samples via API... (Errors: 1, Time: 2338.9s)\n",
      "  Processed 2950 / 3469 samples via API... (Errors: 1, Time: 2379.0s)\n",
      "  Processed 3000 / 3469 samples via API... (Errors: 1, Time: 2419.4s)\n",
      "  Processed 3050 / 3469 samples via API... (Errors: 1, Time: 2459.1s)\n",
      "  Processed 3100 / 3469 samples via API... (Errors: 1, Time: 2498.7s)\n",
      "  Processed 3150 / 3469 samples via API... (Errors: 1, Time: 2538.7s)\n",
      "  Processed 3200 / 3469 samples via API... (Errors: 1, Time: 2578.3s)\n",
      "  Processed 3250 / 3469 samples via API... (Errors: 1, Time: 2618.0s)\n",
      "  Processed 3300 / 3469 samples via API... (Errors: 1, Time: 2657.7s)\n",
      "  Processed 3350 / 3469 samples via API... (Errors: 1, Time: 2697.6s)\n",
      "  Processed 3400 / 3469 samples via API... (Errors: 1, Time: 2737.3s)\n",
      "  Processed 3450 / 3469 samples via API... (Errors: 1, Time: 2777.1s)\n",
      "API prediction finished. Total time: 2793.09s. Errors encountered: 1\n",
      "\n",
      "--- Calculating Errors and R2 Scores ---\n",
      "SKL Python R2: 0.924968\n",
      "ONNX Python R2: 0.924973\n",
      "ONNX JS R2:    0.901331\n",
      "ONNX Browser R2:0.924973\n",
      "API FastAPI R2: 0.924968 (calculated on 3468 valid responses)\n",
      "\n",
      "--- Error Distribution Analysis ---\n",
      "\n",
      "--- SKL_Python ---\n",
      "R2 Score: 0.924968\n",
      "\n",
      "Absolute Error (AE) Distribution:\n",
      "count        3,469.0000\n",
      "mean     1,628,232.1559\n",
      "std      2,857,112.3298\n",
      "min            378.9453\n",
      "25%        354,043.5022\n",
      "50%        815,833.6922\n",
      "75%      1,757,115.0444\n",
      "90%      3,608,283.1564\n",
      "95%      5,767,345.2924\n",
      "99%     14,032,333.7994\n",
      "max     51,201,842.3302\n",
      "dtype: float64\n",
      "\n",
      "Absolute Percentage Error (APE) Distribution (%):\n",
      "count   3,469.0000\n",
      "mean       14.8684\n",
      "std        15.4532\n",
      "min         0.0108\n",
      "25%         4.7656\n",
      "50%        10.4583\n",
      "75%        19.9041\n",
      "90%        32.5673\n",
      "95%        42.6101\n",
      "99%        69.4770\n",
      "max       221.7754\n",
      "dtype: float64\n",
      "\n",
      "--- ONNX_Python ---\n",
      "R2 Score: 0.924973\n",
      "\n",
      "Absolute Error (AE) Distribution:\n",
      "count        3,469.0000\n",
      "mean     1,628,049.0631\n",
      "std      2,857,074.5002\n",
      "min            380.0000\n",
      "25%        354,042.0000\n",
      "50%        815,831.0000\n",
      "75%      1,757,119.5000\n",
      "90%      3,608,282.6000\n",
      "95%      5,767,336.0000\n",
      "99%     14,032,346.6400\n",
      "max     51,201,864.0000\n",
      "dtype: float64\n",
      "\n",
      "Absolute Percentage Error (APE) Distribution (%):\n",
      "count   3,469.0000\n",
      "mean       14.8676\n",
      "std        15.4534\n",
      "min         0.0109\n",
      "25%         4.7656\n",
      "50%        10.4436\n",
      "75%        19.9042\n",
      "90%        32.5673\n",
      "95%        42.6102\n",
      "99%        69.4770\n",
      "max       221.7754\n",
      "dtype: float64\n",
      "\n",
      "--- ONNX_JS ---\n",
      "R2 Score: 0.901331\n",
      "\n",
      "Absolute Error (AE) Distribution:\n",
      "count        3,469.0000\n",
      "mean     1,813,429.2530\n",
      "std      3,306,435.6337\n",
      "min             77.0000\n",
      "25%        361,290.7500\n",
      "50%        859,942.7500\n",
      "75%      1,924,039.0000\n",
      "90%      3,916,735.2000\n",
      "95%      6,437,856.4000\n",
      "99%     17,034,969.9200\n",
      "max     55,162,140.0000\n",
      "dtype: float64\n",
      "\n",
      "Absolute Percentage Error (APE) Distribution (%):\n",
      "count   3,469.0000\n",
      "mean       16.1135\n",
      "std        16.5547\n",
      "min         0.0014\n",
      "25%         5.2311\n",
      "50%        11.2123\n",
      "75%        21.3053\n",
      "90%        35.5707\n",
      "95%        46.1570\n",
      "99%        82.2149\n",
      "max       206.9009\n",
      "dtype: float64\n",
      "\n",
      "--- ONNX_Browser ---\n",
      "R2 Score: 0.924973\n",
      "\n",
      "Absolute Error (AE) Distribution:\n",
      "count        3,469.0000\n",
      "mean     1,628,049.0631\n",
      "std      2,857,074.5002\n",
      "min            380.0000\n",
      "25%        354,042.0000\n",
      "50%        815,831.0000\n",
      "75%      1,757,119.5000\n",
      "90%      3,608,282.6000\n",
      "95%      5,767,336.0000\n",
      "99%     14,032,346.6400\n",
      "max     51,201,864.0000\n",
      "dtype: float64\n",
      "\n",
      "Absolute Percentage Error (APE) Distribution (%):\n",
      "count   3,469.0000\n",
      "mean       14.8676\n",
      "std        15.4534\n",
      "min         0.0109\n",
      "25%         4.7656\n",
      "50%        10.4436\n",
      "75%        19.9042\n",
      "90%        32.5673\n",
      "95%        42.6102\n",
      "99%        69.4770\n",
      "max       221.7754\n",
      "dtype: float64\n",
      "\n",
      "--- API_FastAPI ---\n",
      "R2 Score: 0.924968\n",
      "\n",
      "Absolute Error (AE) Distribution:\n",
      "count        3,468.0000\n",
      "mean     1,628,669.1194\n",
      "std      2,857,408.4038\n",
      "min            378.0000\n",
      "25%        354,069.2500\n",
      "50%        816,067.5000\n",
      "75%      1,757,411.2500\n",
      "90%      3,608,977.5000\n",
      "95%      5,767,646.0500\n",
      "99%     14,034,270.1100\n",
      "max     51,201,843.0000\n",
      "dtype: float64\n",
      "\n",
      "Absolute Percentage Error (APE) Distribution (%):\n",
      "count   3,468.0000\n",
      "mean       14.8724\n",
      "std        15.4536\n",
      "min         0.0108\n",
      "25%         4.7704\n",
      "50%        10.4586\n",
      "75%        19.9105\n",
      "90%        32.5733\n",
      "95%        42.6180\n",
      "99%        69.4867\n",
      "max       221.7754\n",
      "dtype: float64\n",
      "\n",
      "--- Prediction Differences Distribution ---\n",
      "\n",
      "SKL vs ONNX-Py Difference:\n",
      "count     3,469.0000\n",
      "mean        331.4524\n",
      "std      15,593.7423\n",
      "min           0.0007\n",
      "50%           2.6922\n",
      "75%           6.9797\n",
      "95%          14.0976\n",
      "99%          28.5105\n",
      "100%    884,224.1509\n",
      "max     884,224.1509\n",
      "dtype: float64\n",
      "\n",
      "SKL vs ONNX-JS Difference:\n",
      "count        3,469.0000\n",
      "mean       776,203.0617\n",
      "std      1,596,100.7255\n",
      "min            170.0542\n",
      "50%        319,583.2059\n",
      "75%        739,242.6588\n",
      "95%      2,898,468.2954\n",
      "99%      7,341,272.8806\n",
      "100%    28,762,419.2424\n",
      "max     28,762,419.2424\n",
      "dtype: float64\n",
      "\n",
      "SKL vs ONNX-Browser Difference:\n",
      "count     3,469.0000\n",
      "mean        331.4524\n",
      "std      15,593.7423\n",
      "min           0.0007\n",
      "50%           2.6922\n",
      "75%           6.9797\n",
      "95%          14.0976\n",
      "99%          28.5105\n",
      "100%    884,224.1509\n",
      "max     884,224.1509\n",
      "dtype: float64\n",
      "\n",
      "SKL vs API-FastAPI Difference (on valid API responses):\n",
      "count   3,468.0000\n",
      "mean        0.4943\n",
      "std         0.2923\n",
      "min         0.0000\n",
      "50%         0.4901\n",
      "75%         0.7503\n",
      "95%         0.9475\n",
      "99%         0.9898\n",
      "100%        1.0000\n",
      "max         1.0000\n",
      "dtype: float64\n",
      "\n",
      "ONNX-Browser vs API-FastAPI Difference (on valid API responses):\n",
      "count     3,468.0000\n",
      "mean        331.8824\n",
      "std      15,595.9949\n",
      "min           0.0000\n",
      "50%           3.0000\n",
      "75%           7.0000\n",
      "95%          15.0000\n",
      "99%          29.3300\n",
      "100%    884,225.0000\n",
      "max     884,225.0000\n",
      "dtype: float64\n",
      "\n",
      "Comparison finished.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import requests # Import requests library\n",
    "\n",
    "# Scikit-learn metrics\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# ONNX Runtime\n",
    "import onnxruntime as rt\n",
    "\n",
    "# LightGBM and converters\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from skl2onnx import update_registered_converter\n",
    "from skl2onnx.common.shape_calculator import calculate_linear_regressor_output_shapes\n",
    "from onnxmltools.convert.lightgbm.operator_converters.LightGbm import convert_lightgbm\n",
    "\n",
    "# --- Configuration ---\n",
    "TEST_DATA_JSON_PATH = \"test_data_x.json\"\n",
    "PREDICTIONS_JS_PATH = \"onnx_js_predictions.json\"\n",
    "PREDICTIONS_BROWSER_PATH = \"onnx_browser_predictions.json\"\n",
    "PIPELINE_PATH = \"../../PipelinesAndModels/Prediction/prediction_pipeline_iteration_3.pkl\"\n",
    "ONNX_MODEL_PATH = \"../../PipelinesAndModels/Prediction/prediction_pipeline_iteration_3.onnx\"\n",
    "API_ENDPOINT_URL = \"https://phpp-api.adityajoshi.in/predict\" # Your API endpoint\n",
    "API_REQUEST_DELAY = 0.75 # Delay in seconds between API calls\n",
    "\n",
    "# --- Define initial types ---\n",
    "from skl2onnx.common.data_types import (\n",
    "    FloatTensorType, Int64TensorType, StringTensorType\n",
    ")\n",
    "# (initial_types definition remains the same)\n",
    "initial_types = [\n",
    "    (\"localityName\", StringTensorType([None, 1])),\n",
    "    (\"carpetArea\", Int64TensorType([None, 1])),\n",
    "    (\"floorNumber\", Int64TensorType([None, 1])),\n",
    "    (\"totalFloorNumber\", Int64TensorType([None, 1])),\n",
    "    (\"transactionType\", StringTensorType([None, 1])),\n",
    "    (\"furnished\", StringTensorType([None, 1])),\n",
    "    (\"bedrooms\", Int64TensorType([None, 1])),\n",
    "    (\"bathrooms\", Int64TensorType([None, 1])),\n",
    "    (\"ageofcons\", StringTensorType([None, 1])),\n",
    "]\n",
    "\n",
    "\n",
    "# --- Function to prepare ONNX input dict ---\n",
    "def prepare_onnx_input(data_row_df, types):\n",
    "    # (Keep the function as defined previously)\n",
    "    onx_input = {}\n",
    "    for name, itype in types:\n",
    "        col_name = name\n",
    "        series = data_row_df[col_name]\n",
    "        if isinstance(itype, StringTensorType):\n",
    "            numpy_array = series.astype(str).values.reshape(-1, 1)\n",
    "        elif isinstance(itype, Int64TensorType):\n",
    "            numpy_array = series.values.reshape(-1, 1).astype(np.int64)\n",
    "        elif isinstance(itype, FloatTensorType):\n",
    "            numpy_array = series.values.reshape(-1, 1).astype(np.float32)\n",
    "        else:\n",
    "            raise TypeError(f\"Unhandled ONNX input type: {type(itype)}\")\n",
    "        onx_input[name] = numpy_array\n",
    "    return onx_input\n",
    "\n",
    "# --- Main Comparison Logic ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting comparison with detailed error analysis (including API)...\")\n",
    "\n",
    "    # 1. Load Test Data (X_test, y_test)\n",
    "    print(f\"Loading test data features from {TEST_DATA_JSON_PATH}...\")\n",
    "    X_test = pd.read_json(TEST_DATA_JSON_PATH, orient='records')\n",
    "    if 'y_test' not in globals():\n",
    "         raise NameError(\"y_test not found. Ensure it's loaded or reload it.\")\n",
    "    y_test_np = y_test.to_numpy()\n",
    "    print(f\"Loaded X_test shape: {X_test.shape}, y_test shape: {y_test_np.shape}\")\n",
    "\n",
    "    # --- Load Models/Pipelines (Sections 2 & 3) ---\n",
    "    # (Keep the loading logic for SKL Pipeline and ONNX Python as before)\n",
    "    # 2. Load Scikit-learn Pipeline\n",
    "    print(f\"Loading Scikit-learn pipeline from {PIPELINE_PATH}...\")\n",
    "    try:\n",
    "        update_registered_converter(\n",
    "            LGBMRegressor, \"LightGbmLGBMRegressor\",\n",
    "            calculate_linear_regressor_output_shapes, convert_lightgbm\n",
    "        )\n",
    "        with open(PIPELINE_PATH, 'rb') as f:\n",
    "            skl_pipeline = pickle.load(f)\n",
    "        print(\"Pipeline loaded successfully.\")\n",
    "    except Exception as e: print(f\"Error loading pickle file: {e}\"); exit()\n",
    "\n",
    "    # 3. Load ONNX Model (Python Runtime)\n",
    "    print(f\"Loading ONNX model from {ONNX_MODEL_PATH}...\")\n",
    "    try:\n",
    "        onnx_session_py = rt.InferenceSession(\n",
    "            ONNX_MODEL_PATH, providers=['CPUExecutionProvider']\n",
    "        )\n",
    "        onnx_py_output_name = onnx_session_py.get_outputs()[0].name\n",
    "    except Exception as e: print(f\"Error loading ONNX model: {e}\"); exit()\n",
    "\n",
    "\n",
    "    # --- Generate/Load Predictions (Sections 4, 5, 6, 7) ---\n",
    "    # (Keep prediction logic for SKL, ONNX Py, ONNX JS, ONNX Browser as before)\n",
    "    # 4. Get Predictions: Scikit-learn\n",
    "    print(\"Generating predictions with Scikit-learn pipeline...\")\n",
    "    start_time = time.time()\n",
    "    y_pred_skl = skl_pipeline.predict(X_test)\n",
    "    skl_time = time.time() - start_time\n",
    "    print(f\"Scikit-learn prediction time: {skl_time:.2f}s\")\n",
    "\n",
    "\n",
    "    # 5. Get Predictions: ONNX Runtime (Python)\n",
    "    print(\"Generating predictions with ONNX Runtime (Python)...\")\n",
    "    y_pred_onnx_py_list = []\n",
    "    start_time = time.time()\n",
    "    for i in range(len(X_test)):\n",
    "        row_df = X_test.iloc[i:i+1]\n",
    "        onx_input = prepare_onnx_input(row_df, initial_types)\n",
    "        pred = onnx_session_py.run([onnx_py_output_name], onx_input)[0]\n",
    "        y_pred_onnx_py_list.append(pred.item())\n",
    "        if (i + 1) % 100 == 0: print(f\"  Processed {i + 1} / {len(X_test)} samples...\")\n",
    "    y_pred_onnx_py = np.array(y_pred_onnx_py_list)\n",
    "    onnx_py_time = time.time() - start_time\n",
    "    print(f\"ONNX (Python) prediction time: {onnx_py_time:.2f}s\")\n",
    "\n",
    "    # 6. Load Predictions: ONNX Runtime (Node.js)\n",
    "    print(f\"Loading predictions from Node.js ONNX run ({PREDICTIONS_JS_PATH})...\")\n",
    "    y_pred_onnx_js = None\n",
    "    try:\n",
    "        with open(PREDICTIONS_JS_PATH, 'r') as f: y_pred_onnx_js = np.array(json.load(f))\n",
    "        if len(y_pred_onnx_js) != len(y_test_np): raise ValueError(\"Length mismatch\")\n",
    "        print(f\"Loaded {len(y_pred_onnx_js)} Node.js predictions.\")\n",
    "    except Exception as e: print(f\"Error loading Node.js predictions: {e}\")\n",
    "\n",
    "    # 7. Load Predictions: ONNX Runtime (Browser/Web)\n",
    "    print(f\"Loading predictions from Browser ONNX run ({PREDICTIONS_BROWSER_PATH})...\")\n",
    "    y_pred_onnx_browser = None\n",
    "    try:\n",
    "        with open(PREDICTIONS_BROWSER_PATH, 'r') as f: y_pred_onnx_browser = np.array(json.load(f))\n",
    "        if len(y_pred_onnx_browser) != len(y_test_np): raise ValueError(\"Length mismatch\")\n",
    "        print(f\"Loaded {len(y_pred_onnx_browser)} Browser predictions.\")\n",
    "    except Exception as e: print(f\"Error loading Browser predictions: {e}\")\n",
    "\n",
    "\n",
    "    # 8. Get Predictions: Live API (FastAPI)\n",
    "    print(f\"Generating predictions via Live API ({API_ENDPOINT_URL})...\")\n",
    "    y_pred_api_list = []\n",
    "    api_errors = 0\n",
    "    start_time = time.time()\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "    for i in range(len(X_test)): # Trial: \n",
    "        # Convert row to dictionary suitable for JSON payload\n",
    "        # Ensure keys match exactly what your API expects\n",
    "        payload = X_test.iloc[i].to_dict()\n",
    "        # Convert numpy types (like int64) to standard Python types for JSON\n",
    "        for key, value in payload.items():\n",
    "            if isinstance(value, np.integer):\n",
    "                payload[key] = int(value)\n",
    "            elif isinstance(value, np.floating):\n",
    "                payload[key] = float(value)\n",
    "            # Add other type conversions if necessary\n",
    "\n",
    "        try:\n",
    "            response = requests.post(API_ENDPOINT_URL, headers=headers, json=payload, timeout=30) # Added timeout\n",
    "            response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "\n",
    "            data = response.json()\n",
    "            # --- Adjust this line based on the exact key in your API response ---\n",
    "            predicted_price = data.get('predictedPrice')\n",
    "            if predicted_price is None:\n",
    "                 print(f\"Warning: 'predictedPrice' key not found in API response for row {i}. Response: {data}\")\n",
    "                 predicted_price = np.nan # Use NaN for missing predictions\n",
    "                 api_errors += 1\n",
    "            # --- End of adjustment ---\n",
    "            y_pred_api_list.append(float(predicted_price)) # Ensure it's float\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error calling API for row {i}: {e}\")\n",
    "            y_pred_api_list.append(np.nan) # Append NaN on error\n",
    "            api_errors += 1\n",
    "        except Exception as e: # Catch other potential errors like JSON parsing\n",
    "             print(f\"Non-request error processing API response for row {i}: {e}\")\n",
    "             y_pred_api_list.append(np.nan)\n",
    "             api_errors += 1\n",
    "\n",
    "\n",
    "        if (i + 1) % 50 == 0: # Log progress less frequently due to delay\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"  Processed {i + 1} / {len(X_test)} samples via API... (Errors: {api_errors}, Time: {elapsed:.1f}s)\")\n",
    "\n",
    "        # --- Add delay ---\n",
    "        time.sleep(API_REQUEST_DELAY)\n",
    "\n",
    "    y_pred_api = np.array(y_pred_api_list)\n",
    "    api_time = time.time() - start_time\n",
    "    print(f\"API prediction finished. Total time: {api_time:.2f}s. Errors encountered: {api_errors}\")\n",
    "    # Handle potential NaNs if errors occurred\n",
    "    valid_api_preds = ~np.isnan(y_pred_api)\n",
    "\n",
    "\n",
    "    # 9. Calculate Error Arrays and R2 Scores\n",
    "    print(\"\\n--- Calculating Errors and R2 Scores ---\")\n",
    "    results = {}\n",
    "    denominator =  y_test_np + 1e-10 # np.where(y_test_np == 0, 1, y_test_np)\n",
    "\n",
    "    # Scikit-learn\n",
    "    ae_skl = np.abs(y_test_np - y_pred_skl); ape_skl = np.abs((y_test_np - y_pred_skl) / denominator) * 100; r2_skl = r2_score(y_test_np, y_pred_skl)\n",
    "    results[\"SKL_Python\"] = {\"AE\": ae_skl, \"APE\": ape_skl, \"R2\": r2_skl}\n",
    "    print(f\"SKL Python R2: {r2_skl:.6f}\")\n",
    "\n",
    "    # ONNX Python\n",
    "    ae_onnx_py = np.abs(y_test_np - y_pred_onnx_py); ape_onnx_py = np.abs((y_test_np - y_pred_onnx_py) / denominator) * 100; r2_onnx_py = r2_score(y_test_np, y_pred_onnx_py)\n",
    "    results[\"ONNX_Python\"] = {\"AE\": ae_onnx_py, \"APE\": ape_onnx_py, \"R2\": r2_onnx_py}\n",
    "    print(f\"ONNX Python R2: {r2_onnx_py:.6f}\")\n",
    "\n",
    "    # ONNX Node.js\n",
    "    if y_pred_onnx_js is not None:\n",
    "        ae_onnx_js = np.abs(y_test_np - y_pred_onnx_js); ape_onnx_js = np.abs((y_test_np - y_pred_onnx_js) / denominator) * 100; r2_onnx_js = r2_score(y_test_np, y_pred_onnx_js)\n",
    "        results[\"ONNX_JS\"] = {\"AE\": ae_onnx_js, \"APE\": ape_onnx_js, \"R2\": r2_onnx_js}\n",
    "        print(f\"ONNX JS R2:    {r2_onnx_js:.6f}\")\n",
    "    else: print(\"ONNX JS R2:    N/A\")\n",
    "\n",
    "    # ONNX Browser\n",
    "    if y_pred_onnx_browser is not None:\n",
    "        ae_onnx_browser = np.abs(y_test_np - y_pred_onnx_browser); ape_onnx_browser = np.abs((y_test_np - y_pred_onnx_browser) / denominator) * 100; r2_onnx_browser = r2_score(y_test_np, y_pred_onnx_browser)\n",
    "        results[\"ONNX_Browser\"] = {\"AE\": ae_onnx_browser, \"APE\": ape_onnx_browser, \"R2\": r2_onnx_browser}\n",
    "        print(f\"ONNX Browser R2:{r2_onnx_browser:.6f}\")\n",
    "    else: print(\"ONNX Browser R2:N/A\")\n",
    "\n",
    "    # Live API\n",
    "    if api_errors < len(X_test): # Only calculate if we got at least some valid predictions\n",
    "        # Filter y_test and predictions to only include valid API results\n",
    "        y_test_filt = y_test_np[valid_api_preds]\n",
    "        y_pred_api_filt = y_pred_api[valid_api_preds]\n",
    "        denominator_filt = np.where(y_test_filt == 0, 1, y_test_filt)\n",
    "\n",
    "        ae_api = np.abs(y_test_filt - y_pred_api_filt)\n",
    "        ape_api = np.abs((y_test_filt - y_pred_api_filt) / denominator_filt) * 100\n",
    "        r2_api = r2_score(y_test_filt, y_pred_api_filt)\n",
    "        # Store the *filtered* error arrays for describe()\n",
    "        results[\"API_FastAPI\"] = {\"AE\": ae_api, \"APE\": ape_api, \"R2\": r2_api}\n",
    "        print(f\"API FastAPI R2: {r2_api:.6f} (calculated on {len(y_test_filt)} valid responses)\")\n",
    "    else:\n",
    "        print(f\"API FastAPI R2: N/A (No valid responses received)\")\n",
    "        results[\"API_FastAPI\"] = {\"AE\": np.array([]), \"APE\": np.array([]), \"R2\": \"N/A\"}\n",
    "\n",
    "\n",
    "    # 10. Analyze Error Distributions using Pandas describe()\n",
    "    print(\"\\n--- Error Distribution Analysis ---\")\n",
    "    pd.set_option('display.float_format', '{:,.4f}'.format)\n",
    "\n",
    "    for method, data in results.items():\n",
    "        print(f\"\\n--- {method} ---\")\n",
    "        r2_val = data['R2']\n",
    "        print(f\"R2 Score: {r2_val:.6f}\" if isinstance(r2_val, float) else f\"R2 Score: {r2_val}\")\n",
    "\n",
    "        if len(data[\"AE\"]) > 0: # Check if there are errors to describe\n",
    "            ae_series = pd.Series(data[\"AE\"])\n",
    "            print(\"\\nAbsolute Error (AE) Distribution:\")\n",
    "            print(ae_series.describe(percentiles=[.25, .5, .75, .9, .95, .99]))\n",
    "\n",
    "            ape_series = pd.Series(data[\"APE\"])\n",
    "            print(\"\\nAbsolute Percentage Error (APE) Distribution (%):\")\n",
    "            print(ape_series.describe(percentiles=[.25, .5, .75, .9, .95, .99]))\n",
    "        else:\n",
    "            print(\"\\nError distributions: N/A (No valid predictions)\")\n",
    "\n",
    "\n",
    "    # 11. Analyze Prediction Differences\n",
    "    print(\"\\n--- Prediction Differences Distribution ---\")\n",
    "    # (Keep the difference calculations as before, adding comparisons with API results)\n",
    "\n",
    "    print(\"\\nSKL vs ONNX-Py Difference:\")\n",
    "    diff_skl_onnxpy = np.abs(y_pred_skl - y_pred_onnx_py)\n",
    "    print(pd.Series(diff_skl_onnxpy).describe(percentiles=[.5, .75, .95, .99, 1.0]))\n",
    "\n",
    "    if y_pred_onnx_js is not None:\n",
    "        print(\"\\nSKL vs ONNX-JS Difference:\")\n",
    "        diff_skl_onnxjs = np.abs(y_pred_skl - y_pred_onnx_js)\n",
    "        print(pd.Series(diff_skl_onnxjs).describe(percentiles=[.5, .75, .95, .99, 1.0]))\n",
    "\n",
    "    if y_pred_onnx_browser is not None:\n",
    "         print(\"\\nSKL vs ONNX-Browser Difference:\")\n",
    "         diff_skl_onnxbrowser = np.abs(y_pred_skl - y_pred_onnx_browser)\n",
    "         print(pd.Series(diff_skl_onnxbrowser).describe(percentiles=[.5, .75, .95, .99, 1.0]))\n",
    "\n",
    "    # Add comparisons involving the API, only if valid API predictions exist\n",
    "    if api_errors < len(X_test):\n",
    "        print(\"\\nSKL vs API-FastAPI Difference (on valid API responses):\")\n",
    "        # Compare only where API predictions were valid\n",
    "        diff_skl_api = np.abs(y_pred_skl[valid_api_preds] - y_pred_api_filt)\n",
    "        print(pd.Series(diff_skl_api).describe(percentiles=[.5, .75, .95, .99, 1.0]))\n",
    "\n",
    "        if y_pred_onnx_browser is not None:\n",
    "             print(\"\\nONNX-Browser vs API-FastAPI Difference (on valid API responses):\")\n",
    "             diff_browser_api = np.abs(y_pred_onnx_browser[valid_api_preds] - y_pred_api_filt)\n",
    "             print(pd.Series(diff_browser_api).describe(percentiles=[.5, .75, .95, .99, 1.0]))\n",
    "\n",
    "\n",
    "    print(\"\\nComparison finished.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd9eb64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SKL_static</th>\n",
       "      <th>API</th>\n",
       "      <th>ONNX_Browser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>13690255</td>\n",
       "      <td>13690255</td>\n",
       "      <td>13690261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>6785827</td>\n",
       "      <td>6785827</td>\n",
       "      <td>6785828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>2671554</td>\n",
       "      <td>2671554</td>\n",
       "      <td>2671555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>5171097</td>\n",
       "      <td>5171097</td>\n",
       "      <td>5171096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>3831198</td>\n",
       "      <td>3831198</td>\n",
       "      <td>3831198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>19916934</td>\n",
       "      <td>19916934</td>\n",
       "      <td>19916936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>12870733</td>\n",
       "      <td>12870733</td>\n",
       "      <td>12870742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>12583945</td>\n",
       "      <td>12583945</td>\n",
       "      <td>12583959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5712248</td>\n",
       "      <td>5712248</td>\n",
       "      <td>5712245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>8265650</td>\n",
       "      <td>8265650</td>\n",
       "      <td>8265650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SKL_static       API  ONNX_Browser\n",
       "299    13690255  13690255      13690261\n",
       "47      6785827   6785827       6785828\n",
       "444     2671554   2671554       2671555\n",
       "233     5171097   5171097       5171096\n",
       "96      3831198   3831198       3831198\n",
       "312    19916934  19916934      19916936\n",
       "82     12870733  12870733      12870742\n",
       "326    12583945  12583945      12583959\n",
       "53      5712248   5712248       5712245\n",
       "219     8265650   8265650       8265650"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare = pd.DataFrame(\n",
    "    {\n",
    "        'SKL_static': y_pred_skl[:500],\n",
    "        'API': y_pred_api[:500],\n",
    "        'ONNX_Browser': y_pred_onnx_browser[:500],\n",
    "    }\n",
    ")\n",
    "compare.astype(int).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9d62946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>localityName</th>\n",
       "      <th>Carpet</th>\n",
       "      <th>Floor</th>\n",
       "      <th>Total Floors</th>\n",
       "      <th>Type</th>\n",
       "      <th>furnished</th>\n",
       "      <th>Bed</th>\n",
       "      <th>Bath</th>\n",
       "      <th>ageofcons</th>\n",
       "      <th>SKL_static</th>\n",
       "      <th>API</th>\n",
       "      <th>ONNX_Browser</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Sanaswadi</td>\n",
       "      <td>463</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>New Construction</td>\n",
       "      <td>4622269</td>\n",
       "      <td>4622269</td>\n",
       "      <td>4622273</td>\n",
       "      <td>2000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Chinchwad, Pimpri Chinchwad</td>\n",
       "      <td>1239</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Less than 5 years</td>\n",
       "      <td>19075604</td>\n",
       "      <td>19075604</td>\n",
       "      <td>19075594</td>\n",
       "      <td>14000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>Wagholi</td>\n",
       "      <td>750</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Less than 5 years</td>\n",
       "      <td>5920278</td>\n",
       "      <td>5920278</td>\n",
       "      <td>5920280</td>\n",
       "      <td>7200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Hinjewadi</td>\n",
       "      <td>820</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Semi-Furnished</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Less than 5 years</td>\n",
       "      <td>8663022</td>\n",
       "      <td>8663022</td>\n",
       "      <td>8663027</td>\n",
       "      <td>8000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>Pimple Saudagar, Pimpri Chinchwad</td>\n",
       "      <td>760</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5 to 10 years</td>\n",
       "      <td>7875847</td>\n",
       "      <td>7875847</td>\n",
       "      <td>7875849</td>\n",
       "      <td>8500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Balewadi</td>\n",
       "      <td>889</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>New Property</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>New Construction</td>\n",
       "      <td>12332701</td>\n",
       "      <td>12332701</td>\n",
       "      <td>12332716</td>\n",
       "      <td>9700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NIBM Road</td>\n",
       "      <td>1900</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Furnished</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5 to 10 years</td>\n",
       "      <td>22808589</td>\n",
       "      <td>22808589</td>\n",
       "      <td>22808598</td>\n",
       "      <td>23000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>Mohamadwadi Settlement</td>\n",
       "      <td>2200</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>New Property</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Less than 5 years</td>\n",
       "      <td>33829752</td>\n",
       "      <td>33829752</td>\n",
       "      <td>33829728</td>\n",
       "      <td>28060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>Keshav Nagar Mundhwa</td>\n",
       "      <td>1100</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>New Property</td>\n",
       "      <td>Semi-Furnished</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>New Construction</td>\n",
       "      <td>11803099</td>\n",
       "      <td>11803099</td>\n",
       "      <td>11803113</td>\n",
       "      <td>11550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>Hadapsar</td>\n",
       "      <td>730</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>New Construction</td>\n",
       "      <td>9220459</td>\n",
       "      <td>9220459</td>\n",
       "      <td>9220469</td>\n",
       "      <td>8000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          localityName  Carpet  Floor  Total Floors  \\\n",
       "54                           Sanaswadi     463      4             4   \n",
       "191        Chinchwad, Pimpri Chinchwad    1239     12            22   \n",
       "280                            Wagholi     750     10            14   \n",
       "160                          Hinjewadi     820      8            21   \n",
       "330  Pimple Saudagar, Pimpri Chinchwad     760      7             7   \n",
       "196                           Balewadi     889      2            22   \n",
       "34                           NIBM Road    1900      9            12   \n",
       "355             Mohamadwadi Settlement    2200     22            25   \n",
       "468               Keshav Nagar Mundhwa    1100     14            22   \n",
       "436                           Hadapsar     730     12            22   \n",
       "\n",
       "             Type       furnished  Bed  Bath          ageofcons  SKL_static  \\\n",
       "54         Resale     Unfurnished    2     2   New Construction     4622269   \n",
       "191        Resale     Unfurnished    3     3  Less than 5 years    19075604   \n",
       "280        Resale     Unfurnished    2     2  Less than 5 years     5920278   \n",
       "160        Resale  Semi-Furnished    2     2  Less than 5 years     8663022   \n",
       "330        Resale     Unfurnished    2     2      5 to 10 years     7875847   \n",
       "196  New Property     Unfurnished    2     2   New Construction    12332701   \n",
       "34         Resale       Furnished    3     4      5 to 10 years    22808589   \n",
       "355  New Property     Unfurnished    4     4  Less than 5 years    33829752   \n",
       "468  New Property  Semi-Furnished    3     3   New Construction    11803099   \n",
       "436        Resale     Unfurnished    2     2   New Construction     9220459   \n",
       "\n",
       "          API  ONNX_Browser     price  \n",
       "54    4622269       4622273   2000000  \n",
       "191  19075604      19075594  14000000  \n",
       "280   5920278       5920280   7200000  \n",
       "160   8663022       8663027   8000000  \n",
       "330   7875847       7875849   8500000  \n",
       "196  12332701      12332716   9700000  \n",
       "34   22808589      22808598  23000000  \n",
       "355  33829752      33829728  28060000  \n",
       "468  11803099      11803113  11550000  \n",
       "436   9220459       9220469   8000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([X_test[:500], compare.astype(int), df_test.reset_index()[:500][['price']]], axis=1).sample(10).rename(columns={\n",
    "    'totalFloorNumber': 'Total Floors',\n",
    "    'bedrooms': 'Bed',\n",
    "    'bathrooms': 'Bath',\n",
    "    'carpetArea': 'Carpet',\n",
    "    'floorNumber': 'Floor',\n",
    "    'transactionType': 'Type',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "885b75f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>localityName</th>\n",
       "      <th>price</th>\n",
       "      <th>carpetArea</th>\n",
       "      <th>floorNumber</th>\n",
       "      <th>totalFloorNumber</th>\n",
       "      <th>transactionType</th>\n",
       "      <th>furnished</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>ageofcons</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>propertyId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75987143</th>\n",
       "      <td>Bavdhan</td>\n",
       "      <td>11800000</td>\n",
       "      <td>1266</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Less than 5 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75092669</th>\n",
       "      <td>Kondhwa</td>\n",
       "      <td>9500000</td>\n",
       "      <td>1200</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Semi-Furnished</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5 to 10 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74846961</th>\n",
       "      <td>Punawale, Pimpri Chinchwad</td>\n",
       "      <td>6100000</td>\n",
       "      <td>776</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>New Property</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Under Construction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75676635</th>\n",
       "      <td>Camp</td>\n",
       "      <td>14000000</td>\n",
       "      <td>864</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Semi-Furnished</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Above 20 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77813777</th>\n",
       "      <td>Wakad</td>\n",
       "      <td>12500000</td>\n",
       "      <td>1150</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5 to 10 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75656955</th>\n",
       "      <td>Ambegaon</td>\n",
       "      <td>4500000</td>\n",
       "      <td>593</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Less than 5 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75692129</th>\n",
       "      <td>Tathawade Pimpri Chinchwad</td>\n",
       "      <td>4500000</td>\n",
       "      <td>495</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Semi-Furnished</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Less than 5 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75657785</th>\n",
       "      <td>Narhe</td>\n",
       "      <td>4500000</td>\n",
       "      <td>644</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Semi-Furnished</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5 to 10 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72574395</th>\n",
       "      <td>Hinjewadi</td>\n",
       "      <td>6050000</td>\n",
       "      <td>657</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Semi-Furnished</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Less than 5 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68600165</th>\n",
       "      <td>Punawale, Pimpri Chinchwad</td>\n",
       "      <td>6500000</td>\n",
       "      <td>700</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>New Construction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          localityName     price  carpetArea  floorNumber  \\\n",
       "propertyId                                                                  \n",
       "75987143                       Bavdhan  11800000        1266           10   \n",
       "75092669                       Kondhwa   9500000        1200            4   \n",
       "74846961    Punawale, Pimpri Chinchwad   6100000         776            9   \n",
       "75676635                          Camp  14000000         864            2   \n",
       "77813777                         Wakad  12500000        1150            1   \n",
       "...                                ...       ...         ...          ...   \n",
       "75656955                      Ambegaon   4500000         593            2   \n",
       "75692129    Tathawade Pimpri Chinchwad   4500000         495            3   \n",
       "75657785                         Narhe   4500000         644            1   \n",
       "72574395                     Hinjewadi   6050000         657           10   \n",
       "68600165    Punawale, Pimpri Chinchwad   6500000         700            6   \n",
       "\n",
       "            totalFloorNumber transactionType       furnished  bedrooms  \\\n",
       "propertyId                                                               \n",
       "75987143                  12          Resale     Unfurnished         3   \n",
       "75092669                   7          Resale  Semi-Furnished         3   \n",
       "74846961                  24    New Property     Unfurnished         2   \n",
       "75676635                   3          Resale  Semi-Furnished         3   \n",
       "77813777                   6          Resale     Unfurnished         3   \n",
       "...                      ...             ...             ...       ...   \n",
       "75656955                   5          Resale     Unfurnished         2   \n",
       "75692129                   4          Resale  Semi-Furnished         1   \n",
       "75657785                   5          Resale  Semi-Furnished         2   \n",
       "72574395                  22          Resale  Semi-Furnished         2   \n",
       "68600165                  14          Resale     Unfurnished         2   \n",
       "\n",
       "            bathrooms           ageofcons  \n",
       "propertyId                                 \n",
       "75987143            3   Less than 5 years  \n",
       "75092669            3       5 to 10 years  \n",
       "74846961            2  Under Construction  \n",
       "75676635            3      Above 20 years  \n",
       "77813777            3       5 to 10 years  \n",
       "...               ...                 ...  \n",
       "75656955            2   Less than 5 years  \n",
       "75692129            2   Less than 5 years  \n",
       "75657785            2       5 to 10 years  \n",
       "72574395            2   Less than 5 years  \n",
       "68600165            2    New Construction  \n",
       "\n",
       "[500 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[:500]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
