<!DOCTYPE html>
<html>
<head>
    <title>ONNX Web Inference</title>
    <!-- Ensure this path is correct relative to where inference_page.html is -->
    <script src="./node_modules/onnxruntime-web/dist/ort.min.js"></script>
    <style>
        body { font-family: sans-serif; }
        #status { margin-top: 1em; font-weight: bold; }
    </style>
</head>
<body>
    <h1>ONNX Runtime Web Inference Test</h1>
    <div id="status">Initializing...</div>

    <script>
        const statusDiv = document.getElementById('status');
        let session = null;
        // Ensure this path is correct relative to inference_page.html
        const modelPath = './full_pipeline_lgbm_pune_prices.onnx';

        // Function called by Selenium to run inference
        async function runInferenceInBrowser(testData) {
            statusDiv.textContent = 'Loading model...';
            console.log('Browser: Loading model', modelPath);

            try {
                // --- REMOVED or COMMENTED OUT this line ---
                // ort.env.wasm.wasmPaths = './node_modules/onnxruntime-web/dist/';
                // --- Let ORT try to find WASM files automatically relative to ort.min.js ---

                session = await ort.InferenceSession.create(modelPath, {
                    executionProviders: ['wasm'] // Use WASM
                });
                statusDiv.textContent = `Model loaded. Processing ${testData.length} samples...`;
                console.log('Browser: Model loaded successfully.');

                // ... (rest of the inference loop remains the same) ...
                const predictions = [];
                const outputName = session.outputNames[0];

                for (let i = 0; i < testData.length; i++) {
                    const row = testData[i];
                    const inputTensor = { /* ... tensor creation ... */
                        localityName: new ort.Tensor("string", [row.localityName], [1, 1]),
                        carpetArea: new ort.Tensor("int64", [BigInt(row.carpetArea)], [1, 1]),
                        floorNumber: new ort.Tensor("int64", [BigInt(row.floorNumber)], [1, 1]),
                        totalFloorNumber: new ort.Tensor("int64", [BigInt(row.totalFloorNumber)], [1, 1]),
                        transactionType: new ort.Tensor("string", [row.transactionType], [1, 1]),
                        furnished: new ort.Tensor("string", [row.furnished], [1, 1]),
                        bedrooms: new ort.Tensor("int64", [BigInt(row.bedrooms)], [1, 1]),
                        bathrooms: new ort.Tensor("int64", [BigInt(row.bathrooms)], [1, 1]),
                        ageofcons: new ort.Tensor("string", [row.ageofcons], [1, 1]),
                    };
                    const results = await session.run(inputTensor);
                    const prediction = results[outputName].data[0];
                    predictions.push(prediction);
                    if ((i + 1) % 100 === 0) { /* ... progress logging ... */ }
                }
                // ... (rest of the function remains the same) ...
                statusDiv.textContent = 'Inference complete.';
                console.log('Browser: Inference complete.');
                return predictions;

            } catch (error) {
                statusDiv.textContent = `Error: ${error.message}`;
                console.error('Browser: Error during inference:', error);
                return { error: error.message, stack: error.stack };
            }
        }
        statusDiv.textContent = 'Ready for data.';
        console.log('Browser: Page loaded, ready for data.');
    </script>
</body>
</html>
