{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13950fdc",
   "metadata": {},
   "source": [
    "# Imports and Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca6cac49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Null values:  localityName           0\n",
      "price                  0\n",
      "carpetArea          3764\n",
      "floorNumber            0\n",
      "totalFloorNumber       0\n",
      "transactionType        0\n",
      "furnished             37\n",
      "bedrooms               0\n",
      "bathrooms              0\n",
      "ageofcons           2571\n",
      "dtype: int64 \n",
      "\n",
      "Test Set Null values:  localityName          0\n",
      "price                 0\n",
      "carpetArea          977\n",
      "floorNumber           0\n",
      "totalFloorNumber      0\n",
      "transactionType       0\n",
      "furnished            14\n",
      "bedrooms              0\n",
      "bathrooms             0\n",
      "ageofcons           693\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "# from ydata_profiling import ProfileReport\n",
    "import numpy as np\n",
    "\n",
    "dtype_mapping = {\n",
    "    'propertyId': pd.StringDtype(),\n",
    "    'localityName': 'category',\n",
    "    'landMarks': pd.StringDtype(),\n",
    "    'locality': pd.StringDtype(),\n",
    "    'price': pd.Int64Dtype(),\n",
    "    'nameOfSociety': pd.StringDtype(),\n",
    "    'projectName': pd.StringDtype(),\n",
    "    'carpetArea': pd.Int64Dtype(),\n",
    "    'coveredArea': pd.Int64Dtype(),\n",
    "    'carpetAreaSqft': pd.Int64Dtype(),\n",
    "    'possessionStatus': pd.StringDtype(),\n",
    "    'developerName': pd.StringDtype(),\n",
    "    'flooringType': pd.StringDtype(),\n",
    "    'floorNumber': pd.Int64Dtype(),\n",
    "    'unitCountonFloor': pd.Int64Dtype(),\n",
    "    'totalFloorNumber': pd.Int64Dtype(),\n",
    "    'electricityStatus': pd.StringDtype(),\n",
    "    'waterStatus': pd.StringDtype(),\n",
    "    'longitude': pd.Float64Dtype(),\n",
    "    'latitude': pd.Float64Dtype(),\n",
    "    'transactionType': 'category',\n",
    "    'facing': pd.StringDtype(),\n",
    "    'ownershipType': pd.StringDtype(),\n",
    "    'carParking': pd.StringDtype(),\n",
    "    'furnished': 'category',\n",
    "    'bedrooms': pd.Int64Dtype(),\n",
    "    'bathrooms': pd.Int64Dtype(),\n",
    "    'numberOfBalconied': pd.Int64Dtype(),\n",
    "    'propertyType': 'category',\n",
    "    'additionalRooms': pd.StringDtype(),\n",
    "    'bookingAmountExact': pd.Int64Dtype(),\n",
    "    'maintenanceChargesFrequency': 'category',\n",
    "    'maintenanceCharges': pd.Int64Dtype(),\n",
    "    'ageofcons': 'category',\n",
    "    'isVerified': 'category',\n",
    "    'listingTypeDesc': 'category',\n",
    "    'premiumProperty': pd.BooleanDtype(),\n",
    "    'noOfLifts': pd.Int64Dtype(),\n",
    "    'propertyAmenities': pd.StringDtype(),\n",
    "    'facilitiesDesc': pd.StringDtype(),\n",
    "    'uuid': pd.StringDtype(),\n",
    "    'flooringType_Vitrified': pd.BooleanDtype(),\n",
    "    'flooringType_CeramicTiles': pd.BooleanDtype(),\n",
    "    'flooringType_Marble': pd.BooleanDtype(),\n",
    "    'flooringType_NormalTilesKotahStone': pd.BooleanDtype(),\n",
    "    'flooringType_Granite': pd.BooleanDtype(),\n",
    "    'flooringType_Wooden': pd.BooleanDtype(),\n",
    "    'flooringType_Mosaic': pd.BooleanDtype(),\n",
    "    'flooringType_Marbonite': pd.BooleanDtype(),\n",
    "    'additionalRoom_PujaRoom': pd.BooleanDtype(),\n",
    "    'additionalRoom_Study': pd.BooleanDtype(),\n",
    "    'additionalRoom_Store': pd.BooleanDtype(),\n",
    "    'additionalRoom_ServantRoom': pd.BooleanDtype(),\n",
    "    'carParking_Open': pd.Int64Dtype(),\n",
    "    'carParking_Covered': pd.Int64Dtype(),\n",
    "    'ReservedParking': pd.BooleanDtype(),\n",
    "}\n",
    "\n",
    "COLUMNS_TO_DROP = [\n",
    "    'coveredArea',\n",
    "    'ReservedParking',\n",
    "] + [\n",
    "        'unitCountonFloor',\n",
    "        'electricityStatus',\n",
    "        'waterStatus',\n",
    "        'facing',\n",
    "        'bookingAmountExact',\n",
    "        'isVerified',\n",
    "        'listingTypeDesc',\n",
    "        'maintenanceCharges',\n",
    "        'maintenanceChargesFrequency',\n",
    "        'latitude',\n",
    "        'longitude',\n",
    "        'carParking_Open',\n",
    "        'carParking_Covered',\n",
    "        'numberOfBalconied',\n",
    "        'premiumProperty',\n",
    "        'projectName',\n",
    "        'nameOfSociety',\n",
    "        'url',\n",
    "        # 'uuid',\n",
    "        'carpetAreaSqft',\n",
    "        'noOfLifts',\n",
    "        'ownershipType',\n",
    "        'possessionStatus',\n",
    "        'propertyType',\n",
    "\n",
    "        'flooringType_Vitrified',\n",
    "        'flooringType_CeramicTiles',\n",
    "        'flooringType_Marble',\n",
    "        'flooringType_NormalTilesKotahStone',\n",
    "        'flooringType_Granite',\n",
    "        'flooringType_Wooden',\n",
    "        'flooringType_Mosaic',\n",
    "        'flooringType_Marbonite',\n",
    "\n",
    "        'additionalRoom_PujaRoom',\n",
    "        'additionalRoom_Study',\n",
    "        'additionalRoom_Store',\n",
    "        'additionalRoom_ServantRoom',\n",
    "        \n",
    "        'landMarks', \n",
    "        'locality', \n",
    "        'developerName',]\n",
    "\n",
    "################################################################################\n",
    "# ONLY USING THE RAW SETs, NOT IMPUTED SET\n",
    "################################################################################\n",
    "df_train = pd.read_csv(\n",
    "    '../Data/train.csv',\n",
    "    dtype = dtype_mapping,\n",
    "    index_col=0\n",
    ")\n",
    "df_train.drop(COLUMNS_TO_DROP, axis=1, inplace=True)\n",
    "\n",
    "df_test = pd.read_csv(\n",
    "    '../Data/test.csv',\n",
    "    dtype = dtype_mapping,\n",
    "    index_col=0\n",
    ")\n",
    "df_test.drop(COLUMNS_TO_DROP, axis=1, inplace=True)\n",
    "\n",
    "################################################################################\n",
    "# DROPPING ALL ROWS WITH MISSING VALUES\n",
    "################################################################################\n",
    "\n",
    "print(\"Train Set Null values: \", df_train.isna().sum(), '\\n')\n",
    "print(\"Test Set Null values: \", df_test.isna().sum(), '\\n')\n",
    "\n",
    "df_train.dropna(axis=0, inplace=True)\n",
    "df_test.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6b5830",
   "metadata": {},
   "source": [
    "# Python Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdcab94",
   "metadata": {},
   "source": [
    "## Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04111b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "# Assume that df_train and df_test are your already cleaned and imputed datasets.\n",
    "X_train = df_train.drop(\"price\", axis=1)\n",
    "y_train = df_train[\"price\"]\n",
    "\n",
    "# List of numeric features\n",
    "numeric_cols = [\n",
    "    \"carpetArea\",\n",
    "    \"floorNumber\",\n",
    "    \"totalFloorNumber\",\n",
    "    \"bedrooms\",\n",
    "    \"bathrooms\",\n",
    "]\n",
    "\n",
    "# For the two features that will be encoded differently:\n",
    "cat_diff_cols = [\"localityName\", \"transactionType\"]\n",
    "\n",
    "ordinal_cols = [\"furnished\", \"ageofcons\"]\n",
    "\n",
    "furnished_order = ['Unfurnished', 'Semi-Furnished', 'Furnished']\n",
    "ordinal_transformer_furnished = Pipeline(\n",
    "    steps=[\n",
    "        (\"ordinal\", OrdinalEncoder(categories=[furnished_order])),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Here we create a pipeline that first ordinal-encodes then scales the result.\n",
    "age_order = [\n",
    "    'Under Construction',  # first: youngest / newest state\n",
    "    'New Construction',\n",
    "    'Less than 5 years',\n",
    "    '5 to 10 years',\n",
    "    '10 to 15 years',\n",
    "    '15 to 20 years',\n",
    "    'Above 20 years'       # last: oldest\n",
    "]\n",
    "ordinal_transformer_ageofcons = Pipeline(\n",
    "    steps=[\n",
    "        (\"ordinal\", OrdinalEncoder(categories=[age_order])),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c9f1d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_preprocessor_gb = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_cols),\n",
    "        (\"passthrough\", \"passthrough\", cat_diff_cols),\n",
    "        (\"ord-furnished\", ordinal_transformer_furnished, [\"furnished\"]),\n",
    "        # (\"ord-reservedparking\", ordinal_transformer_rs, [\"ReservedParking\"]),\n",
    "        (\"ord-ageofcons\", ordinal_transformer_ageofcons, [\"ageofcons\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tree_pipeline_gb = Pipeline(steps=[(\"preprocessor\", tree_preprocessor_gb)])\n",
    "# Now transform the training features for the tree models:\n",
    "X_train_gb = tree_pipeline_gb.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee111a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test features saved to test_data_x.json\n",
      "Test target shape: (3469,)\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have df_test loaded and cleaned similarly to df_train\n",
    "# Make sure it has the same columns as the original X_train before preprocessing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# --- Configuration ---\n",
    "TEST_DATA_JSON_PATH = \"test_data_x.json\"\n",
    "PREDICTIONS_JS_PATH = \"onnx_js_predictions.json\"\n",
    "PIPELINE_PATH = \"../PipelinesAndModels/full_pipeline_lgbm_pune_prices.pkl\" # Assuming you saved the fitted pipeline\n",
    "ONNX_MODEL_PATH = \"../PipelinesAndModels/full_pipeline_lgbm_pune_prices.onnx\"\n",
    "\n",
    "X_test = df_test.drop(\"price\", axis=1)\n",
    "y_test = df_test[\"price\"].astype(float) # Ensure y_test is float for metrics\n",
    "\n",
    "# --- Save X_test to JSON for Node.js ---\n",
    "# Convert categoricals to strings for JSON compatibility\n",
    "X_test_json = X_test.copy()\n",
    "for col in X_test_json.select_dtypes(include='category').columns:\n",
    "     X_test_json[col] = X_test_json[col].astype(str)\n",
    "\n",
    "# Use 'records' orientation for an array of objects\n",
    "X_test_json.to_json(TEST_DATA_JSON_PATH, orient='records', indent=4)\n",
    "\n",
    "print(f\"Test features saved to {TEST_DATA_JSON_PATH}\")\n",
    "print(f\"Test target shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d8f80a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05594b79",
   "metadata": {},
   "source": [
    "# Web ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec075d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Selenium ONNX Runtime Web prediction...\n",
      "Serving HTTP on http://localhost:8008/ from directory '.'...\n",
      "Loading test data from test_data_x.json...\n",
      "Loaded 3469 test samples.\n",
      "Setting up Chrome WebDriver...\n",
      "WebDriver initialized.\n",
      "Navigating to http://localhost:8008/inference_page.html...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Apr/2025 18:35:06] \"GET /inference_page.html HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Apr/2025 18:35:06] \"GET /node_modules/onnxruntime-web/dist/ort.min.js HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML page loaded and initial JS ready.\n",
      "Executing inference function in browser...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Apr/2025 18:35:06] code 404, message File not found\n",
      "127.0.0.1 - - [23/Apr/2025 18:35:06] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [23/Apr/2025 18:35:06] \"GET /node_modules/onnxruntime-web/dist/ort-wasm-simd-threaded.jsep.mjs HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Apr/2025 18:35:07] \"GET /node_modules/onnxruntime-web/dist/ort-wasm-simd-threaded.jsep.wasm HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [23/Apr/2025 18:35:07] \"GET /full_pipeline_lgbm_pune_prices.onnx HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Browser inference execution time: 1.72s\n",
      "Received 3469 predictions back from browser.\n",
      "Saving browser predictions to c:\\Aditya Joshi\\PuneHousePricePrediction\\Stationary\\Iteration_3\\Tests\\onnx_browser_predictions.json...\n",
      "Browser predictions saved successfully.\n",
      "Closing browser...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 58810)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\socketserver.py\", line 318, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\socketserver.py\", line 349, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\socketserver.py\", line 362, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\http\\server.py\", line 672, in __init__\n",
      "    super().__init__(*args, **kwargs)\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\socketserver.py\", line 761, in __init__\n",
      "    self.handle()\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\http\\server.py\", line 436, in handle\n",
      "    self.handle_one_request()\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\http\\server.py\", line 404, in handle_one_request\n",
      "    self.raw_requestline = self.rfile.readline(65537)\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python312\\Lib\\socket.py\", line 707, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Browser closed.\n",
      "Shutting down HTTP server...\n",
      "HTTP server stopped.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import http.server\n",
    "import socketserver\n",
    "import threading # To run the server in the background\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "# from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# --- Configuration ---\n",
    "TEST_DATA_JSON_PATH = \"test_data_x.json\"\n",
    "PREDICTIONS_BROWSER_PATH = \"onnx_browser_predictions.json\"\n",
    "HTML_PAGE_FILENAME = \"inference_page.html\"\n",
    "SERVER_PORT = 8008 # Choose an available port\n",
    "SERVER_ADDRESS = \"localhost\"\n",
    "\n",
    "# --- Simple HTTP Server Setup ---\n",
    "class Handler(http.server.SimpleHTTPRequestHandler):\n",
    "    # Optional: Prevent caching to ensure fresh loads during testing\n",
    "    def end_headers(self):\n",
    "        self.send_header('Cache-Control', 'no-store, no-cache, must-revalidate')\n",
    "        self.send_header('Pragma', 'no-cache')\n",
    "        self.send_header('Expires', '0')\n",
    "        super().end_headers()\n",
    "\n",
    "def start_http_server(port, directory=\".\"):\n",
    "    \"\"\"Starts a simple HTTP server in a background thread.\"\"\"\n",
    "    os.chdir(directory) # Serve files from the specified directory\n",
    "    httpd = socketserver.TCPServer((\"\", port), Handler)\n",
    "    print(f\"Serving HTTP on http://{SERVER_ADDRESS}:{port}/ from directory '{directory}'...\")\n",
    "    server_thread = threading.Thread(target=httpd.serve_forever, daemon=True)\n",
    "    server_thread.start()\n",
    "    return httpd, server_thread\n",
    "\n",
    "# --- Main Selenium Logic ---\n",
    "def run_selenium_prediction():\n",
    "    print(\"Starting Selenium ONNX Runtime Web prediction...\")\n",
    "    driver = None\n",
    "    httpd = None\n",
    "    server_thread = None\n",
    "    original_cwd = os.getcwd() # Remember original directory\n",
    "\n",
    "    try:\n",
    "        # 0. Start HTTP Server\n",
    "        # Determine the correct directory to serve from. It should be the one\n",
    "        # where relative paths in inference_page.html make sense.\n",
    "        # Assuming the script runs where node_modules and PipelinesAndModels are accessible\n",
    "        # If not, adjust the directory path.\n",
    "        serve_directory = \".\"\n",
    "        httpd, server_thread = start_http_server(SERVER_PORT, serve_directory)\n",
    "        time.sleep(1) # Give server a moment to start\n",
    "\n",
    "        # 1. Load Test Data\n",
    "        print(f\"Loading test data from {TEST_DATA_JSON_PATH}...\")\n",
    "        test_data_path = os.path.join(original_cwd, TEST_DATA_JSON_PATH) # Use absolute path if needed\n",
    "        if not os.path.exists(test_data_path):\n",
    "            raise FileNotFoundError(f\"Test data file not found: {test_data_path}\")\n",
    "        with open(test_data_path, 'r') as f:\n",
    "            test_data = json.load(f)\n",
    "        print(f\"Loaded {len(test_data)} test samples.\")\n",
    "\n",
    "        # 2. Setup Selenium WebDriver\n",
    "        print(\"Setting up Chrome WebDriver...\")\n",
    "        chrome_options = ChromeOptions()\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        chrome_options.add_argument(\"--disable-gpu\")\n",
    "        chrome_options.add_argument(\"--no-sandbox\")\n",
    "        chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        # Optional: Increase timeout if model loading is slow\n",
    "        # chrome_options.page_load_strategy = 'normal' # Default\n",
    "        # service = ChromeService(ChromeDriverManager().install())\n",
    "        driver = webdriver.Chrome(options=chrome_options)\n",
    "        # Set a script timeout in case JS execution hangs\n",
    "        driver.set_script_timeout(120) # 120 seconds, adjust as needed\n",
    "        print(\"WebDriver initialized.\")\n",
    "\n",
    "        # 3. Load the HTML Page via HTTP\n",
    "        page_url = f\"http://{SERVER_ADDRESS}:{SERVER_PORT}/{HTML_PAGE_FILENAME}\"\n",
    "        print(f\"Navigating to {page_url}...\")\n",
    "        driver.get(page_url)\n",
    "        # Wait for the \"Ready for data.\" status, indicating JS has loaded initially\n",
    "        # Using Selenium's explicit waits is more robust than time.sleep\n",
    "        from selenium.webdriver.support.ui import WebDriverWait\n",
    "        from selenium.webdriver.support import expected_conditions as EC\n",
    "        from selenium.webdriver.common.by import By\n",
    "\n",
    "        WebDriverWait(driver, 30).until(\n",
    "            EC.text_to_be_present_in_element((By.ID, 'status'), 'Ready for data.')\n",
    "        )\n",
    "        print(\"HTML page loaded and initial JS ready.\")\n",
    "\n",
    "        # 4. Execute Inference Function in Browser Context\n",
    "        print(\"Executing inference function in browser...\")\n",
    "        start_time = time.time()\n",
    "        js_script = \"return await runInferenceInBrowser(arguments[0]);\"\n",
    "        # Use execute_async_script if the JS function is truly async and long-running,\n",
    "        # but execute_script often works fine if the await resolves within the timeout.\n",
    "        predictions_or_error = driver.execute_script(js_script, test_data)\n",
    "        browser_time = time.time() - start_time\n",
    "        print(f\"Browser inference execution time: {browser_time:.2f}s\")\n",
    "\n",
    "        # 5. Check for Errors returned from JS\n",
    "        if isinstance(predictions_or_error, dict) and 'error' in predictions_or_error:\n",
    "             print(\"Error received from browser JavaScript:\")\n",
    "             print(f\"  Message: {predictions_or_error.get('error')}\")\n",
    "             print(f\"  Stack: {predictions_or_error.get('stack')}\")\n",
    "             raise RuntimeError(\"JavaScript execution failed in browser.\")\n",
    "\n",
    "        if not isinstance(predictions_or_error, list):\n",
    "             raise TypeError(f\"Expected a list of predictions from browser, got: {type(predictions_or_error)}\")\n",
    "\n",
    "        print(f\"Received {len(predictions_or_error)} predictions back from browser.\")\n",
    "\n",
    "        # 6. Save Predictions\n",
    "        output_path = os.path.join(original_cwd, PREDICTIONS_BROWSER_PATH)\n",
    "        print(f\"Saving browser predictions to {output_path}...\")\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(predictions_or_error, f, indent=2)\n",
    "        print(\"Browser predictions saved successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during Selenium browser prediction: {e}\")\n",
    "        raise\n",
    "\n",
    "    finally:\n",
    "        # 7. Close Browser\n",
    "        if driver:\n",
    "            print(\"Closing browser...\")\n",
    "            driver.quit()\n",
    "            print(\"Browser closed.\")\n",
    "        # 8. Stop HTTP Server\n",
    "        if httpd:\n",
    "            print(\"Shutting down HTTP server...\")\n",
    "            httpd.shutdown() # Stop the server loop\n",
    "            httpd.server_close() # Release the port\n",
    "            if server_thread:\n",
    "                server_thread.join(timeout=5) # Wait for thread to finish\n",
    "            print(\"HTTP server stopped.\")\n",
    "        os.chdir(original_cwd) # Change back to original directory\n",
    "\n",
    "\n",
    "run_selenium_prediction()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25de649c",
   "metadata": {},
   "source": [
    "# Comparison: Python vs Node.js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "daee56b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting comparison with detailed error analysis (including API)...\n",
      "Loading test data features from test_data_x.json...\n",
      "Loaded X_test shape: (3469, 9), y_test shape: (3469,)\n",
      "Loading Scikit-learn pipeline from ../PipelinesAndModels/full_pipeline_lgbm_pune_prices.pkl...\n",
      "Pipeline loaded successfully.\n",
      "Loading ONNX model from ../PipelinesAndModels/full_pipeline_lgbm_pune_prices.onnx...\n",
      "Generating predictions with Scikit-learn pipeline...\n",
      "Scikit-learn prediction time: 0.05s\n",
      "Generating predictions with ONNX Runtime (Python)...\n",
      "  Processed 100 / 3469 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Aditya Joshi\\PuneHousePricePrediction\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 200 / 3469 samples...\n",
      "  Processed 300 / 3469 samples...\n",
      "  Processed 400 / 3469 samples...\n",
      "  Processed 500 / 3469 samples...\n",
      "  Processed 600 / 3469 samples...\n",
      "  Processed 700 / 3469 samples...\n",
      "  Processed 800 / 3469 samples...\n",
      "  Processed 900 / 3469 samples...\n",
      "  Processed 1000 / 3469 samples...\n",
      "  Processed 1100 / 3469 samples...\n",
      "  Processed 1200 / 3469 samples...\n",
      "  Processed 1300 / 3469 samples...\n",
      "  Processed 1400 / 3469 samples...\n",
      "  Processed 1500 / 3469 samples...\n",
      "  Processed 1600 / 3469 samples...\n",
      "  Processed 1700 / 3469 samples...\n",
      "  Processed 1800 / 3469 samples...\n",
      "  Processed 1900 / 3469 samples...\n",
      "  Processed 2000 / 3469 samples...\n",
      "  Processed 2100 / 3469 samples...\n",
      "  Processed 2200 / 3469 samples...\n",
      "  Processed 2300 / 3469 samples...\n",
      "  Processed 2400 / 3469 samples...\n",
      "  Processed 2500 / 3469 samples...\n",
      "  Processed 2600 / 3469 samples...\n",
      "  Processed 2700 / 3469 samples...\n",
      "  Processed 2800 / 3469 samples...\n",
      "  Processed 2900 / 3469 samples...\n",
      "  Processed 3000 / 3469 samples...\n",
      "  Processed 3100 / 3469 samples...\n",
      "  Processed 3200 / 3469 samples...\n",
      "  Processed 3300 / 3469 samples...\n",
      "  Processed 3400 / 3469 samples...\n",
      "ONNX (Python) prediction time: 1.65s\n",
      "Loading predictions from Node.js ONNX run (onnx_js_predictions.json)...\n",
      "Loaded 3469 Node.js predictions.\n",
      "Loading predictions from Browser ONNX run (onnx_browser_predictions.json)...\n",
      "Loaded 3469 Browser predictions.\n",
      "Generating predictions via Live API (https://phpp-api.adityajoshi.in/predict)...\n",
      "  Processed 50 / 3469 samples via API... (Errors: 0, Time: 39.2s)\n",
      "  Processed 100 / 3469 samples via API... (Errors: 0, Time: 79.5s)\n",
      "  Processed 150 / 3469 samples via API... (Errors: 0, Time: 119.7s)\n",
      "  Processed 200 / 3469 samples via API... (Errors: 0, Time: 160.0s)\n",
      "  Processed 250 / 3469 samples via API... (Errors: 0, Time: 199.8s)\n",
      "  Processed 300 / 3469 samples via API... (Errors: 0, Time: 239.7s)\n",
      "  Processed 350 / 3469 samples via API... (Errors: 0, Time: 279.7s)\n",
      "  Processed 400 / 3469 samples via API... (Errors: 0, Time: 319.6s)\n",
      "  Processed 450 / 3469 samples via API... (Errors: 0, Time: 359.5s)\n",
      "  Processed 500 / 3469 samples via API... (Errors: 0, Time: 399.9s)\n",
      "  Processed 550 / 3469 samples via API... (Errors: 0, Time: 440.9s)\n",
      "  Processed 600 / 3469 samples via API... (Errors: 0, Time: 480.8s)\n",
      "  Processed 650 / 3469 samples via API... (Errors: 0, Time: 520.7s)\n",
      "  Processed 700 / 3469 samples via API... (Errors: 0, Time: 560.5s)\n",
      "  Processed 750 / 3469 samples via API... (Errors: 0, Time: 600.3s)\n",
      "  Processed 800 / 3469 samples via API... (Errors: 0, Time: 640.1s)\n",
      "  Processed 850 / 3469 samples via API... (Errors: 0, Time: 680.3s)\n",
      "  Processed 900 / 3469 samples via API... (Errors: 0, Time: 720.4s)\n",
      "  Processed 950 / 3469 samples via API... (Errors: 0, Time: 760.7s)\n",
      "  Processed 1000 / 3469 samples via API... (Errors: 0, Time: 800.6s)\n",
      "  Processed 1050 / 3469 samples via API... (Errors: 0, Time: 840.5s)\n",
      "  Processed 1100 / 3469 samples via API... (Errors: 0, Time: 880.5s)\n",
      "  Processed 1150 / 3469 samples via API... (Errors: 0, Time: 920.4s)\n",
      "  Processed 1200 / 3469 samples via API... (Errors: 0, Time: 961.2s)\n",
      "  Processed 1250 / 3469 samples via API... (Errors: 0, Time: 1001.1s)\n",
      "  Processed 1300 / 3469 samples via API... (Errors: 0, Time: 1040.9s)\n",
      "  Processed 1350 / 3469 samples via API... (Errors: 0, Time: 1080.8s)\n",
      "  Processed 1400 / 3469 samples via API... (Errors: 0, Time: 1120.7s)\n",
      "  Processed 1450 / 3469 samples via API... (Errors: 0, Time: 1160.9s)\n",
      "  Processed 1500 / 3469 samples via API... (Errors: 0, Time: 1200.7s)\n",
      "  Processed 1550 / 3469 samples via API... (Errors: 0, Time: 1240.5s)\n",
      "  Processed 1600 / 3469 samples via API... (Errors: 0, Time: 1280.3s)\n",
      "  Processed 1650 / 3469 samples via API... (Errors: 0, Time: 1320.4s)\n",
      "  Processed 1700 / 3469 samples via API... (Errors: 0, Time: 1360.6s)\n",
      "  Processed 1750 / 3469 samples via API... (Errors: 0, Time: 1400.5s)\n",
      "  Processed 1800 / 3469 samples via API... (Errors: 0, Time: 1441.0s)\n",
      "  Processed 1850 / 3469 samples via API... (Errors: 0, Time: 1481.1s)\n",
      "  Processed 1900 / 3469 samples via API... (Errors: 0, Time: 1521.4s)\n",
      "  Processed 1950 / 3469 samples via API... (Errors: 0, Time: 1561.4s)\n",
      "  Processed 2000 / 3469 samples via API... (Errors: 0, Time: 1601.4s)\n",
      "  Processed 2050 / 3469 samples via API... (Errors: 0, Time: 1641.5s)\n",
      "  Processed 2100 / 3469 samples via API... (Errors: 0, Time: 1681.4s)\n",
      "  Processed 2150 / 3469 samples via API... (Errors: 0, Time: 1721.6s)\n",
      "  Processed 2200 / 3469 samples via API... (Errors: 0, Time: 1761.9s)\n",
      "  Processed 2250 / 3469 samples via API... (Errors: 0, Time: 1801.7s)\n",
      "  Processed 2300 / 3469 samples via API... (Errors: 0, Time: 1841.8s)\n",
      "  Processed 2350 / 3469 samples via API... (Errors: 0, Time: 1881.7s)\n",
      "  Processed 2400 / 3469 samples via API... (Errors: 0, Time: 1921.7s)\n",
      "  Processed 2450 / 3469 samples via API... (Errors: 0, Time: 1961.5s)\n",
      "  Processed 2500 / 3469 samples via API... (Errors: 0, Time: 2001.4s)\n",
      "  Processed 2550 / 3469 samples via API... (Errors: 0, Time: 2041.2s)\n",
      "  Processed 2600 / 3469 samples via API... (Errors: 0, Time: 2081.1s)\n",
      "  Processed 2650 / 3469 samples via API... (Errors: 0, Time: 2121.0s)\n",
      "  Processed 2700 / 3469 samples via API... (Errors: 0, Time: 2161.7s)\n",
      "  Processed 2750 / 3469 samples via API... (Errors: 0, Time: 2201.5s)\n",
      "  Processed 2800 / 3469 samples via API... (Errors: 0, Time: 2242.7s)\n",
      "  Processed 2850 / 3469 samples via API... (Errors: 0, Time: 2282.7s)\n",
      "  Processed 2900 / 3469 samples via API... (Errors: 0, Time: 2322.6s)\n",
      "  Processed 2950 / 3469 samples via API... (Errors: 0, Time: 2362.5s)\n",
      "  Processed 3000 / 3469 samples via API... (Errors: 0, Time: 2402.3s)\n",
      "  Processed 3050 / 3469 samples via API... (Errors: 0, Time: 2442.1s)\n",
      "  Processed 3100 / 3469 samples via API... (Errors: 0, Time: 2482.0s)\n",
      "  Processed 3150 / 3469 samples via API... (Errors: 0, Time: 2522.0s)\n",
      "  Processed 3200 / 3469 samples via API... (Errors: 0, Time: 2561.9s)\n",
      "  Processed 3250 / 3469 samples via API... (Errors: 0, Time: 2601.7s)\n",
      "  Processed 3300 / 3469 samples via API... (Errors: 0, Time: 2641.6s)\n",
      "  Processed 3350 / 3469 samples via API... (Errors: 0, Time: 2681.8s)\n",
      "  Processed 3400 / 3469 samples via API... (Errors: 0, Time: 2721.7s)\n",
      "  Processed 3450 / 3469 samples via API... (Errors: 0, Time: 2761.5s)\n",
      "API prediction finished. Total time: 2777.48s. Errors encountered: 0\n",
      "\n",
      "--- Calculating Errors and R2 Scores ---\n",
      "SKL Python R2: 0.901331\n",
      "ONNX Python R2: 0.901331\n",
      "ONNX JS R2:    0.901331\n",
      "ONNX Browser R2:0.901331\n",
      "API FastAPI R2: 0.924968 (calculated on 3469 valid responses)\n",
      "\n",
      "--- Error Distribution Analysis ---\n",
      "\n",
      "--- SKL_Python ---\n",
      "R2 Score: 0.901331\n",
      "\n",
      "Absolute Error (AE) Distribution:\n",
      "count        3,469.0000\n",
      "mean     1,813,410.7879\n",
      "std      3,306,435.1471\n",
      "min             77.8439\n",
      "25%        361,291.0175\n",
      "50%        859,942.6464\n",
      "75%      1,924,038.5555\n",
      "90%      3,916,732.2082\n",
      "95%      6,437,863.7818\n",
      "99%     17,034,982.7228\n",
      "max     55,162,142.7293\n",
      "dtype: float64\n",
      "\n",
      "Absolute Percentage Error (APE) Distribution (%):\n",
      "count   3,469.0000\n",
      "mean       16.1134\n",
      "std        16.5547\n",
      "min         0.0014\n",
      "25%         5.2311\n",
      "50%        11.2123\n",
      "75%        21.3052\n",
      "90%        35.5707\n",
      "95%        46.1570\n",
      "99%        82.2149\n",
      "max       206.9008\n",
      "dtype: float64\n",
      "\n",
      "--- ONNX_Python ---\n",
      "R2 Score: 0.901331\n",
      "\n",
      "Absolute Error (AE) Distribution:\n",
      "count        3,469.0000\n",
      "mean     1,813,429.2530\n",
      "std      3,306,435.6337\n",
      "min             77.0000\n",
      "25%        361,290.7500\n",
      "50%        859,942.7500\n",
      "75%      1,924,039.0000\n",
      "90%      3,916,735.2000\n",
      "95%      6,437,856.4000\n",
      "99%     17,034,969.9200\n",
      "max     55,162,140.0000\n",
      "dtype: float64\n",
      "\n",
      "Absolute Percentage Error (APE) Distribution (%):\n",
      "count   3,469.0000\n",
      "mean       16.1135\n",
      "std        16.5547\n",
      "min         0.0014\n",
      "25%         5.2311\n",
      "50%        11.2123\n",
      "75%        21.3053\n",
      "90%        35.5707\n",
      "95%        46.1570\n",
      "99%        82.2149\n",
      "max       206.9009\n",
      "dtype: float64\n",
      "\n",
      "--- ONNX_JS ---\n",
      "R2 Score: 0.901331\n",
      "\n",
      "Absolute Error (AE) Distribution:\n",
      "count        3,469.0000\n",
      "mean     1,813,429.2530\n",
      "std      3,306,435.6337\n",
      "min             77.0000\n",
      "25%        361,290.7500\n",
      "50%        859,942.7500\n",
      "75%      1,924,039.0000\n",
      "90%      3,916,735.2000\n",
      "95%      6,437,856.4000\n",
      "99%     17,034,969.9200\n",
      "max     55,162,140.0000\n",
      "dtype: float64\n",
      "\n",
      "Absolute Percentage Error (APE) Distribution (%):\n",
      "count   3,469.0000\n",
      "mean       16.1135\n",
      "std        16.5547\n",
      "min         0.0014\n",
      "25%         5.2311\n",
      "50%        11.2123\n",
      "75%        21.3053\n",
      "90%        35.5707\n",
      "95%        46.1570\n",
      "99%        82.2149\n",
      "max       206.9009\n",
      "dtype: float64\n",
      "\n",
      "--- ONNX_Browser ---\n",
      "R2 Score: 0.901331\n",
      "\n",
      "Absolute Error (AE) Distribution:\n",
      "count        3,469.0000\n",
      "mean     1,813,429.2530\n",
      "std      3,306,435.6337\n",
      "min             77.0000\n",
      "25%        361,290.7500\n",
      "50%        859,942.7500\n",
      "75%      1,924,039.0000\n",
      "90%      3,916,735.2000\n",
      "95%      6,437,856.4000\n",
      "99%     17,034,969.9200\n",
      "max     55,162,140.0000\n",
      "dtype: float64\n",
      "\n",
      "Absolute Percentage Error (APE) Distribution (%):\n",
      "count   3,469.0000\n",
      "mean       16.1135\n",
      "std        16.5547\n",
      "min         0.0014\n",
      "25%         5.2311\n",
      "50%        11.2123\n",
      "75%        21.3053\n",
      "90%        35.5707\n",
      "95%        46.1570\n",
      "99%        82.2149\n",
      "max       206.9009\n",
      "dtype: float64\n",
      "\n",
      "--- API_FastAPI ---\n",
      "R2 Score: 0.924968\n",
      "\n",
      "Absolute Error (AE) Distribution:\n",
      "count        3,469.0000\n",
      "mean     1,628,232.1116\n",
      "std      2,857,112.3465\n",
      "min            378.0000\n",
      "25%        354,043.0000\n",
      "50%        815,834.0000\n",
      "75%      1,757,115.0000\n",
      "90%      3,608,283.0000\n",
      "95%      5,767,345.2000\n",
      "99%     14,032,334.4400\n",
      "max     51,201,843.0000\n",
      "dtype: float64\n",
      "\n",
      "Absolute Percentage Error (APE) Distribution (%):\n",
      "count   3,469.0000\n",
      "mean       14.8684\n",
      "std        15.4532\n",
      "min         0.0108\n",
      "25%         4.7656\n",
      "50%        10.4583\n",
      "75%        19.9041\n",
      "90%        32.5673\n",
      "95%        42.6101\n",
      "99%        69.4770\n",
      "max       221.7754\n",
      "dtype: float64\n",
      "\n",
      "--- Prediction Differences Distribution ---\n",
      "\n",
      "SKL vs ONNX-Py Difference:\n",
      "count    3,469.0000\n",
      "mean        22.2408\n",
      "std      1,094.9822\n",
      "min          0.0010\n",
      "50%          1.8251\n",
      "75%          4.2539\n",
      "95%         11.7490\n",
      "99%         28.8684\n",
      "100%    64,494.9966\n",
      "max     64,494.9966\n",
      "dtype: float64\n",
      "\n",
      "SKL vs ONNX-JS Difference:\n",
      "count    3,469.0000\n",
      "mean        22.2408\n",
      "std      1,094.9822\n",
      "min          0.0010\n",
      "50%          1.8251\n",
      "75%          4.2539\n",
      "95%         11.7490\n",
      "99%         28.8684\n",
      "100%    64,494.9966\n",
      "max     64,494.9966\n",
      "dtype: float64\n",
      "\n",
      "SKL vs ONNX-Browser Difference:\n",
      "count    3,469.0000\n",
      "mean        22.2408\n",
      "std      1,094.9822\n",
      "min          0.0010\n",
      "50%          1.8251\n",
      "75%          4.2539\n",
      "95%         11.7490\n",
      "99%         28.8684\n",
      "100%    64,494.9966\n",
      "max     64,494.9966\n",
      "dtype: float64\n",
      "\n",
      "SKL vs API-FastAPI Difference (on valid API responses):\n",
      "count        3,469.0000\n",
      "mean       776,221.5333\n",
      "std      1,596,098.6484\n",
      "min            172.8054\n",
      "50%        319,580.9744\n",
      "75%        739,236.9443\n",
      "95%      2,898,474.1872\n",
      "99%      7,341,278.7098\n",
      "100%    28,762,313.5292\n",
      "max     28,762,313.5292\n",
      "dtype: float64\n",
      "\n",
      "ONNX-Browser vs API-FastAPI Difference (on valid API responses):\n",
      "count        3,469.0000\n",
      "mean       776,203.0633\n",
      "std      1,596,100.7043\n",
      "min            171.0000\n",
      "50%        319,583.0000\n",
      "75%        739,242.0000\n",
      "95%      2,898,468.2000\n",
      "99%      7,341,272.9600\n",
      "100%    28,762,419.0000\n",
      "max     28,762,419.0000\n",
      "dtype: float64\n",
      "\n",
      "Comparison finished.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import requests # Import requests library\n",
    "\n",
    "# Scikit-learn metrics\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# ONNX Runtime\n",
    "import onnxruntime as rt\n",
    "\n",
    "# LightGBM and converters\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from skl2onnx import update_registered_converter\n",
    "from skl2onnx.common.shape_calculator import calculate_linear_regressor_output_shapes\n",
    "from onnxmltools.convert.lightgbm.operator_converters.LightGbm import convert_lightgbm\n",
    "\n",
    "# --- Configuration ---\n",
    "TEST_DATA_JSON_PATH = \"test_data_x.json\"\n",
    "PREDICTIONS_JS_PATH = \"onnx_js_predictions.json\"\n",
    "PREDICTIONS_BROWSER_PATH = \"onnx_browser_predictions.json\"\n",
    "PIPELINE_PATH = \"../PipelinesAndModels/full_pipeline_lgbm_pune_prices.pkl\"\n",
    "ONNX_MODEL_PATH = \"../PipelinesAndModels/full_pipeline_lgbm_pune_prices.onnx\"\n",
    "API_ENDPOINT_URL = \"https://phpp-api.adityajoshi.in/predict\" # Your API endpoint\n",
    "API_REQUEST_DELAY = 0.75 # Delay in seconds between API calls\n",
    "\n",
    "# --- Define initial types ---\n",
    "from skl2onnx.common.data_types import (\n",
    "    FloatTensorType, Int64TensorType, StringTensorType\n",
    ")\n",
    "# (initial_types definition remains the same)\n",
    "initial_types = [\n",
    "    (\"localityName\", StringTensorType([None, 1])),\n",
    "    (\"carpetArea\", Int64TensorType([None, 1])),\n",
    "    (\"floorNumber\", Int64TensorType([None, 1])),\n",
    "    (\"totalFloorNumber\", Int64TensorType([None, 1])),\n",
    "    (\"transactionType\", StringTensorType([None, 1])),\n",
    "    (\"furnished\", StringTensorType([None, 1])),\n",
    "    (\"bedrooms\", Int64TensorType([None, 1])),\n",
    "    (\"bathrooms\", Int64TensorType([None, 1])),\n",
    "    (\"ageofcons\", StringTensorType([None, 1])),\n",
    "]\n",
    "\n",
    "\n",
    "# --- Function to prepare ONNX input dict ---\n",
    "def prepare_onnx_input(data_row_df, types):\n",
    "    # (Keep the function as defined previously)\n",
    "    onx_input = {}\n",
    "    for name, itype in types:\n",
    "        col_name = name\n",
    "        series = data_row_df[col_name]\n",
    "        if isinstance(itype, StringTensorType):\n",
    "            numpy_array = series.astype(str).values.reshape(-1, 1)\n",
    "        elif isinstance(itype, Int64TensorType):\n",
    "            numpy_array = series.values.reshape(-1, 1).astype(np.int64)\n",
    "        elif isinstance(itype, FloatTensorType):\n",
    "            numpy_array = series.values.reshape(-1, 1).astype(np.float32)\n",
    "        else:\n",
    "            raise TypeError(f\"Unhandled ONNX input type: {type(itype)}\")\n",
    "        onx_input[name] = numpy_array\n",
    "    return onx_input\n",
    "\n",
    "# --- Main Comparison Logic ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting comparison with detailed error analysis (including API)...\")\n",
    "\n",
    "    # 1. Load Test Data (X_test, y_test)\n",
    "    print(f\"Loading test data features from {TEST_DATA_JSON_PATH}...\")\n",
    "    X_test = pd.read_json(TEST_DATA_JSON_PATH, orient='records')\n",
    "    if 'y_test' not in globals():\n",
    "         raise NameError(\"y_test not found. Ensure it's loaded or reload it.\")\n",
    "    y_test_np = y_test.to_numpy()\n",
    "    print(f\"Loaded X_test shape: {X_test.shape}, y_test shape: {y_test_np.shape}\")\n",
    "\n",
    "    # --- Load Models/Pipelines (Sections 2 & 3) ---\n",
    "    # (Keep the loading logic for SKL Pipeline and ONNX Python as before)\n",
    "    # 2. Load Scikit-learn Pipeline\n",
    "    print(f\"Loading Scikit-learn pipeline from {PIPELINE_PATH}...\")\n",
    "    try:\n",
    "        update_registered_converter(\n",
    "            LGBMRegressor, \"LightGbmLGBMRegressor\",\n",
    "            calculate_linear_regressor_output_shapes, convert_lightgbm\n",
    "        )\n",
    "        with open(PIPELINE_PATH, 'rb') as f:\n",
    "            skl_pipeline = pickle.load(f)\n",
    "        print(\"Pipeline loaded successfully.\")\n",
    "    except Exception as e: print(f\"Error loading pickle file: {e}\"); exit()\n",
    "\n",
    "    # 3. Load ONNX Model (Python Runtime)\n",
    "    print(f\"Loading ONNX model from {ONNX_MODEL_PATH}...\")\n",
    "    try:\n",
    "        onnx_session_py = rt.InferenceSession(\n",
    "            ONNX_MODEL_PATH, providers=['CPUExecutionProvider']\n",
    "        )\n",
    "        onnx_py_output_name = onnx_session_py.get_outputs()[0].name\n",
    "    except Exception as e: print(f\"Error loading ONNX model: {e}\"); exit()\n",
    "\n",
    "\n",
    "    # --- Generate/Load Predictions (Sections 4, 5, 6, 7) ---\n",
    "    # (Keep prediction logic for SKL, ONNX Py, ONNX JS, ONNX Browser as before)\n",
    "    # 4. Get Predictions: Scikit-learn\n",
    "    print(\"Generating predictions with Scikit-learn pipeline...\")\n",
    "    start_time = time.time()\n",
    "    y_pred_skl = skl_pipeline.predict(X_test)\n",
    "    skl_time = time.time() - start_time\n",
    "    print(f\"Scikit-learn prediction time: {skl_time:.2f}s\")\n",
    "\n",
    "\n",
    "    # 5. Get Predictions: ONNX Runtime (Python)\n",
    "    print(\"Generating predictions with ONNX Runtime (Python)...\")\n",
    "    y_pred_onnx_py_list = []\n",
    "    start_time = time.time()\n",
    "    for i in range(len(X_test)):\n",
    "        row_df = X_test.iloc[i:i+1]\n",
    "        onx_input = prepare_onnx_input(row_df, initial_types)\n",
    "        pred = onnx_session_py.run([onnx_py_output_name], onx_input)[0]\n",
    "        y_pred_onnx_py_list.append(pred.item())\n",
    "        if (i + 1) % 100 == 0: print(f\"  Processed {i + 1} / {len(X_test)} samples...\")\n",
    "    y_pred_onnx_py = np.array(y_pred_onnx_py_list)\n",
    "    onnx_py_time = time.time() - start_time\n",
    "    print(f\"ONNX (Python) prediction time: {onnx_py_time:.2f}s\")\n",
    "\n",
    "    # 6. Load Predictions: ONNX Runtime (Node.js)\n",
    "    print(f\"Loading predictions from Node.js ONNX run ({PREDICTIONS_JS_PATH})...\")\n",
    "    y_pred_onnx_js = None\n",
    "    try:\n",
    "        with open(PREDICTIONS_JS_PATH, 'r') as f: y_pred_onnx_js = np.array(json.load(f))\n",
    "        if len(y_pred_onnx_js) != len(y_test_np): raise ValueError(\"Length mismatch\")\n",
    "        print(f\"Loaded {len(y_pred_onnx_js)} Node.js predictions.\")\n",
    "    except Exception as e: print(f\"Error loading Node.js predictions: {e}\")\n",
    "\n",
    "    # 7. Load Predictions: ONNX Runtime (Browser/Web)\n",
    "    print(f\"Loading predictions from Browser ONNX run ({PREDICTIONS_BROWSER_PATH})...\")\n",
    "    y_pred_onnx_browser = None\n",
    "    try:\n",
    "        with open(PREDICTIONS_BROWSER_PATH, 'r') as f: y_pred_onnx_browser = np.array(json.load(f))\n",
    "        if len(y_pred_onnx_browser) != len(y_test_np): raise ValueError(\"Length mismatch\")\n",
    "        print(f\"Loaded {len(y_pred_onnx_browser)} Browser predictions.\")\n",
    "    except Exception as e: print(f\"Error loading Browser predictions: {e}\")\n",
    "\n",
    "\n",
    "    # 8. Get Predictions: Live API (FastAPI)\n",
    "    print(f\"Generating predictions via Live API ({API_ENDPOINT_URL})...\")\n",
    "    y_pred_api_list = []\n",
    "    api_errors = 0\n",
    "    start_time = time.time()\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "    for i in range(len(X_test)): # Trial: \n",
    "        # Convert row to dictionary suitable for JSON payload\n",
    "        # Ensure keys match exactly what your API expects\n",
    "        payload = X_test.iloc[i].to_dict()\n",
    "        # Convert numpy types (like int64) to standard Python types for JSON\n",
    "        for key, value in payload.items():\n",
    "            if isinstance(value, np.integer):\n",
    "                payload[key] = int(value)\n",
    "            elif isinstance(value, np.floating):\n",
    "                payload[key] = float(value)\n",
    "            # Add other type conversions if necessary\n",
    "\n",
    "        try:\n",
    "            response = requests.post(API_ENDPOINT_URL, headers=headers, json=payload, timeout=30) # Added timeout\n",
    "            response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "\n",
    "            data = response.json()\n",
    "            # --- Adjust this line based on the exact key in your API response ---\n",
    "            predicted_price = data.get('predictedPrice')\n",
    "            if predicted_price is None:\n",
    "                 print(f\"Warning: 'predictedPrice' key not found in API response for row {i}. Response: {data}\")\n",
    "                 predicted_price = np.nan # Use NaN for missing predictions\n",
    "                 api_errors += 1\n",
    "            # --- End of adjustment ---\n",
    "            y_pred_api_list.append(float(predicted_price)) # Ensure it's float\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error calling API for row {i}: {e}\")\n",
    "            y_pred_api_list.append(np.nan) # Append NaN on error\n",
    "            api_errors += 1\n",
    "        except Exception as e: # Catch other potential errors like JSON parsing\n",
    "             print(f\"Non-request error processing API response for row {i}: {e}\")\n",
    "             y_pred_api_list.append(np.nan)\n",
    "             api_errors += 1\n",
    "\n",
    "\n",
    "        if (i + 1) % 50 == 0: # Log progress less frequently due to delay\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"  Processed {i + 1} / {len(X_test)} samples via API... (Errors: {api_errors}, Time: {elapsed:.1f}s)\")\n",
    "\n",
    "        # --- Add delay ---\n",
    "        time.sleep(API_REQUEST_DELAY)\n",
    "\n",
    "    y_pred_api = np.array(y_pred_api_list)\n",
    "    api_time = time.time() - start_time\n",
    "    print(f\"API prediction finished. Total time: {api_time:.2f}s. Errors encountered: {api_errors}\")\n",
    "    # Handle potential NaNs if errors occurred\n",
    "    valid_api_preds = ~np.isnan(y_pred_api)\n",
    "\n",
    "\n",
    "    # 9. Calculate Error Arrays and R2 Scores\n",
    "    print(\"\\n--- Calculating Errors and R2 Scores ---\")\n",
    "    results = {}\n",
    "    denominator =  y_test_np + 1e-10 # np.where(y_test_np == 0, 1, y_test_np)\n",
    "\n",
    "    # Scikit-learn\n",
    "    ae_skl = np.abs(y_test_np - y_pred_skl); ape_skl = np.abs((y_test_np - y_pred_skl) / denominator) * 100; r2_skl = r2_score(y_test_np, y_pred_skl)\n",
    "    results[\"SKL_Python\"] = {\"AE\": ae_skl, \"APE\": ape_skl, \"R2\": r2_skl}\n",
    "    print(f\"SKL Python R2: {r2_skl:.6f}\")\n",
    "\n",
    "    # ONNX Python\n",
    "    ae_onnx_py = np.abs(y_test_np - y_pred_onnx_py); ape_onnx_py = np.abs((y_test_np - y_pred_onnx_py) / denominator) * 100; r2_onnx_py = r2_score(y_test_np, y_pred_onnx_py)\n",
    "    results[\"ONNX_Python\"] = {\"AE\": ae_onnx_py, \"APE\": ape_onnx_py, \"R2\": r2_onnx_py}\n",
    "    print(f\"ONNX Python R2: {r2_onnx_py:.6f}\")\n",
    "\n",
    "    # ONNX Node.js\n",
    "    if y_pred_onnx_js is not None:\n",
    "        ae_onnx_js = np.abs(y_test_np - y_pred_onnx_js); ape_onnx_js = np.abs((y_test_np - y_pred_onnx_js) / denominator) * 100; r2_onnx_js = r2_score(y_test_np, y_pred_onnx_js)\n",
    "        results[\"ONNX_JS\"] = {\"AE\": ae_onnx_js, \"APE\": ape_onnx_js, \"R2\": r2_onnx_js}\n",
    "        print(f\"ONNX JS R2:    {r2_onnx_js:.6f}\")\n",
    "    else: print(\"ONNX JS R2:    N/A\")\n",
    "\n",
    "    # ONNX Browser\n",
    "    if y_pred_onnx_browser is not None:\n",
    "        ae_onnx_browser = np.abs(y_test_np - y_pred_onnx_browser); ape_onnx_browser = np.abs((y_test_np - y_pred_onnx_browser) / denominator) * 100; r2_onnx_browser = r2_score(y_test_np, y_pred_onnx_browser)\n",
    "        results[\"ONNX_Browser\"] = {\"AE\": ae_onnx_browser, \"APE\": ape_onnx_browser, \"R2\": r2_onnx_browser}\n",
    "        print(f\"ONNX Browser R2:{r2_onnx_browser:.6f}\")\n",
    "    else: print(\"ONNX Browser R2:N/A\")\n",
    "\n",
    "    # Live API\n",
    "    if api_errors < len(X_test): # Only calculate if we got at least some valid predictions\n",
    "        # Filter y_test and predictions to only include valid API results\n",
    "        y_test_filt = y_test_np[valid_api_preds]\n",
    "        y_pred_api_filt = y_pred_api[valid_api_preds]\n",
    "        denominator_filt = np.where(y_test_filt == 0, 1, y_test_filt)\n",
    "\n",
    "        ae_api = np.abs(y_test_filt - y_pred_api_filt)\n",
    "        ape_api = np.abs((y_test_filt - y_pred_api_filt) / denominator_filt) * 100\n",
    "        r2_api = r2_score(y_test_filt, y_pred_api_filt)\n",
    "        # Store the *filtered* error arrays for describe()\n",
    "        results[\"API_FastAPI\"] = {\"AE\": ae_api, \"APE\": ape_api, \"R2\": r2_api}\n",
    "        print(f\"API FastAPI R2: {r2_api:.6f} (calculated on {len(y_test_filt)} valid responses)\")\n",
    "    else:\n",
    "        print(f\"API FastAPI R2: N/A (No valid responses received)\")\n",
    "        results[\"API_FastAPI\"] = {\"AE\": np.array([]), \"APE\": np.array([]), \"R2\": \"N/A\"}\n",
    "\n",
    "\n",
    "    # 10. Analyze Error Distributions using Pandas describe()\n",
    "    print(\"\\n--- Error Distribution Analysis ---\")\n",
    "    pd.set_option('display.float_format', '{:,.4f}'.format)\n",
    "\n",
    "    for method, data in results.items():\n",
    "        print(f\"\\n--- {method} ---\")\n",
    "        r2_val = data['R2']\n",
    "        print(f\"R2 Score: {r2_val:.6f}\" if isinstance(r2_val, float) else f\"R2 Score: {r2_val}\")\n",
    "\n",
    "        if len(data[\"AE\"]) > 0: # Check if there are errors to describe\n",
    "            ae_series = pd.Series(data[\"AE\"])\n",
    "            print(\"\\nAbsolute Error (AE) Distribution:\")\n",
    "            print(ae_series.describe(percentiles=[.25, .5, .75, .9, .95, .99]))\n",
    "\n",
    "            ape_series = pd.Series(data[\"APE\"])\n",
    "            print(\"\\nAbsolute Percentage Error (APE) Distribution (%):\")\n",
    "            print(ape_series.describe(percentiles=[.25, .5, .75, .9, .95, .99]))\n",
    "        else:\n",
    "            print(\"\\nError distributions: N/A (No valid predictions)\")\n",
    "\n",
    "\n",
    "    # 11. Analyze Prediction Differences\n",
    "    print(\"\\n--- Prediction Differences Distribution ---\")\n",
    "    # (Keep the difference calculations as before, adding comparisons with API results)\n",
    "\n",
    "    print(\"\\nSKL vs ONNX-Py Difference:\")\n",
    "    diff_skl_onnxpy = np.abs(y_pred_skl - y_pred_onnx_py)\n",
    "    print(pd.Series(diff_skl_onnxpy).describe(percentiles=[.5, .75, .95, .99, 1.0]))\n",
    "\n",
    "    if y_pred_onnx_js is not None:\n",
    "        print(\"\\nSKL vs ONNX-JS Difference:\")\n",
    "        diff_skl_onnxjs = np.abs(y_pred_skl - y_pred_onnx_js)\n",
    "        print(pd.Series(diff_skl_onnxjs).describe(percentiles=[.5, .75, .95, .99, 1.0]))\n",
    "\n",
    "    if y_pred_onnx_browser is not None:\n",
    "         print(\"\\nSKL vs ONNX-Browser Difference:\")\n",
    "         diff_skl_onnxbrowser = np.abs(y_pred_skl - y_pred_onnx_browser)\n",
    "         print(pd.Series(diff_skl_onnxbrowser).describe(percentiles=[.5, .75, .95, .99, 1.0]))\n",
    "\n",
    "    # Add comparisons involving the API, only if valid API predictions exist\n",
    "    if api_errors < len(X_test):\n",
    "        print(\"\\nSKL vs API-FastAPI Difference (on valid API responses):\")\n",
    "        # Compare only where API predictions were valid\n",
    "        diff_skl_api = np.abs(y_pred_skl[valid_api_preds] - y_pred_api_filt)\n",
    "        print(pd.Series(diff_skl_api).describe(percentiles=[.5, .75, .95, .99, 1.0]))\n",
    "\n",
    "        if y_pred_onnx_browser is not None:\n",
    "             print(\"\\nONNX-Browser vs API-FastAPI Difference (on valid API responses):\")\n",
    "             diff_browser_api = np.abs(y_pred_onnx_browser[valid_api_preds] - y_pred_api_filt)\n",
    "             print(pd.Series(diff_browser_api).describe(percentiles=[.5, .75, .95, .99, 1.0]))\n",
    "\n",
    "\n",
    "    print(\"\\nComparison finished.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd9eb64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SKL_static</th>\n",
       "      <th>API</th>\n",
       "      <th>ONNX_Browser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15217601</td>\n",
       "      <td>15338303</td>\n",
       "      <td>15217599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>42628863</td>\n",
       "      <td>36454465</td>\n",
       "      <td>42628868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>6923664</td>\n",
       "      <td>6855992</td>\n",
       "      <td>6923662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>17303947</td>\n",
       "      <td>14194727</td>\n",
       "      <td>17303940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>11794302</td>\n",
       "      <td>11927707</td>\n",
       "      <td>11794296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>13486323</td>\n",
       "      <td>12583945</td>\n",
       "      <td>13486319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>14016508</td>\n",
       "      <td>15152250</td>\n",
       "      <td>14016509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>3753220</td>\n",
       "      <td>3687930</td>\n",
       "      <td>3753221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>4073572</td>\n",
       "      <td>3900320</td>\n",
       "      <td>4073571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5483308</td>\n",
       "      <td>5438279</td>\n",
       "      <td>5483306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SKL_static       API  ONNX_Browser\n",
       "0      15217601  15338303      15217599\n",
       "320    42628863  36454465      42628868\n",
       "92      6923664   6855992       6923662\n",
       "222    17303947  14194727      17303940\n",
       "117    11794302  11927707      11794296\n",
       "326    13486323  12583945      13486319\n",
       "138    14016508  15152250      14016509\n",
       "417     3753220   3687930       3753221\n",
       "325     4073572   3900320       4073571\n",
       "8       5483308   5438279       5483306"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare = pd.DataFrame(\n",
    "    {\n",
    "        'SKL_static': y_pred_skl[:500],\n",
    "        'API': y_pred_api[:500],\n",
    "        'ONNX_Browser': y_pred_onnx_browser[:500],\n",
    "    }\n",
    ")\n",
    "compare.astype(int).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9d62946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>localityName</th>\n",
       "      <th>Carpet</th>\n",
       "      <th>Floor</th>\n",
       "      <th>Total Floors</th>\n",
       "      <th>Type</th>\n",
       "      <th>furnished</th>\n",
       "      <th>Bed</th>\n",
       "      <th>Bath</th>\n",
       "      <th>ageofcons</th>\n",
       "      <th>SKL_static</th>\n",
       "      <th>API</th>\n",
       "      <th>ONNX_Browser</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>Hadapsar</td>\n",
       "      <td>640</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Furnished</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15 to 20 years</td>\n",
       "      <td>5798267</td>\n",
       "      <td>5766669</td>\n",
       "      <td>5798268</td>\n",
       "      <td>7500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Kondhawe Dhawade</td>\n",
       "      <td>400</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Furnished</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5 to 10 years</td>\n",
       "      <td>3812668</td>\n",
       "      <td>2576718</td>\n",
       "      <td>3812668</td>\n",
       "      <td>3250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wakad</td>\n",
       "      <td>855</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5 to 10 years</td>\n",
       "      <td>8898176</td>\n",
       "      <td>9044251</td>\n",
       "      <td>8898173</td>\n",
       "      <td>8400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>Hinjewadi</td>\n",
       "      <td>315</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Less than 5 years</td>\n",
       "      <td>1945833</td>\n",
       "      <td>1838835</td>\n",
       "      <td>1945832</td>\n",
       "      <td>1500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Undri</td>\n",
       "      <td>853</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>New Construction</td>\n",
       "      <td>6271266</td>\n",
       "      <td>6376725</td>\n",
       "      <td>6271270</td>\n",
       "      <td>6150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Pimple Saudagar, Pimpri Chinchwad</td>\n",
       "      <td>435</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Semi-Furnished</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5 to 10 years</td>\n",
       "      <td>4598903</td>\n",
       "      <td>4626339</td>\n",
       "      <td>4598899</td>\n",
       "      <td>5500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Bibwewadi</td>\n",
       "      <td>450</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Furnished</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5 to 10 years</td>\n",
       "      <td>5494659</td>\n",
       "      <td>4589048</td>\n",
       "      <td>5494659</td>\n",
       "      <td>4200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Amanora Park Town</td>\n",
       "      <td>741</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>New Construction</td>\n",
       "      <td>11579416</td>\n",
       "      <td>11466331</td>\n",
       "      <td>11579412</td>\n",
       "      <td>12800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>NIBM Road</td>\n",
       "      <td>2265</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5 to 10 years</td>\n",
       "      <td>22850670</td>\n",
       "      <td>25653708</td>\n",
       "      <td>22850658</td>\n",
       "      <td>23500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>Wakad</td>\n",
       "      <td>971</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Semi-Furnished</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5 to 10 years</td>\n",
       "      <td>11206169</td>\n",
       "      <td>11102299</td>\n",
       "      <td>11206164</td>\n",
       "      <td>13500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          localityName  Carpet  Floor  Total Floors    Type  \\\n",
       "345                           Hadapsar     640      3             5  Resale   \n",
       "136                   Kondhawe Dhawade     400      1             7  Resale   \n",
       "18                               Wakad     855      8            12  Resale   \n",
       "321                          Hinjewadi     315      8             7  Resale   \n",
       "206                              Undri     853      7            12  Resale   \n",
       "168  Pimple Saudagar, Pimpri Chinchwad     435      3             7  Resale   \n",
       "238                          Bibwewadi     450      5             5  Resale   \n",
       "123                  Amanora Park Town     741      4            32  Resale   \n",
       "290                          NIBM Road    2265      5            11  Resale   \n",
       "387                              Wakad     971      9            11  Resale   \n",
       "\n",
       "          furnished  Bed  Bath          ageofcons  SKL_static       API  \\\n",
       "345       Furnished    2     1     15 to 20 years     5798267   5766669   \n",
       "136       Furnished    1     1      5 to 10 years     3812668   2576718   \n",
       "18      Unfurnished    2     2      5 to 10 years     8898176   9044251   \n",
       "321     Unfurnished    1     1  Less than 5 years     1945833   1838835   \n",
       "206     Unfurnished    2     2   New Construction     6271266   6376725   \n",
       "168  Semi-Furnished    1     2      5 to 10 years     4598903   4626339   \n",
       "238       Furnished    1     1      5 to 10 years     5494659   4589048   \n",
       "123     Unfurnished    2     2   New Construction    11579416  11466331   \n",
       "290     Unfurnished    3     3      5 to 10 years    22850670  25653708   \n",
       "387  Semi-Furnished    3     3      5 to 10 years    11206169  11102299   \n",
       "\n",
       "     ONNX_Browser     price  \n",
       "345       5798268   7500000  \n",
       "136       3812668   3250000  \n",
       "18        8898173   8400000  \n",
       "321       1945832   1500000  \n",
       "206       6271270   6150000  \n",
       "168       4598899   5500000  \n",
       "238       5494659   4200000  \n",
       "123      11579412  12800000  \n",
       "290      22850658  23500000  \n",
       "387      11206164  13500000  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([X_test[:500], compare.astype(int), df_test.reset_index()[:500][['price']]], axis=1).sample(10).rename(columns={\n",
    "    'totalFloorNumber': 'Total Floors',\n",
    "    'bedrooms': 'Bed',\n",
    "    'bathrooms': 'Bath',\n",
    "    'carpetArea': 'Carpet',\n",
    "    'floorNumber': 'Floor',\n",
    "    'transactionType': 'Type',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "885b75f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>localityName</th>\n",
       "      <th>price</th>\n",
       "      <th>carpetArea</th>\n",
       "      <th>floorNumber</th>\n",
       "      <th>totalFloorNumber</th>\n",
       "      <th>transactionType</th>\n",
       "      <th>furnished</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>ageofcons</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>propertyId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75987143</th>\n",
       "      <td>Bavdhan</td>\n",
       "      <td>11800000</td>\n",
       "      <td>1266</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Less than 5 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75092669</th>\n",
       "      <td>Kondhwa</td>\n",
       "      <td>9500000</td>\n",
       "      <td>1200</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Semi-Furnished</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5 to 10 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74846961</th>\n",
       "      <td>Punawale, Pimpri Chinchwad</td>\n",
       "      <td>6100000</td>\n",
       "      <td>776</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>New Property</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Under Construction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75676635</th>\n",
       "      <td>Camp</td>\n",
       "      <td>14000000</td>\n",
       "      <td>864</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Semi-Furnished</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Above 20 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77813777</th>\n",
       "      <td>Wakad</td>\n",
       "      <td>12500000</td>\n",
       "      <td>1150</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5 to 10 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75656955</th>\n",
       "      <td>Ambegaon</td>\n",
       "      <td>4500000</td>\n",
       "      <td>593</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Less than 5 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75692129</th>\n",
       "      <td>Tathawade Pimpri Chinchwad</td>\n",
       "      <td>4500000</td>\n",
       "      <td>495</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Semi-Furnished</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Less than 5 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75657785</th>\n",
       "      <td>Narhe</td>\n",
       "      <td>4500000</td>\n",
       "      <td>644</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Semi-Furnished</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5 to 10 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72574395</th>\n",
       "      <td>Hinjewadi</td>\n",
       "      <td>6050000</td>\n",
       "      <td>657</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Semi-Furnished</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Less than 5 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68600165</th>\n",
       "      <td>Punawale, Pimpri Chinchwad</td>\n",
       "      <td>6500000</td>\n",
       "      <td>700</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>Resale</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>New Construction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          localityName     price  carpetArea  floorNumber  \\\n",
       "propertyId                                                                  \n",
       "75987143                       Bavdhan  11800000        1266           10   \n",
       "75092669                       Kondhwa   9500000        1200            4   \n",
       "74846961    Punawale, Pimpri Chinchwad   6100000         776            9   \n",
       "75676635                          Camp  14000000         864            2   \n",
       "77813777                         Wakad  12500000        1150            1   \n",
       "...                                ...       ...         ...          ...   \n",
       "75656955                      Ambegaon   4500000         593            2   \n",
       "75692129    Tathawade Pimpri Chinchwad   4500000         495            3   \n",
       "75657785                         Narhe   4500000         644            1   \n",
       "72574395                     Hinjewadi   6050000         657           10   \n",
       "68600165    Punawale, Pimpri Chinchwad   6500000         700            6   \n",
       "\n",
       "            totalFloorNumber transactionType       furnished  bedrooms  \\\n",
       "propertyId                                                               \n",
       "75987143                  12          Resale     Unfurnished         3   \n",
       "75092669                   7          Resale  Semi-Furnished         3   \n",
       "74846961                  24    New Property     Unfurnished         2   \n",
       "75676635                   3          Resale  Semi-Furnished         3   \n",
       "77813777                   6          Resale     Unfurnished         3   \n",
       "...                      ...             ...             ...       ...   \n",
       "75656955                   5          Resale     Unfurnished         2   \n",
       "75692129                   4          Resale  Semi-Furnished         1   \n",
       "75657785                   5          Resale  Semi-Furnished         2   \n",
       "72574395                  22          Resale  Semi-Furnished         2   \n",
       "68600165                  14          Resale     Unfurnished         2   \n",
       "\n",
       "            bathrooms           ageofcons  \n",
       "propertyId                                 \n",
       "75987143            3   Less than 5 years  \n",
       "75092669            3       5 to 10 years  \n",
       "74846961            2  Under Construction  \n",
       "75676635            3      Above 20 years  \n",
       "77813777            3       5 to 10 years  \n",
       "...               ...                 ...  \n",
       "75656955            2   Less than 5 years  \n",
       "75692129            2   Less than 5 years  \n",
       "75657785            2       5 to 10 years  \n",
       "72574395            2   Less than 5 years  \n",
       "68600165            2    New Construction  \n",
       "\n",
       "[500 rows x 10 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[:500]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
