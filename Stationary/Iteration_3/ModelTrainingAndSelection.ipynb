{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def displayHorizontalDataframes(dfs, titles):\n",
    "    \"\"\"\n",
    "    Display a list of pandas dataframes horizontally with titles on top.\n",
    "    \n",
    "    Parameters:\n",
    "    dfs (list): List of pandas DataFrames.\n",
    "    titles (list): List of titles (strings) corresponding to each DataFrame.\n",
    "    \"\"\"\n",
    "    if len(dfs) != len(titles):\n",
    "        raise ValueError(\"The number of dataframes and titles must be the same.\")\n",
    "\n",
    "    # Start a flex container to align content horizontally and center them.\n",
    "    html = (\n",
    "        \"<div style='display: flex; justify-content: center; \"\n",
    "        \"align-items: flex-start;'>\"\n",
    "    )\n",
    "    \n",
    "    # Iterate over the dataframes and their corresponding titles.\n",
    "    for df, title in zip(dfs, titles):\n",
    "        title = \" \" if not title else title\n",
    "        html += (\n",
    "            \"<div style='margin-left: 20px; margin-right: 20px; text-align: center;'>\"\n",
    "            f\"<h3>{title}</h3>\"\n",
    "            f\"{df.to_html(classes='dataframe', border=1)}\"\n",
    "            \"</div>\"\n",
    "        )\n",
    "    \n",
    "    html += \"</div>\"\n",
    "    display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Null values:  localityName           0\n",
      "price                  0\n",
      "carpetArea          3764\n",
      "floorNumber            0\n",
      "totalFloorNumber       0\n",
      "transactionType        0\n",
      "furnished             37\n",
      "bedrooms               0\n",
      "bathrooms              0\n",
      "ageofcons           2571\n",
      "dtype: int64 \n",
      "\n",
      "Test Set Null values:  localityName          0\n",
      "price                 0\n",
      "carpetArea          977\n",
      "floorNumber           0\n",
      "totalFloorNumber      0\n",
      "transactionType       0\n",
      "furnished            14\n",
      "bedrooms              0\n",
      "bathrooms             0\n",
      "ageofcons           693\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "# from ydata_profiling import ProfileReport\n",
    "import numpy as np\n",
    "\n",
    "dtype_mapping = {\n",
    "    'propertyId': pd.StringDtype(),\n",
    "    'localityName': 'category',\n",
    "    'landMarks': pd.StringDtype(),\n",
    "    'locality': pd.StringDtype(),\n",
    "    'price': pd.Int64Dtype(),\n",
    "    'nameOfSociety': pd.StringDtype(),\n",
    "    'projectName': pd.StringDtype(),\n",
    "    'carpetArea': pd.Int64Dtype(),\n",
    "    'coveredArea': pd.Int64Dtype(),\n",
    "    'carpetAreaSqft': pd.Int64Dtype(),\n",
    "    'possessionStatus': pd.StringDtype(),\n",
    "    'developerName': pd.StringDtype(),\n",
    "    'flooringType': pd.StringDtype(),\n",
    "    'floorNumber': pd.Int64Dtype(),\n",
    "    'unitCountonFloor': pd.Int64Dtype(),\n",
    "    'totalFloorNumber': pd.Int64Dtype(),\n",
    "    'electricityStatus': pd.StringDtype(),\n",
    "    'waterStatus': pd.StringDtype(),\n",
    "    'longitude': pd.Float64Dtype(),\n",
    "    'latitude': pd.Float64Dtype(),\n",
    "    'transactionType': 'category',\n",
    "    'facing': pd.StringDtype(),\n",
    "    'ownershipType': pd.StringDtype(),\n",
    "    'carParking': pd.StringDtype(),\n",
    "    'furnished': 'category',\n",
    "    'bedrooms': pd.Int64Dtype(),\n",
    "    'bathrooms': pd.Int64Dtype(),\n",
    "    'numberOfBalconied': pd.Int64Dtype(),\n",
    "    'propertyType': 'category',\n",
    "    'additionalRooms': pd.StringDtype(),\n",
    "    'bookingAmountExact': pd.Int64Dtype(),\n",
    "    'maintenanceChargesFrequency': 'category',\n",
    "    'maintenanceCharges': pd.Int64Dtype(),\n",
    "    'ageofcons': 'category',\n",
    "    'isVerified': 'category',\n",
    "    'listingTypeDesc': 'category',\n",
    "    'premiumProperty': pd.BooleanDtype(),\n",
    "    'noOfLifts': pd.Int64Dtype(),\n",
    "    'propertyAmenities': pd.StringDtype(),\n",
    "    'facilitiesDesc': pd.StringDtype(),\n",
    "    'uuid': pd.StringDtype(),\n",
    "    'flooringType_Vitrified': pd.BooleanDtype(),\n",
    "    'flooringType_CeramicTiles': pd.BooleanDtype(),\n",
    "    'flooringType_Marble': pd.BooleanDtype(),\n",
    "    'flooringType_NormalTilesKotahStone': pd.BooleanDtype(),\n",
    "    'flooringType_Granite': pd.BooleanDtype(),\n",
    "    'flooringType_Wooden': pd.BooleanDtype(),\n",
    "    'flooringType_Mosaic': pd.BooleanDtype(),\n",
    "    'flooringType_Marbonite': pd.BooleanDtype(),\n",
    "    'additionalRoom_PujaRoom': pd.BooleanDtype(),\n",
    "    'additionalRoom_Study': pd.BooleanDtype(),\n",
    "    'additionalRoom_Store': pd.BooleanDtype(),\n",
    "    'additionalRoom_ServantRoom': pd.BooleanDtype(),\n",
    "    'carParking_Open': pd.Int64Dtype(),\n",
    "    'carParking_Covered': pd.Int64Dtype(),\n",
    "    'ReservedParking': pd.BooleanDtype(),\n",
    "}\n",
    "\n",
    "COLUMNS_TO_DROP = [\n",
    "    'coveredArea',\n",
    "    'ReservedParking',\n",
    "] + [\n",
    "        'unitCountonFloor',\n",
    "        'electricityStatus',\n",
    "        'waterStatus',\n",
    "        'facing',\n",
    "        'bookingAmountExact',\n",
    "        'isVerified',\n",
    "        'listingTypeDesc',\n",
    "        'maintenanceCharges',\n",
    "        'maintenanceChargesFrequency',\n",
    "        'latitude',\n",
    "        'longitude',\n",
    "        'carParking_Open',\n",
    "        'carParking_Covered',\n",
    "        'numberOfBalconied',\n",
    "        'premiumProperty',\n",
    "        'projectName',\n",
    "        'nameOfSociety',\n",
    "        'url',\n",
    "        # 'uuid',\n",
    "        'carpetAreaSqft',\n",
    "        'noOfLifts',\n",
    "        'ownershipType',\n",
    "        'possessionStatus',\n",
    "        'propertyType',\n",
    "\n",
    "        'flooringType_Vitrified',\n",
    "        'flooringType_CeramicTiles',\n",
    "        'flooringType_Marble',\n",
    "        'flooringType_NormalTilesKotahStone',\n",
    "        'flooringType_Granite',\n",
    "        'flooringType_Wooden',\n",
    "        'flooringType_Mosaic',\n",
    "        'flooringType_Marbonite',\n",
    "\n",
    "        'additionalRoom_PujaRoom',\n",
    "        'additionalRoom_Study',\n",
    "        'additionalRoom_Store',\n",
    "        'additionalRoom_ServantRoom',\n",
    "        \n",
    "        'landMarks', \n",
    "        'locality', \n",
    "        'developerName',]\n",
    "\n",
    "################################################################################\n",
    "# ONLY USING THE RAW SETs, NOT IMPUTED SET\n",
    "################################################################################\n",
    "df_train = pd.read_csv(\n",
    "    'Data/train.csv',\n",
    "    dtype = dtype_mapping,\n",
    "    index_col=0\n",
    ")\n",
    "df_train.drop(COLUMNS_TO_DROP, axis=1, inplace=True)\n",
    "\n",
    "df_test = pd.read_csv(\n",
    "    'Data/test.csv',\n",
    "    dtype = dtype_mapping,\n",
    "    index_col=0\n",
    ")\n",
    "df_test.drop(COLUMNS_TO_DROP, axis=1, inplace=True)\n",
    "\n",
    "################################################################################\n",
    "# DROPPING ALL ROWS WITH MISSING VALUES\n",
    "################################################################################\n",
    "\n",
    "print(\"Train Set Null values: \", df_train.isna().sum(), '\\n')\n",
    "print(\"Test Set Null values: \", df_test.isna().sum(), '\\n')\n",
    "\n",
    "df_train.dropna(axis=0, inplace=True)\n",
    "df_test.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 13983 entries, 65067453 to 76736011\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype   \n",
      "---  ------            --------------  -----   \n",
      " 0   localityName      13983 non-null  category\n",
      " 1   price             13983 non-null  Int64   \n",
      " 2   carpetArea        13983 non-null  Int64   \n",
      " 3   floorNumber       13983 non-null  Int64   \n",
      " 4   totalFloorNumber  13983 non-null  Int64   \n",
      " 5   transactionType   13983 non-null  category\n",
      " 6   furnished         13983 non-null  category\n",
      " 7   bedrooms          13983 non-null  Int64   \n",
      " 8   bathrooms         13983 non-null  Int64   \n",
      " 9   ageofcons         13983 non-null  category\n",
      "dtypes: Int64(6), category(4)\n",
      "memory usage: 925.2 KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['localityName'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['localityName'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3469 entries, 75987143 to 77784815\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype   \n",
      "---  ------            --------------  -----   \n",
      " 0   localityName      3469 non-null   category\n",
      " 1   price             3469 non-null   Int64   \n",
      " 2   carpetArea        3469 non-null   Int64   \n",
      " 3   floorNumber       3469 non-null   Int64   \n",
      " 4   totalFloorNumber  3469 non-null   Int64   \n",
      " 5   transactionType   3469 non-null   category\n",
      " 6   furnished         3469 non-null   category\n",
      " 7   bedrooms          3469 non-null   Int64   \n",
      " 8   bathrooms         3469 non-null   Int64   \n",
      " 9   ageofcons         3469 non-null   category\n",
      "dtypes: Int64(6), category(4)\n",
      "memory usage: 237.4 KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, TargetEncoder\n",
    "\n",
    "# Assume that df_train and df_test are your already cleaned and imputed datasets.\n",
    "X_train = df_train.drop(\"price\", axis=1)\n",
    "y_train = df_train[\"price\"]\n",
    "\n",
    "X_test = df_test.drop(\"price\", axis=1)\n",
    "y_test = df_test[\"price\"]\n",
    "\n",
    "# List of numeric features\n",
    "numeric_cols = [\n",
    "    \"carpetArea\",\n",
    "    \"floorNumber\",\n",
    "    \"totalFloorNumber\",\n",
    "    \"bedrooms\",\n",
    "    \"bathrooms\",\n",
    "]\n",
    "\n",
    "# For the two features that will be encoded differently:\n",
    "cat_diff_cols = [\"localityName\", \"transactionType\"]\n",
    "\n",
    "# The remaining categorical columns that are on an inherently ordinal scale.\n",
    "# Note: even though localityName might appear here, you may choose a different\n",
    "# encoding strategy depending on its cardinality. In this code, we are treating\n",
    "# it specially in the one-hot transformation.\n",
    "ordinal_cols = [\"furnished\", \"ageofcons\"]\n",
    "\n",
    "\n",
    "# You can now proceed to train your models using X_train_linear / X_train_tree and \n",
    "# evaluate using X_test_linear / X_test_tree.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Pipeline for linear models\n",
    "#   - Numerical features: standard scaled.\n",
    "#   - For transactionType, furnished: one-hot encoded.\n",
    "#   - For ordinal_cols (localityName, ageofcons): ordinal-encoded\n",
    "#     and then scaled (so that all features are on a similar scale).\n",
    "# =============================================================================\n",
    "\n",
    "# Define transformers\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "onehot_transformer = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "\n",
    "# Here we create a pipeline that first ordinal-encodes then scales the result.\n",
    "furnished_order = ['Unfurnished', 'Semi-Furnished', 'Furnished']\n",
    "ordinal_transformer_furnished = Pipeline(\n",
    "    steps=[\n",
    "        (\"ordinal\", OrdinalEncoder(categories=[furnished_order])),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# # Here we create a pipeline that first ordinal-encodes then scales the result.\n",
    "# ordinal_transformer_rs = Pipeline(\n",
    "#     steps=[\n",
    "#         (\"ordinal\", OrdinalEncoder()),\n",
    "#         (\"scaler\", StandardScaler()),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# Here we create a pipeline that first ordinal-encodes then scales the result.\n",
    "age_order = [\n",
    "    'Under Construction',  # first: youngest / newest state\n",
    "    'New Construction',\n",
    "    'Less than 5 years',\n",
    "    '5 to 10 years',\n",
    "    '10 to 15 years',\n",
    "    '15 to 20 years',\n",
    "    'Above 20 years'       # last: oldest\n",
    "]\n",
    "ordinal_transformer_ageofcons = Pipeline(\n",
    "    steps=[\n",
    "        (\"ordinal\", OrdinalEncoder(categories=[age_order])),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the ColumnTransformer for the linear pipeline.\n",
    "lin_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"onehot\", onehot_transformer, cat_diff_cols),\n",
    "        (\"ord-furnished\", ordinal_transformer_furnished, [\"furnished\"]),\n",
    "        # (\"ord-reservedparking\", ordinal_transformer_rs, [\"ReservedParking\"]),\n",
    "        (\"ord-ageofcons\", ordinal_transformer_ageofcons, [\"ageofcons\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# The overall pipeline (here you could add a linear model as the final estimator)\n",
    "lin_pipeline = Pipeline(steps=[(\"preprocessor\", lin_preprocessor)])\n",
    "\n",
    "# Now transform the training features for the linear model:\n",
    "X_train_linear = lin_pipeline.fit_transform(X_train)\n",
    "X_test_linear = lin_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree (numeric only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Pipeline for tree-based models\n",
    "#   - Numerical features: standard scaled.\n",
    "#   - For all categorical features (transactionType, furnished, ReservedParking,\n",
    "#     localityName, ageofcons): ordinal-encoded and then scaled.\n",
    "# =============================================================================\n",
    "\n",
    "# Create a pipeline for encoding the categorical features as ordinal then scaling.\n",
    "tree_cat_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"ordinal\", OrdinalEncoder()),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tree_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_cols),\n",
    "        (\"ord\", tree_cat_transformer, cat_diff_cols),\n",
    "        (\"ord-furnished\", ordinal_transformer_furnished, [\"furnished\"]),\n",
    "        # (\"ord-reservedparking\", ordinal_transformer_rs, [\"ReservedParking\"]),\n",
    "        (\"ord-ageofcons\", ordinal_transformer_ageofcons, [\"ageofcons\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tree_pipeline = Pipeline(steps=[(\"preprocessor\", tree_preprocessor)])\n",
    "# Now transform the training features for the tree models:\n",
    "\n",
    "X_train_tree = tree_pipeline.fit_transform(X_train)\n",
    "X_test_tree = tree_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree (numeric and categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create a pipeline that first ordinal-encodes then scales the result.\n",
    "furnished_order = ['Unfurnished', 'Semi-Furnished', 'Furnished']\n",
    "ordinal_transformer_furnished = Pipeline(\n",
    "    steps=[\n",
    "        (\"ordinal\", OrdinalEncoder(categories=[furnished_order])),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Here we create a pipeline that first ordinal-encodes then scales the result.\n",
    "age_order = [\n",
    "    'Under Construction',  # first: youngest / newest state\n",
    "    'New Construction',\n",
    "    'Less than 5 years',\n",
    "    '5 to 10 years',\n",
    "    '10 to 15 years',\n",
    "    '15 to 20 years',\n",
    "    'Above 20 years'       # last: oldest\n",
    "]\n",
    "ordinal_transformer_ageofcons = Pipeline(\n",
    "    steps=[\n",
    "        (\"ordinal\", OrdinalEncoder(categories=[age_order])),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tree_preprocessor_gb = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_cols),\n",
    "        (\"passthrough\", \"passthrough\", cat_diff_cols),\n",
    "        (\"ord-furnished\", ordinal_transformer_furnished, [\"furnished\"]),\n",
    "        # (\"ord-reservedparking\", ordinal_transformer_rs, [\"ReservedParking\"]),\n",
    "        (\"ord-ageofcons\", ordinal_transformer_ageofcons, [\"ageofcons\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tree_pipeline_gb = Pipeline(steps=[(\"preprocessor\", tree_preprocessor_gb)])\n",
    "# Now transform the training features for the tree models:\n",
    "X_train_gb = tree_pipeline_gb.fit_transform(X_train)\n",
    "X_test_gb = tree_pipeline_gb.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree + Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create a pipeline that first ordinal-encodes then scales the result.\n",
    "furnished_order = ['Unfurnished', 'Semi-Furnished', 'Furnished']\n",
    "ordinal_transformer_furnished = Pipeline(\n",
    "    steps=[\n",
    "        (\"ordinal\", OrdinalEncoder(categories=[furnished_order])),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "target_encoder_cats = Pipeline(\n",
    "    steps=[\n",
    "        (\n",
    "            \"target_encoder\",\n",
    "            TargetEncoder(\n",
    "                categories='auto',         # Auto-detect categories\n",
    "                target_type='continuous',  # Specify regression target\n",
    "                smooth='auto',             # Use empirical Bayes smoothing\n",
    "                cv=5,                      # Use 5-fold internal cross-fitting\n",
    "                shuffle=True,              # Shuffle data before folding\n",
    "                random_state=42            # For reproducible fold splits\n",
    "            )\n",
    "        ),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Here we create a pipeline that first ordinal-encodes then scales the result.\n",
    "age_order = [\n",
    "    'Under Construction',  # first: youngest / newest state\n",
    "    'New Construction',\n",
    "    'Less than 5 years',\n",
    "    '5 to 10 years',\n",
    "    '10 to 15 years',\n",
    "    '15 to 20 years',\n",
    "    'Above 20 years'       # last: oldest\n",
    "]\n",
    "ordinal_transformer_ageofcons = Pipeline(\n",
    "    steps=[\n",
    "        (\"ordinal\", OrdinalEncoder(categories=[age_order])),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tree_preprocessor_target = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_cols),\n",
    "        (\"cat_target\", target_encoder_cats, cat_diff_cols),\n",
    "        (\"ord-furnished\", ordinal_transformer_furnished, [\"furnished\"]),\n",
    "        (\"ord-ageofcons\", ordinal_transformer_ageofcons, [\"ageofcons\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tree_pipeline_target = Pipeline(steps=[(\"preprocessor\", tree_preprocessor_target)])\n",
    "# Now transform the training features for the tree models:\n",
    "X_train_target = tree_pipeline_target.fit_transform(X_train, y_train)\n",
    "X_test_target = tree_pipeline_target.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model feature shape: train: (13983, 233)\n",
      "Tree model feature shape: train: (13983, 9)\n",
      "Tree model for GB feature shape: train: (13983, 9)\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear model feature shape: train:\", X_train_linear.shape)\n",
    "print(\"Tree model feature shape: train:\", X_train_tree.shape)\n",
    "print(\"Tree model for GB feature shape: train:\", X_train_gb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Metrics and Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from sklearn.metrics import (mean_absolute_error,\n",
    "                             mean_absolute_percentage_error,\n",
    "                             r2_score,\n",
    "                             make_scorer)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.base import clone\n",
    "\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Ignore warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Custom adjusted R2 scorer\n",
    "# ---------------------------------------------\n",
    "def adjusted_r2_scoring(estimator, X, y):\n",
    "    \"\"\"\n",
    "    Scoring function that computes adjusted R2.\n",
    "    \"\"\"\n",
    "    y_pred = estimator.predict(X)\n",
    "    base_r2 = r2_score(y, y_pred)\n",
    "    n = len(y)\n",
    "    p = X.shape[1]\n",
    "    if (n - p - 1) == 0:\n",
    "        return base_r2\n",
    "    adj_r2 = 1 - (1 - base_r2) * ((n - 1) / (n - p - 1))\n",
    "    print(f\"Adjusted R2 score: {adj_r2:.4f}\")\n",
    "    return adj_r2\n",
    "\n",
    "\n",
    "adj_r2_scorer = make_scorer(adjusted_r2_scoring, greater_is_better=True)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Define scoring dictionary for GridSearchCV.\n",
    "# Note: For MAE and MAPE, we use the negative built-in scorers\n",
    "# so that “higher” is better.\n",
    "# ---------------------------------------------\n",
    "scoring = {\n",
    "    \"MAE\": \"neg_mean_absolute_error\",\n",
    "    \"MAPE\": \"neg_mean_absolute_percentage_error\",\n",
    "    \"R2\": \"r2\",\n",
    "    # \"adj_R2\": adj_r2_scorer,\n",
    "}\n",
    "\n",
    "# Global dictionary to store results\n",
    "results_dict = {}\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Function to run GridSearchCV and store metrics\n",
    "# ---------------------------------------------\n",
    "def run_grid_search(model, param_grid, X_train, y_train, X_test, y_test, \n",
    "                    model_name):\n",
    "    \"\"\"\n",
    "    Performs grid search with the given estimator and parameter grid, \n",
    "    computes cross validation and test metrics, then stores the results \n",
    "    in the global dictionary.\n",
    "    \"\"\"\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        scoring=scoring,\n",
    "        cv=5,\n",
    "        refit=\"MAE\",  # refit based on neg MAE (i.e. lower MAE is higher -MAE)\n",
    "        return_train_score=True,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    if model not in [\"LightGBM\"]: \n",
    "        grid_search.fit(X_train, y_train)\n",
    "    else:\n",
    "        grid_search.fit(X_train, y_train, categorical_feature = ['localityName', 'transactionType'])\n",
    "    best_index = grid_search.best_index_\n",
    "    # Note: The built-in scorers return negative error values.\n",
    "    cv_scores = {\n",
    "        \"MAE\": -grid_search.cv_results_[\"mean_test_MAE\"][best_index],\n",
    "        \"MAPE\": -grid_search.cv_results_[\"mean_test_MAPE\"][best_index],\n",
    "        \"R2\": grid_search.cv_results_[\"mean_test_R2\"][best_index],\n",
    "        # \"adj_R2\": grid_search.cv_results_[\"mean_test_adj_R2\"][best_index],\n",
    "    }\n",
    "\n",
    "    # Evaluate on test data\n",
    "    y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "    test_mae = np.abs(y_test - y_pred)\n",
    "    test_mape = (np.abs(y_test - y_pred) / (np.abs(y_test) + 1e-10))*100\n",
    "    test_r2 = r2_score(y_test, y_pred)\n",
    "    n_test = len(y_test)\n",
    "    p_test = X_test.shape[1]\n",
    "    test_adj_r2 = (\n",
    "        1 - (1 - test_r2) * ((n_test - 1) / (n_test - p_test - 1))\n",
    "        if (n_test - p_test - 1) != 0\n",
    "        else test_r2\n",
    "    )\n",
    "\n",
    "    results_dict[model_name] = {\n",
    "        \"best_params\": grid_search.best_params_,\n",
    "        \"cv_scores\": cv_scores,\n",
    "        \"test_scores\": {\n",
    "            \"MAE\": test_mae,\n",
    "            \"MAPE\": test_mape,\n",
    "            \"R2\": test_r2,\n",
    "            \"adj_R2\": test_adj_r2,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    return grid_search\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Function to run the passed model with default settings.\n",
    "# ---------------------------------------------\n",
    "def run_default_model(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    \"\"\"\n",
    "    Trains the provided model with default parameters on the training set\n",
    "    and evaluates it on the test set. The evaluation metrics are then stored\n",
    "    in the global results_dict under the key '<model_name>_default'.\n",
    "    \"\"\"\n",
    "    # Create a fresh copy of the model using clone()\n",
    "    default_model = clone(model)\n",
    "\n",
    "    # If the model is CatBoost or LightGBM, handle categorical features.\n",
    "    if model_name == 'LightGBM':\n",
    "        default_model.fit(X_train, y_train, categorical_feature=[\"localityName\", 'transactionType'])\n",
    "    else:\n",
    "        default_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = default_model.predict(X_test)\n",
    "    test_mae = np.abs(y_test - y_pred)\n",
    "    test_mape = (np.abs(y_test - y_pred) / (np.abs(y_test) + 1e-10)) * 100\n",
    "    test_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    n_test = len(y_test)\n",
    "    p_test = X_test.shape[1]\n",
    "    test_adj_r2 = (\n",
    "        1 - (1 - test_r2) * ((n_test - 1) / (n_test - p_test - 1))\n",
    "        if (n_test - p_test - 1) != 0\n",
    "        else test_r2\n",
    "    )\n",
    "\n",
    "    if results_dict.get(model_name) is None:\n",
    "        results_dict[model_name] = {'default':{}}\n",
    "    results_dict[model_name]['default'] = {\n",
    "        \"test_scores\": {\n",
    "            \"MAE\": test_mae,\n",
    "            \"MAPE\": test_mape,\n",
    "            \"R2\": test_r2,\n",
    "            \"adj_R2\": test_adj_r2,\n",
    "        }\n",
    "    }\n",
    "# ===============================================================\n",
    "# Use the appropriate training/testing sets according to the model:\n",
    "# 1. Linear, ElasticNet, and KNN will use the \"linear\" set.\n",
    "# 2. Decision Tree, Random Forest, XGBoost, and XGB RF will use the\n",
    "#    \"tree\" set.\n",
    "# 3. CatBoost and LightGBM will use the \"GB\" set.\n",
    "# ==============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Linear Regression (no hyperparameter tuning required)\n",
    "lin_reg = LinearRegression()\n",
    "# No hyperparameters to tune; we use an empty grid\n",
    "run_grid_search(\n",
    "    lin_reg, {}, X_train_linear, y_train, X_test_linear, y_test,\n",
    "    \"LinearRegression\"\n",
    ")\n",
    "run_default_model(\n",
    "    lin_reg, X_train_linear, y_train, X_test_linear, y_test, \"LinearRegression\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ElasticNet\n",
    "elastic_net = ElasticNet(random_state=42, max_iter=10000)\n",
    "param_grid_en = {\n",
    "    \"alpha\": [0.1, 0.5, 0.75, 1.0, 2.0, 2.5, 5.0, 10.0],\n",
    "    \"l1_ratio\": [0.1, 0.2, 0.4, 0.6, 0.8, 0.9],\n",
    "}\n",
    "grid_search = run_grid_search(\n",
    "    elastic_net, param_grid_en, X_train_linear, y_train, X_test_linear, y_test,\n",
    "    \"ElasticNet\"\n",
    ")\n",
    "run_default_model(\n",
    "    elastic_net, X_train_linear, y_train, X_test_linear, y_test, \"ElasticNet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Decision Tree Regressor\n",
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "param_grid_dt = {\n",
    "    \"max_depth\": [None, 5, 10, 20, 25, 35, 50],\n",
    "    \"min_samples_split\": [2, 5, 10, 15],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 6],\n",
    "}\n",
    "run_grid_search(\n",
    "    dt, param_grid_dt, X_train_tree, y_train, X_test_tree, y_test,\n",
    "    \"DecisionTree\"\n",
    ")\n",
    "run_default_model(\n",
    "    dt, X_train_tree, y_train, X_test_tree, y_test, \"DecisionTree\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 6. XGBoost Regressor\n",
    "# xgb_reg = xgb.XGBRegressor(\n",
    "#     objective=\"reg:squarederror\",\n",
    "#     random_state=42,\n",
    "#     verbosity=0,\n",
    "# )\n",
    "# param_grid_xgb = {\n",
    "#     \"n_estimators\": [100, 150, 200, 250, 300, 500],\n",
    "#     \"max_depth\": [3, 5, 7],\n",
    "#     \"max_leaves\": [0, 10, 25, 50],\n",
    "#     \"learning_rate\": [0.01, 0.05, 0.1, 0.2, 0.3, 0.5],\n",
    "#     \"subsample\": [0.8, 1.0],\n",
    "# }\n",
    "# grid_search = run_grid_search(\n",
    "#     xgb_reg, param_grid_xgb, X_train_linear, y_train, X_test_linear, y_test,\n",
    "#     \"XGBoostRegressor_Linear\"\n",
    "# )\n",
    "# run_default_model(\n",
    "#     xgb_reg, X_train_linear, y_train, X_test_linear, y_test, \"XGBoostRegressor_Linear\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. XGBoost Regressor\n",
    "xgb_reg = xgb.XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42,\n",
    "    verbosity=0,\n",
    ")\n",
    "param_grid_xgb = {\n",
    "    \"n_estimators\": [100, 150, 200, 250, 300, 500], # \n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"max_leaves\": [0, 10, 25, 50],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1, 0.2, 0.3, 0.5],\n",
    "    \"subsample\": [0.8, 1.0],\n",
    "}\n",
    "grid_search = run_grid_search(\n",
    "    xgb_reg, param_grid_xgb, X_train_tree, y_train, X_test_tree, y_test,\n",
    "    \"XGBoostRegressor\"\n",
    ")\n",
    "run_default_model(\n",
    "    xgb_reg, X_train_tree, y_train, X_test_tree, y_test, \"XGBoostRegressor\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree + Target Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. XGBoost Regressor\n",
    "xgb_reg = xgb.XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42,\n",
    "    verbosity=0,\n",
    ")\n",
    "param_grid_xgb = {\n",
    "    \"n_estimators\": [100, 150, 200, 250, 300, 500],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"max_leaves\": [0, 10, 25, 50],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1, 0.2, 0.3, 0.5],\n",
    "    \"subsample\": [0.8, 1.0],\n",
    "}\n",
    "grid_search = run_grid_search(\n",
    "    xgb_reg, param_grid_xgb, X_train_target, y_train, X_test_target, y_test,\n",
    "    \"XGBoostRegressor_Target\"\n",
    ")\n",
    "run_default_model(\n",
    "    xgb_reg, X_train_target, y_train, X_test_target, y_test, \"XGBoostRegressor_Target\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13983 entries, 0 to 13982\n",
      "Columns: 233 entries, 0 to 232\n",
      "dtypes: float64(233)\n",
      "memory usage: 24.9 MB\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(X_train_linear).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Random Forest Regressor\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "param_grid_rf = {\n",
    "    \"n_estimators\": [100, 150, 200],\n",
    "    \"max_depth\": [None, 10, 20],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2],\n",
    "}\n",
    "run_grid_search(\n",
    "    rf, param_grid_rf, X_train_tree, y_train, X_test_tree, y_test,\n",
    "    \"RandomForest\"\n",
    ")\n",
    "run_default_model(\n",
    "    rf, X_train_tree, y_train, X_test_tree, y_test, \"RandomForest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. K-Nearest Neighbors (KNN)\n",
    "knn = KNeighborsRegressor()\n",
    "param_grid_knn = {\n",
    "    \"n_neighbors\": [10, 20, 30, 40, 50],\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"algorithm\": [\"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "    \"p\": [1, 2],\n",
    "}\n",
    "#run_grid_search(\n",
    "#    knn, param_grid_knn, X_train_linear, y_train, X_test_linear, y_test, \"KNN\"\n",
    "#)\n",
    "run_default_model(\n",
    "    knn, X_train_linear, y_train, X_test_linear, y_test, \"KNN\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. XGBoost Random Forest Regressor\n",
    "xgb_rf = xgb.XGBRFRegressor(\n",
    "    random_state=42,\n",
    "    verbosity=0,\n",
    ")\n",
    "param_grid_xgb_rf = {\n",
    "    \"n_estimators\": [100, 150, 200],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"subsample\": [0.8, 1.0],\n",
    "}\n",
    "run_grid_search(\n",
    "    xgb_rf, param_grid_xgb_rf, X_train_tree, y_train, X_test_tree, y_test,\n",
    "    \"XGBoostRFRegressor\"\n",
    ")\n",
    "run_default_model(\n",
    "    xgb_rf, X_train_tree, y_train, X_test_tree, y_test, \"XGBoostRFRegressor\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Tree dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000820 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 588\n",
      "[LightGBM] [Info] Number of data points in the train set: 13983, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11030358.469284\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 588\n",
      "[LightGBM] [Info] Number of data points in the train set: 13983, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11030358.469284\n"
     ]
    }
   ],
   "source": [
    "# 9. LightGBM Regressor\n",
    "lgbm_reg = lgb.LGBMRegressor(random_state=42)\n",
    "param_grid_lgb = {\n",
    "    \"n_estimators\": [100, 150, 200, 300, 500],\n",
    "    \"max_depth\": [-1, 3, 5, 7],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "run_grid_search(\n",
    "    lgbm_reg, param_grid_lgb, X_train_tree, y_train, X_test_tree, y_test, \n",
    "    \"LightGBM_encoded\"\n",
    ")\n",
    "run_default_model(\n",
    "    lgbm_reg, X_train_tree, y_train, X_test_tree, y_test, \"LightGBM_encoded\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree + Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 628\n",
      "[LightGBM] [Info] Number of data points in the train set: 13983, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11030358.469284\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 628\n",
      "[LightGBM] [Info] Number of data points in the train set: 13983, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11030358.469284\n"
     ]
    }
   ],
   "source": [
    "# 9. LightGBM Regressor\n",
    "lgbm_reg = lgb.LGBMRegressor(random_state=42)\n",
    "param_grid_lgb = {\n",
    "    \"n_estimators\": [100, 150, 200, 300, 500],\n",
    "    \"max_depth\": [-1, 3, 5, 7],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "run_grid_search(\n",
    "    lgbm_reg, param_grid_lgb, X_train_target, y_train, X_test_target, y_test,\n",
    "    \"LightGBM_target\"\n",
    ")\n",
    "run_default_model(\n",
    "    lgbm_reg, X_train_target, y_train, X_test_target, y_test, \"LightGBM_target\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With unencoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 588\n",
      "[LightGBM] [Info] Number of data points in the train set: 13983, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11030358.469284\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 588\n",
      "[LightGBM] [Info] Number of data points in the train set: 13983, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 11030358.469284\n"
     ]
    }
   ],
   "source": [
    "# 9. LightGBM Regressor\n",
    "lgbm_reg = lgb.LGBMRegressor(random_state=42)\n",
    "param_grid_lgb = {\n",
    "    \"n_estimators\": [100, 150, 200, 300, 500],\n",
    "    \"max_depth\": [-1, 3, 5, 7],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "mapping = {\n",
    "    \"carpetArea\": pd.Float64Dtype(),\n",
    "    \"floorNumber\": pd.Float64Dtype(),\n",
    "    \"totalFloorNumber\": pd.Float64Dtype(),\n",
    "    \"bedrooms\": pd.Float64Dtype(),\n",
    "    \"bathrooms\": pd.Float64Dtype(),\n",
    "    \"localityName\": 'category',\n",
    "    \"transactionType\": 'category',\n",
    "    \"furnished\": pd.Float64Dtype(),\n",
    "    \"ageofcons\": pd.Float64Dtype(),\n",
    "}\n",
    "X_train_gb_df = pd.DataFrame(X_train_gb, columns = numeric_cols + cat_diff_cols + ordinal_cols).astype(mapping)\n",
    "X_test_gb_df = pd.DataFrame(X_test_gb,  columns = numeric_cols + cat_diff_cols + ordinal_cols).astype(mapping)\n",
    "y_train_df = pd.Series(y_train)\n",
    "y_test_df = pd.Series(y_test)\n",
    "\n",
    "run_grid_search(\n",
    "    lgbm_reg, param_grid_lgb, X_train_gb_df, y_train_df, X_test_gb_df, y_test_df,\n",
    "    \"LightGBM\"\n",
    ")\n",
    "run_default_model(\n",
    "    lgbm_reg, X_train_gb_df, y_train_df, X_test_gb_df, y_test_df, \"LightGBM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Tree data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 8. CatBoost Regressor\n",
    "# catboost_reg = CatBoostRegressor(random_state=42, verbose=0)\n",
    "# param_grid_cat = {\n",
    "#     \"iterations\": [250, 500],\n",
    "#     \"depth\": [3, 5, 7],\n",
    "#     \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "# }\n",
    "\n",
    "# run_grid_search(\n",
    "#     catboost_reg, param_grid_cat, X_train_tree, y_train, X_test_tree, y_test,\n",
    "#     \"CatBoost_encoded\"\n",
    "# )\n",
    "# run_default_model(\n",
    "#     catboost_reg, X_train_tree, y_train, X_test_tree, y_test, \"CatBoost_encoded\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With unencoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. CatBoost Regressor\n",
    "catboost_reg = CatBoostRegressor(random_state=42, verbose=0, cat_features = ['localityName', 'transactionType'])\n",
    "param_grid_cat = {\n",
    "    \"iterations\": [250, 500],\n",
    "    \"depth\": [3, 5, 7],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "}\n",
    "mapping = {\n",
    "    \"carpetArea\": pd.Float64Dtype(),\n",
    "    \"floorNumber\": pd.Float64Dtype(),\n",
    "    \"totalFloorNumber\": pd.Float64Dtype(),\n",
    "    \"bedrooms\": pd.Float64Dtype(),\n",
    "    \"bathrooms\": pd.Float64Dtype(),\n",
    "    \"localityName\": 'category',\n",
    "    \"transactionType\": 'category',\n",
    "    \"furnished\": pd.Float64Dtype(),\n",
    "    \"ageofcons\": pd.Float64Dtype(),\n",
    "}\n",
    "X_train_gb_df = pd.DataFrame(X_train_gb, columns = numeric_cols + cat_diff_cols + ordinal_cols).astype(mapping)\n",
    "X_test_gb_df = pd.DataFrame(X_test_gb,  columns = numeric_cols + cat_diff_cols + ordinal_cols).astype(mapping)\n",
    "y_train_df = pd.Series(y_train)\n",
    "y_test_df = pd.Series(y_test)\n",
    "run_grid_search(\n",
    "    catboost_reg, param_grid_cat, X_train_gb_df, y_train_df, X_test_gb_df, y_test_df,\n",
    "    \"CatBoost\"\n",
    ")\n",
    "run_default_model(\n",
    "    catboost_reg, X_train_gb_df, y_train_df, X_test_gb_df, y_test_df, \"CatBoost\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Hyperparameter Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameter config for all models:\n",
      "\n",
      "XGBoostRegressor: {'learning_rate': 0.2, 'max_depth': 5, 'max_leaves': 0, 'n_estimators': 500, 'subsample': 1.0}\n",
      "LightGBM_encoded: {'learning_rate': 0.2, 'max_depth': -1, 'n_estimators': 500}\n",
      "LightGBM: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameter config for all models:\\n\")\n",
    "for model, values in results_dict.items():\n",
    "    print(f\"{model}: {values['best_params'] if values.get('best_params') else 'N/A'}\")\n",
    "\n",
    "with open(\"Results/BestHyperparameters.txt\", \"w\") as f:\n",
    "    for model, values in results_dict.items():\n",
    "        f.write(f\"{model}: {values['best_params'] if values.get('best_params') else 'N/A'}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV scores for best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>1.573628e+06</td>\n",
       "      <td>0.150681</td>\n",
       "      <td>0.917920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoostRegressor</th>\n",
       "      <td>1.604337e+06</td>\n",
       "      <td>0.154164</td>\n",
       "      <td>0.913222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM_encoded</th>\n",
       "      <td>1.669862e+06</td>\n",
       "      <td>0.158222</td>\n",
       "      <td>0.907645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MAE      MAPE        R2\n",
       "index                                             \n",
       "LightGBM          1.573628e+06  0.150681  0.917920\n",
       "XGBoostRegressor  1.604337e+06  0.154164  0.913222\n",
       "LightGBM_encoded  1.669862e+06  0.158222  0.907645"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = {\n",
    "    \"index\":[],\n",
    "    'MAE':[],\n",
    "    'MAPE':[],\n",
    "    'R2':[],\n",
    "}\n",
    "for model, values in results_dict.items():\n",
    "    if values.get('cv_scores') is None:\n",
    "        continue\n",
    "    temp['index'].append(model)\n",
    "    temp['MAE'].append(values['cv_scores']['MAE'])\n",
    "    temp['MAPE'].append(values['cv_scores']['MAPE'])\n",
    "    temp['R2'].append(values['cv_scores']['R2'])\n",
    "\n",
    "cv_scores = pd.DataFrame(temp).set_index('index')\n",
    "# cv_scores.sort_values(by='MAPE', ascending=True).to_csv(\"Results/cv_scores.csv\", index=True)\n",
    "cv_scores.sort_values(by='MAPE', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test scores for Best Hyperparameter Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_percentiles = sorted({0.05, 0.1, 0.2, 0.25, 0.5, 0.75, 0.8, 0.9, 0.95})\n",
    "\n",
    "# Initialize dictionaries to store the summaries for each metric.\n",
    "mae_data = {}\n",
    "mape_data = {}\n",
    "r2_data = {}\n",
    "adj_r2_data = {}\n",
    "\n",
    "# Loop over each model in your results_dict.\n",
    "for model_name, model_results in results_dict.items():\n",
    "\n",
    "    if model_results.get('test_scores') is None:\n",
    "        continue\n",
    "\n",
    "    # Get the dictionary that contains the test scores.\n",
    "    test_scores = model_results['test_scores']\n",
    "    \n",
    "    # For each metric, compute the descriptive statistics using .describe.\n",
    "    # pd.Series.describe returns a Series with index: count, mean, std, min,\n",
    "    # the provided percentiles, and max.\n",
    "    mae_data[model_name] = pd.Series(test_scores['MAE']).describe(\n",
    "        percentiles=custom_percentiles\n",
    "    )\n",
    "    mape_data[model_name] = pd.Series(test_scores['MAPE']).describe(\n",
    "        percentiles=custom_percentiles\n",
    "    )\n",
    "    r2_data[model_name] = pd.Series(test_scores['R2']).describe(\n",
    "        percentiles=custom_percentiles\n",
    "    )\n",
    "    adj_r2_data[model_name] = pd.Series(test_scores['adj_R2']).describe(\n",
    "        percentiles=custom_percentiles\n",
    "    )\n",
    "\n",
    "# Now, create dataframes for each metric with the model names as the index.\n",
    "mae_df = pd.DataFrame.from_dict(mae_data, orient=\"index\")\n",
    "mape_df = pd.DataFrame.from_dict(mape_data, orient=\"index\")\n",
    "r2_df = pd.DataFrame.from_dict(r2_data, orient=\"index\")\n",
    "adj_r2_df = pd.DataFrame.from_dict(adj_r2_data, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count             3469.0\n",
       "mean       11362982.3661\n",
       "std      12005742.076629\n",
       "min             900000.0\n",
       "25%            5000000.0\n",
       "50%            8000000.0\n",
       "75%           13000000.0\n",
       "max          150000000.0\n",
       "Name: price, dtype: Float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>5%</th>\n",
       "      <th>10%</th>\n",
       "      <th>20%</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>80%</th>\n",
       "      <th>90%</th>\n",
       "      <th>95%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>3.469</td>\n",
       "      <td>1628.232156</td>\n",
       "      <td>2857.112330</td>\n",
       "      <td>0.378945</td>\n",
       "      <td>67.089893</td>\n",
       "      <td>128.568938</td>\n",
       "      <td>277.166458</td>\n",
       "      <td>354.043502</td>\n",
       "      <td>815.833692</td>\n",
       "      <td>1757.115044</td>\n",
       "      <td>2136.204932</td>\n",
       "      <td>3608.283156</td>\n",
       "      <td>5767.345292</td>\n",
       "      <td>51201.842330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM_encoded</th>\n",
       "      <td>3.469</td>\n",
       "      <td>1692.603270</td>\n",
       "      <td>3047.074635</td>\n",
       "      <td>1.651833</td>\n",
       "      <td>74.294989</td>\n",
       "      <td>145.276532</td>\n",
       "      <td>293.222155</td>\n",
       "      <td>366.032721</td>\n",
       "      <td>819.579929</td>\n",
       "      <td>1818.752514</td>\n",
       "      <td>2290.261989</td>\n",
       "      <td>3650.734544</td>\n",
       "      <td>5875.858319</td>\n",
       "      <td>54205.505606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoostRegressor</th>\n",
       "      <td>3.469</td>\n",
       "      <td>1661.999798</td>\n",
       "      <td>3076.256228</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>70.563150</td>\n",
       "      <td>148.303400</td>\n",
       "      <td>289.480650</td>\n",
       "      <td>366.231000</td>\n",
       "      <td>826.701000</td>\n",
       "      <td>1741.529000</td>\n",
       "      <td>2125.363600</td>\n",
       "      <td>3603.749200</td>\n",
       "      <td>6021.356400</td>\n",
       "      <td>76129.312000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count         mean          std       min         5%  \\\n",
       "LightGBM          3.469  1628.232156  2857.112330  0.378945  67.089893   \n",
       "LightGBM_encoded  3.469  1692.603270  3047.074635  1.651833  74.294989   \n",
       "XGBoostRegressor  3.469  1661.999798  3076.256228  0.118000  70.563150   \n",
       "\n",
       "                         10%         20%         25%         50%          75%  \\\n",
       "LightGBM          128.568938  277.166458  354.043502  815.833692  1757.115044   \n",
       "LightGBM_encoded  145.276532  293.222155  366.032721  819.579929  1818.752514   \n",
       "XGBoostRegressor  148.303400  289.480650  366.231000  826.701000  1741.529000   \n",
       "\n",
       "                          80%          90%          95%           max  \n",
       "LightGBM          2136.204932  3608.283156  5767.345292  51201.842330  \n",
       "LightGBM_encoded  2290.261989  3650.734544  5875.858319  54205.505606  \n",
       "XGBoostRegressor  2125.363600  3603.749200  6021.356400  76129.312000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mae_df/1000).sort_values(by=\"50%\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>5%</th>\n",
       "      <th>10%</th>\n",
       "      <th>20%</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>80%</th>\n",
       "      <th>90%</th>\n",
       "      <th>95%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>3469.0</td>\n",
       "      <td>14.868410</td>\n",
       "      <td>15.453179</td>\n",
       "      <td>0.010827</td>\n",
       "      <td>0.941432</td>\n",
       "      <td>1.906193</td>\n",
       "      <td>3.716854</td>\n",
       "      <td>4.765630</td>\n",
       "      <td>10.458317</td>\n",
       "      <td>19.904110</td>\n",
       "      <td>22.589038</td>\n",
       "      <td>32.567333</td>\n",
       "      <td>42.610134</td>\n",
       "      <td>221.775446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoostRegressor</th>\n",
       "      <td>3469.0</td>\n",
       "      <td>14.954389</td>\n",
       "      <td>14.688738</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>1.016924</td>\n",
       "      <td>1.994360</td>\n",
       "      <td>4.112759</td>\n",
       "      <td>5.087438</td>\n",
       "      <td>10.823944</td>\n",
       "      <td>20.093266</td>\n",
       "      <td>22.752502</td>\n",
       "      <td>32.940537</td>\n",
       "      <td>41.498062</td>\n",
       "      <td>149.510590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM_encoded</th>\n",
       "      <td>3469.0</td>\n",
       "      <td>15.222631</td>\n",
       "      <td>14.939056</td>\n",
       "      <td>0.012609</td>\n",
       "      <td>1.042912</td>\n",
       "      <td>2.070999</td>\n",
       "      <td>4.105897</td>\n",
       "      <td>5.127227</td>\n",
       "      <td>10.929158</td>\n",
       "      <td>20.249350</td>\n",
       "      <td>23.341647</td>\n",
       "      <td>33.790781</td>\n",
       "      <td>42.922273</td>\n",
       "      <td>137.162541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count       mean        std       min        5%       10%  \\\n",
       "LightGBM          3469.0  14.868410  15.453179  0.010827  0.941432  1.906193   \n",
       "XGBoostRegressor  3469.0  14.954389  14.688738  0.001124  1.016924  1.994360   \n",
       "LightGBM_encoded  3469.0  15.222631  14.939056  0.012609  1.042912  2.070999   \n",
       "\n",
       "                       20%       25%        50%        75%        80%  \\\n",
       "LightGBM          3.716854  4.765630  10.458317  19.904110  22.589038   \n",
       "XGBoostRegressor  4.112759  5.087438  10.823944  20.093266  22.752502   \n",
       "LightGBM_encoded  4.105897  5.127227  10.929158  20.249350  23.341647   \n",
       "\n",
       "                        90%        95%         max  \n",
       "LightGBM          32.567333  42.610134  221.775446  \n",
       "XGBoostRegressor  32.940537  41.498062  149.510590  \n",
       "LightGBM_encoded  33.790781  42.922273  137.162541  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape_df.sort_values(by=\"90%\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>5%</th>\n",
       "      <th>10%</th>\n",
       "      <th>20%</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>80%</th>\n",
       "      <th>90%</th>\n",
       "      <th>95%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.924968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.924968</td>\n",
       "      <td>0.924968</td>\n",
       "      <td>0.924968</td>\n",
       "      <td>0.924968</td>\n",
       "      <td>0.924968</td>\n",
       "      <td>0.924968</td>\n",
       "      <td>0.924968</td>\n",
       "      <td>0.924968</td>\n",
       "      <td>0.924968</td>\n",
       "      <td>0.924968</td>\n",
       "      <td>0.924968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM_encoded</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.915703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.915703</td>\n",
       "      <td>0.915703</td>\n",
       "      <td>0.915703</td>\n",
       "      <td>0.915703</td>\n",
       "      <td>0.915703</td>\n",
       "      <td>0.915703</td>\n",
       "      <td>0.915703</td>\n",
       "      <td>0.915703</td>\n",
       "      <td>0.915703</td>\n",
       "      <td>0.915703</td>\n",
       "      <td>0.915703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoostRegressor</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>0.915176</td>\n",
       "      <td>0.915176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count      mean  std       min        5%       10%  \\\n",
       "LightGBM            1.0  0.924968  NaN  0.924968  0.924968  0.924968   \n",
       "LightGBM_encoded    1.0  0.915703  NaN  0.915703  0.915703  0.915703   \n",
       "XGBoostRegressor    1.0  0.915176  NaN  0.915176  0.915176  0.915176   \n",
       "\n",
       "                       20%       25%       50%       75%       80%       90%  \\\n",
       "LightGBM          0.924968  0.924968  0.924968  0.924968  0.924968  0.924968   \n",
       "LightGBM_encoded  0.915703  0.915703  0.915703  0.915703  0.915703  0.915703   \n",
       "XGBoostRegressor  0.915176  0.915176  0.915176  0.915176  0.915176  0.915176   \n",
       "\n",
       "                       95%       max  \n",
       "LightGBM          0.924968  0.924968  \n",
       "LightGBM_encoded  0.915703  0.915703  \n",
       "XGBoostRegressor  0.915176  0.915176  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_df.sort_values(by=\"50%\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test scores for models with default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_percentiles = sorted({0.05, 0.1, 0.2, 0.25, 0.5, 0.75, 0.8, 0.9, 0.95})\n",
    "\n",
    "# Initialize dictionaries to store the summaries for each metric.\n",
    "mae_data = {}\n",
    "mape_data = {}\n",
    "r2_data = {}\n",
    "adj_r2_data = {}\n",
    "\n",
    "# Loop over each model in your results_dict.\n",
    "for model_name, model_results in results_dict.items():\n",
    "\n",
    "    if model_results.get('default') is None:\n",
    "        continue\n",
    "\n",
    "    # Get the dictionary that contains the test scores.\n",
    "    test_scores = model_results['default']['test_scores']\n",
    "    \n",
    "    # For each metric, compute the descriptive statistics using .describe.\n",
    "    # pd.Series.describe returns a Series with index: count, mean, std, min,\n",
    "    # the provided percentiles, and max.\n",
    "    mae_data[model_name] = pd.Series(test_scores['MAE']).describe(\n",
    "        percentiles=custom_percentiles\n",
    "    )\n",
    "    mape_data[model_name] = pd.Series(test_scores['MAPE']).describe(\n",
    "        percentiles=custom_percentiles\n",
    "    )\n",
    "    r2_data[model_name] = pd.Series(test_scores['R2']).describe(\n",
    "        percentiles=custom_percentiles\n",
    "    )\n",
    "    adj_r2_data[model_name] = pd.Series(test_scores['adj_R2']).describe(\n",
    "        percentiles=custom_percentiles\n",
    "    )\n",
    "\n",
    "# Now, create dataframes for each metric with the model names as the index.\n",
    "mae_df = pd.DataFrame.from_dict(mae_data, orient=\"index\")\n",
    "mape_df = pd.DataFrame.from_dict(mape_data, orient=\"index\")\n",
    "r2_df = pd.DataFrame.from_dict(r2_data, orient=\"index\")\n",
    "adj_r2_df = pd.DataFrame.from_dict(adj_r2_data, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LightGBM_encoded</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>XGBoostRegressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3469.000000</td>\n",
       "      <td>3469.000000</td>\n",
       "      <td>3469.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17.182531</td>\n",
       "      <td>15.412704</td>\n",
       "      <td>15.545680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17.035502</td>\n",
       "      <td>15.923893</td>\n",
       "      <td>15.204562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.002895</td>\n",
       "      <td>0.004263</td>\n",
       "      <td>0.000357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5%</th>\n",
       "      <td>1.009988</td>\n",
       "      <td>0.888883</td>\n",
       "      <td>0.952234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>2.090490</td>\n",
       "      <td>1.946408</td>\n",
       "      <td>1.909942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20%</th>\n",
       "      <td>4.419424</td>\n",
       "      <td>4.040612</td>\n",
       "      <td>4.032719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.660052</td>\n",
       "      <td>5.233697</td>\n",
       "      <td>5.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.441651</td>\n",
       "      <td>10.938554</td>\n",
       "      <td>11.374674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22.868418</td>\n",
       "      <td>20.428784</td>\n",
       "      <td>20.962187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>26.571962</td>\n",
       "      <td>23.606596</td>\n",
       "      <td>24.047997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>37.799729</td>\n",
       "      <td>33.317841</td>\n",
       "      <td>33.946722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>49.485812</td>\n",
       "      <td>43.989460</td>\n",
       "      <td>44.916744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>173.920725</td>\n",
       "      <td>226.227207</td>\n",
       "      <td>148.030784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LightGBM_encoded     LightGBM  XGBoostRegressor\n",
       "count       3469.000000  3469.000000       3469.000000\n",
       "mean          17.182531    15.412704         15.545680\n",
       "std           17.035502    15.923893         15.204562\n",
       "min            0.002895     0.004263          0.000357\n",
       "5%             1.009988     0.888883          0.952234\n",
       "10%            2.090490     1.946408          1.909942\n",
       "20%            4.419424     4.040612          4.032719\n",
       "25%            5.660052     5.233697          5.187500\n",
       "50%           12.441651    10.938554         11.374674\n",
       "75%           22.868418    20.428784         20.962187\n",
       "80%           26.571962    23.606596         24.047997\n",
       "90%           37.799729    33.317841         33.946722\n",
       "95%           49.485812    43.989460         44.916744\n",
       "max          173.920725   226.227207        148.030784"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinearRegression</th>\n",
       "      <th>ElasticNet</th>\n",
       "      <th>DecisionTree</th>\n",
       "      <th>XGBoostRegressor</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>KNN</th>\n",
       "      <th>XGBoostRFRegressor</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>CatBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3469.000000</td>\n",
       "      <td>3469.000000</td>\n",
       "      <td>3469.000000</td>\n",
       "      <td>3469.000000</td>\n",
       "      <td>3469.000000</td>\n",
       "      <td>3469.000000</td>\n",
       "      <td>3469.000000</td>\n",
       "      <td>3469.000000</td>\n",
       "      <td>3469.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>25.115170</td>\n",
       "      <td>34.262142</td>\n",
       "      <td>23.104223</td>\n",
       "      <td>15.545680</td>\n",
       "      <td>17.568837</td>\n",
       "      <td>19.408405</td>\n",
       "      <td>23.212094</td>\n",
       "      <td>15.412704</td>\n",
       "      <td>15.746216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28.513756</td>\n",
       "      <td>29.163628</td>\n",
       "      <td>27.685499</td>\n",
       "      <td>15.204562</td>\n",
       "      <td>18.203948</td>\n",
       "      <td>18.860335</td>\n",
       "      <td>21.429049</td>\n",
       "      <td>15.923893</td>\n",
       "      <td>14.928601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006817</td>\n",
       "      <td>0.032421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.008860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012537</td>\n",
       "      <td>0.004263</td>\n",
       "      <td>0.002835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5%</th>\n",
       "      <td>1.490900</td>\n",
       "      <td>2.317638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.952234</td>\n",
       "      <td>0.997200</td>\n",
       "      <td>1.359868</td>\n",
       "      <td>1.689819</td>\n",
       "      <td>0.888883</td>\n",
       "      <td>1.157125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>2.963585</td>\n",
       "      <td>4.725553</td>\n",
       "      <td>1.836029</td>\n",
       "      <td>1.909942</td>\n",
       "      <td>1.943906</td>\n",
       "      <td>2.738911</td>\n",
       "      <td>3.281040</td>\n",
       "      <td>1.946408</td>\n",
       "      <td>2.228315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20%</th>\n",
       "      <td>5.791901</td>\n",
       "      <td>10.191055</td>\n",
       "      <td>4.651163</td>\n",
       "      <td>4.032719</td>\n",
       "      <td>4.119736</td>\n",
       "      <td>5.138404</td>\n",
       "      <td>6.664041</td>\n",
       "      <td>4.040612</td>\n",
       "      <td>4.164368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.421536</td>\n",
       "      <td>12.763087</td>\n",
       "      <td>6.060606</td>\n",
       "      <td>5.187500</td>\n",
       "      <td>5.347222</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>8.331586</td>\n",
       "      <td>5.233697</td>\n",
       "      <td>5.268167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17.233439</td>\n",
       "      <td>27.144656</td>\n",
       "      <td>15.151515</td>\n",
       "      <td>11.374674</td>\n",
       "      <td>12.071246</td>\n",
       "      <td>14.339623</td>\n",
       "      <td>17.548833</td>\n",
       "      <td>10.938554</td>\n",
       "      <td>11.756473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>33.038559</td>\n",
       "      <td>48.309059</td>\n",
       "      <td>30.666667</td>\n",
       "      <td>20.962187</td>\n",
       "      <td>23.390000</td>\n",
       "      <td>26.575000</td>\n",
       "      <td>31.234879</td>\n",
       "      <td>20.428784</td>\n",
       "      <td>21.709270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>37.961539</td>\n",
       "      <td>53.868779</td>\n",
       "      <td>35.714286</td>\n",
       "      <td>24.047997</td>\n",
       "      <td>27.522640</td>\n",
       "      <td>30.329697</td>\n",
       "      <td>35.339826</td>\n",
       "      <td>23.606596</td>\n",
       "      <td>24.537115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>55.036062</td>\n",
       "      <td>69.926090</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>33.946722</td>\n",
       "      <td>40.438766</td>\n",
       "      <td>40.947227</td>\n",
       "      <td>50.930265</td>\n",
       "      <td>33.317841</td>\n",
       "      <td>34.075096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>72.995035</td>\n",
       "      <td>88.827517</td>\n",
       "      <td>67.876923</td>\n",
       "      <td>44.916744</td>\n",
       "      <td>53.464374</td>\n",
       "      <td>53.583729</td>\n",
       "      <td>63.846076</td>\n",
       "      <td>43.989460</td>\n",
       "      <td>44.174729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>374.315492</td>\n",
       "      <td>222.894851</td>\n",
       "      <td>316.666667</td>\n",
       "      <td>148.030784</td>\n",
       "      <td>191.886364</td>\n",
       "      <td>203.157895</td>\n",
       "      <td>221.228622</td>\n",
       "      <td>226.227207</td>\n",
       "      <td>160.081945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LinearRegression   ElasticNet  DecisionTree  XGBoostRegressor  \\\n",
       "count       3469.000000  3469.000000   3469.000000       3469.000000   \n",
       "mean          25.115170    34.262142     23.104223         15.545680   \n",
       "std           28.513756    29.163628     27.685499         15.204562   \n",
       "min            0.006817     0.032421      0.000000          0.000357   \n",
       "5%             1.490900     2.317638      0.000000          0.952234   \n",
       "10%            2.963585     4.725553      1.836029          1.909942   \n",
       "20%            5.791901    10.191055      4.651163          4.032719   \n",
       "25%            7.421536    12.763087      6.060606          5.187500   \n",
       "50%           17.233439    27.144656     15.151515         11.374674   \n",
       "75%           33.038559    48.309059     30.666667         20.962187   \n",
       "80%           37.961539    53.868779     35.714286         24.047997   \n",
       "90%           55.036062    69.926090     50.000000         33.946722   \n",
       "95%           72.995035    88.827517     67.876923         44.916744   \n",
       "max          374.315492   222.894851    316.666667        148.030784   \n",
       "\n",
       "       RandomForest          KNN  XGBoostRFRegressor     LightGBM     CatBoost  \n",
       "count   3469.000000  3469.000000         3469.000000  3469.000000  3469.000000  \n",
       "mean      17.568837    19.408405           23.212094    15.412704    15.746216  \n",
       "std       18.203948    18.860335           21.429049    15.923893    14.928601  \n",
       "min        0.008860     0.000000            0.012537     0.004263     0.002835  \n",
       "5%         0.997200     1.359868            1.689819     0.888883     1.157125  \n",
       "10%        1.943906     2.738911            3.281040     1.946408     2.228315  \n",
       "20%        4.119736     5.138404            6.664041     4.040612     4.164368  \n",
       "25%        5.347222     6.666667            8.331586     5.233697     5.268167  \n",
       "50%       12.071246    14.339623           17.548833    10.938554    11.756473  \n",
       "75%       23.390000    26.575000           31.234879    20.428784    21.709270  \n",
       "80%       27.522640    30.329697           35.339826    23.606596    24.537115  \n",
       "90%       40.438766    40.947227           50.930265    33.317841    34.075096  \n",
       "95%       53.464374    53.583729           63.846076    43.989460    44.174729  \n",
       "max      191.886364   203.157895          221.228622   226.227207   160.081945  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinearRegression</th>\n",
       "      <th>ElasticNet</th>\n",
       "      <th>DecisionTree</th>\n",
       "      <th>XGBoostRegressor</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>KNN</th>\n",
       "      <th>XGBoostRFRegressor</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>CatBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.469000</td>\n",
       "      <td>3.469000</td>\n",
       "      <td>3.469000</td>\n",
       "      <td>3.469000</td>\n",
       "      <td>3.469000</td>\n",
       "      <td>3.469000</td>\n",
       "      <td>3.469000</td>\n",
       "      <td>3.469000</td>\n",
       "      <td>3.469000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2334.079651</td>\n",
       "      <td>3288.336918</td>\n",
       "      <td>2398.403256</td>\n",
       "      <td>1722.110519</td>\n",
       "      <td>1907.348031</td>\n",
       "      <td>2269.388371</td>\n",
       "      <td>2479.399542</td>\n",
       "      <td>1698.402172</td>\n",
       "      <td>1764.820522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3648.169130</td>\n",
       "      <td>5625.712411</td>\n",
       "      <td>4497.824488</td>\n",
       "      <td>3123.305261</td>\n",
       "      <td>3563.434435</td>\n",
       "      <td>4258.902518</td>\n",
       "      <td>4140.272174</td>\n",
       "      <td>2923.020635</td>\n",
       "      <td>3300.691407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.647652</td>\n",
       "      <td>4.510008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.424000</td>\n",
       "      <td>0.490238</td>\n",
       "      <td>0.099219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5%</th>\n",
       "      <td>120.338622</td>\n",
       "      <td>210.251651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68.888200</td>\n",
       "      <td>73.289540</td>\n",
       "      <td>93.880000</td>\n",
       "      <td>125.140200</td>\n",
       "      <td>63.392573</td>\n",
       "      <td>78.450068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>230.957491</td>\n",
       "      <td>433.048334</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>137.379600</td>\n",
       "      <td>155.758748</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>242.258250</td>\n",
       "      <td>133.437805</td>\n",
       "      <td>159.241238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20%</th>\n",
       "      <td>478.317498</td>\n",
       "      <td>842.916565</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>296.153200</td>\n",
       "      <td>308.800000</td>\n",
       "      <td>355.312000</td>\n",
       "      <td>465.249300</td>\n",
       "      <td>281.566920</td>\n",
       "      <td>303.058903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>622.376602</td>\n",
       "      <td>1044.965965</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>382.085250</td>\n",
       "      <td>387.550000</td>\n",
       "      <td>449.999000</td>\n",
       "      <td>612.488250</td>\n",
       "      <td>367.691271</td>\n",
       "      <td>384.221128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1416.987130</td>\n",
       "      <td>2108.218918</td>\n",
       "      <td>1149.000000</td>\n",
       "      <td>852.389500</td>\n",
       "      <td>926.500000</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>1358.787500</td>\n",
       "      <td>856.608597</td>\n",
       "      <td>886.741913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2677.085296</td>\n",
       "      <td>3588.235378</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>1778.853250</td>\n",
       "      <td>1978.000000</td>\n",
       "      <td>2327.200000</td>\n",
       "      <td>2741.653000</td>\n",
       "      <td>1835.215068</td>\n",
       "      <td>1871.098977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>3084.193038</td>\n",
       "      <td>4108.103186</td>\n",
       "      <td>3100.000000</td>\n",
       "      <td>2211.047200</td>\n",
       "      <td>2410.194704</td>\n",
       "      <td>2860.000000</td>\n",
       "      <td>3311.614400</td>\n",
       "      <td>2221.322436</td>\n",
       "      <td>2241.113095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>4711.218785</td>\n",
       "      <td>5968.230697</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>3787.349600</td>\n",
       "      <td>4101.771879</td>\n",
       "      <td>4951.389600</td>\n",
       "      <td>5356.642200</td>\n",
       "      <td>3872.508426</td>\n",
       "      <td>3780.372750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>7235.270284</td>\n",
       "      <td>8292.182592</td>\n",
       "      <td>8332.160000</td>\n",
       "      <td>6091.922400</td>\n",
       "      <td>6773.031064</td>\n",
       "      <td>7920.000000</td>\n",
       "      <td>7942.676000</td>\n",
       "      <td>6074.958189</td>\n",
       "      <td>6351.501973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>61992.632773</td>\n",
       "      <td>98180.917199</td>\n",
       "      <td>74000.000000</td>\n",
       "      <td>69053.016000</td>\n",
       "      <td>64147.950000</td>\n",
       "      <td>71833.400000</td>\n",
       "      <td>77471.576000</td>\n",
       "      <td>50178.373531</td>\n",
       "      <td>62122.192740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LinearRegression    ElasticNet  DecisionTree  XGBoostRegressor  \\\n",
       "count          3.469000      3.469000      3.469000          3.469000   \n",
       "mean        2334.079651   3288.336918   2398.403256       1722.110519   \n",
       "std         3648.169130   5625.712411   4497.824488       3123.305261   \n",
       "min            0.647652      4.510008      0.000000          0.050000   \n",
       "5%           120.338622    210.251651      0.000000         68.888200   \n",
       "10%          230.957491    433.048334    100.000000        137.379600   \n",
       "20%          478.317498    842.916565    300.000000        296.153200   \n",
       "25%          622.376602   1044.965965    500.000000        382.085250   \n",
       "50%         1416.987130   2108.218918   1149.000000        852.389500   \n",
       "75%         2677.085296   3588.235378   2500.000000       1778.853250   \n",
       "80%         3084.193038   4108.103186   3100.000000       2211.047200   \n",
       "90%         4711.218785   5968.230697   5000.000000       3787.349600   \n",
       "95%         7235.270284   8292.182592   8332.160000       6091.922400   \n",
       "max        61992.632773  98180.917199  74000.000000      69053.016000   \n",
       "\n",
       "       RandomForest           KNN  XGBoostRFRegressor      LightGBM  \\\n",
       "count      3.469000      3.469000            3.469000      3.469000   \n",
       "mean    1907.348031   2269.388371         2479.399542   1698.402172   \n",
       "std     3563.434435   4258.902518         4140.272174   2923.020635   \n",
       "min        0.300000      0.000000            1.424000      0.490238   \n",
       "5%        73.289540     93.880000          125.140200     63.392573   \n",
       "10%      155.758748    180.000000          242.258250    133.437805   \n",
       "20%      308.800000    355.312000          465.249300    281.566920   \n",
       "25%      387.550000    449.999000          612.488250    367.691271   \n",
       "50%      926.500000   1100.000000         1358.787500    856.608597   \n",
       "75%     1978.000000   2327.200000         2741.653000   1835.215068   \n",
       "80%     2410.194704   2860.000000         3311.614400   2221.322436   \n",
       "90%     4101.771879   4951.389600         5356.642200   3872.508426   \n",
       "95%     6773.031064   7920.000000         7942.676000   6074.958189   \n",
       "max    64147.950000  71833.400000        77471.576000  50178.373531   \n",
       "\n",
       "           CatBoost  \n",
       "count      3.469000  \n",
       "mean    1764.820522  \n",
       "std     3300.691407  \n",
       "min        0.099219  \n",
       "5%        78.450068  \n",
       "10%      159.241238  \n",
       "20%      303.058903  \n",
       "25%      384.221128  \n",
       "50%      886.741913  \n",
       "75%     1871.098977  \n",
       "80%     2241.113095  \n",
       "90%     3780.372750  \n",
       "95%     6351.501973  \n",
       "max    62122.192740  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_df.T/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinearRegression</th>\n",
       "      <th>ElasticNet</th>\n",
       "      <th>DecisionTree</th>\n",
       "      <th>XGBoostRegressor</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>KNN</th>\n",
       "      <th>XGBoostRFRegressor</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>CatBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.469000</td>\n",
       "      <td>3.469000</td>\n",
       "      <td>3.469000</td>\n",
       "      <td>3.469000</td>\n",
       "      <td>3.469000</td>\n",
       "      <td>3.469000</td>\n",
       "      <td>3.469000</td>\n",
       "      <td>3.469000</td>\n",
       "      <td>3.469000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2334.079651</td>\n",
       "      <td>3288.336918</td>\n",
       "      <td>2398.403256</td>\n",
       "      <td>1722.110519</td>\n",
       "      <td>1907.348031</td>\n",
       "      <td>2269.388371</td>\n",
       "      <td>2479.399542</td>\n",
       "      <td>1698.402172</td>\n",
       "      <td>1764.820522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3648.169130</td>\n",
       "      <td>5625.712411</td>\n",
       "      <td>4497.824488</td>\n",
       "      <td>3123.305261</td>\n",
       "      <td>3563.434435</td>\n",
       "      <td>4258.902518</td>\n",
       "      <td>4140.272174</td>\n",
       "      <td>2923.020635</td>\n",
       "      <td>3300.691407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.647652</td>\n",
       "      <td>4.510008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.424000</td>\n",
       "      <td>0.490238</td>\n",
       "      <td>0.099219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5%</th>\n",
       "      <td>120.338622</td>\n",
       "      <td>210.251651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68.888200</td>\n",
       "      <td>73.289540</td>\n",
       "      <td>93.880000</td>\n",
       "      <td>125.140200</td>\n",
       "      <td>63.392573</td>\n",
       "      <td>78.450068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>230.957491</td>\n",
       "      <td>433.048334</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>137.379600</td>\n",
       "      <td>155.758748</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>242.258250</td>\n",
       "      <td>133.437805</td>\n",
       "      <td>159.241238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20%</th>\n",
       "      <td>478.317498</td>\n",
       "      <td>842.916565</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>296.153200</td>\n",
       "      <td>308.800000</td>\n",
       "      <td>355.312000</td>\n",
       "      <td>465.249300</td>\n",
       "      <td>281.566920</td>\n",
       "      <td>303.058903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>622.376602</td>\n",
       "      <td>1044.965965</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>382.085250</td>\n",
       "      <td>387.550000</td>\n",
       "      <td>449.999000</td>\n",
       "      <td>612.488250</td>\n",
       "      <td>367.691271</td>\n",
       "      <td>384.221128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1416.987130</td>\n",
       "      <td>2108.218918</td>\n",
       "      <td>1149.000000</td>\n",
       "      <td>852.389500</td>\n",
       "      <td>926.500000</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>1358.787500</td>\n",
       "      <td>856.608597</td>\n",
       "      <td>886.741913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2677.085296</td>\n",
       "      <td>3588.235378</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>1778.853250</td>\n",
       "      <td>1978.000000</td>\n",
       "      <td>2327.200000</td>\n",
       "      <td>2741.653000</td>\n",
       "      <td>1835.215068</td>\n",
       "      <td>1871.098977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>3084.193038</td>\n",
       "      <td>4108.103186</td>\n",
       "      <td>3100.000000</td>\n",
       "      <td>2211.047200</td>\n",
       "      <td>2410.194704</td>\n",
       "      <td>2860.000000</td>\n",
       "      <td>3311.614400</td>\n",
       "      <td>2221.322436</td>\n",
       "      <td>2241.113095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>4711.218785</td>\n",
       "      <td>5968.230697</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>3787.349600</td>\n",
       "      <td>4101.771879</td>\n",
       "      <td>4951.389600</td>\n",
       "      <td>5356.642200</td>\n",
       "      <td>3872.508426</td>\n",
       "      <td>3780.372750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>7235.270284</td>\n",
       "      <td>8292.182592</td>\n",
       "      <td>8332.160000</td>\n",
       "      <td>6091.922400</td>\n",
       "      <td>6773.031064</td>\n",
       "      <td>7920.000000</td>\n",
       "      <td>7942.676000</td>\n",
       "      <td>6074.958189</td>\n",
       "      <td>6351.501973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>61992.632773</td>\n",
       "      <td>98180.917199</td>\n",
       "      <td>74000.000000</td>\n",
       "      <td>69053.016000</td>\n",
       "      <td>64147.950000</td>\n",
       "      <td>71833.400000</td>\n",
       "      <td>77471.576000</td>\n",
       "      <td>50178.373531</td>\n",
       "      <td>62122.192740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LinearRegression    ElasticNet  DecisionTree  XGBoostRegressor  \\\n",
       "count          3.469000      3.469000      3.469000          3.469000   \n",
       "mean        2334.079651   3288.336918   2398.403256       1722.110519   \n",
       "std         3648.169130   5625.712411   4497.824488       3123.305261   \n",
       "min            0.647652      4.510008      0.000000          0.050000   \n",
       "5%           120.338622    210.251651      0.000000         68.888200   \n",
       "10%          230.957491    433.048334    100.000000        137.379600   \n",
       "20%          478.317498    842.916565    300.000000        296.153200   \n",
       "25%          622.376602   1044.965965    500.000000        382.085250   \n",
       "50%         1416.987130   2108.218918   1149.000000        852.389500   \n",
       "75%         2677.085296   3588.235378   2500.000000       1778.853250   \n",
       "80%         3084.193038   4108.103186   3100.000000       2211.047200   \n",
       "90%         4711.218785   5968.230697   5000.000000       3787.349600   \n",
       "95%         7235.270284   8292.182592   8332.160000       6091.922400   \n",
       "max        61992.632773  98180.917199  74000.000000      69053.016000   \n",
       "\n",
       "       RandomForest           KNN  XGBoostRFRegressor      LightGBM  \\\n",
       "count      3.469000      3.469000            3.469000      3.469000   \n",
       "mean    1907.348031   2269.388371         2479.399542   1698.402172   \n",
       "std     3563.434435   4258.902518         4140.272174   2923.020635   \n",
       "min        0.300000      0.000000            1.424000      0.490238   \n",
       "5%        73.289540     93.880000          125.140200     63.392573   \n",
       "10%      155.758748    180.000000          242.258250    133.437805   \n",
       "20%      308.800000    355.312000          465.249300    281.566920   \n",
       "25%      387.550000    449.999000          612.488250    367.691271   \n",
       "50%      926.500000   1100.000000         1358.787500    856.608597   \n",
       "75%     1978.000000   2327.200000         2741.653000   1835.215068   \n",
       "80%     2410.194704   2860.000000         3311.614400   2221.322436   \n",
       "90%     4101.771879   4951.389600         5356.642200   3872.508426   \n",
       "95%     6773.031064   7920.000000         7942.676000   6074.958189   \n",
       "max    64147.950000  71833.400000        77471.576000  50178.373531   \n",
       "\n",
       "           CatBoost  \n",
       "count      3.469000  \n",
       "mean    1764.820522  \n",
       "std     3300.691407  \n",
       "min        0.099219  \n",
       "5%        78.450068  \n",
       "10%      159.241238  \n",
       "20%      303.058903  \n",
       "25%      384.221128  \n",
       "50%      886.741913  \n",
       "75%     1871.098977  \n",
       "80%     2241.113095  \n",
       "90%     3780.372750  \n",
       "95%     6351.501973  \n",
       "max    62122.192740  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_df.T/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count             3469.0\n",
       "mean       11362982.3661\n",
       "std      12005742.076629\n",
       "min             900000.0\n",
       "25%            5000000.0\n",
       "50%            8000000.0\n",
       "75%           13000000.0\n",
       "max          150000000.0\n",
       "Name: price, dtype: Float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_test).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
