{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dtype_mapping = {\n",
    "    'propertyId': pd.StringDtype(),\n",
    "    'localityName': 'category',\n",
    "    'landMarks': pd.StringDtype(),\n",
    "    'locality': pd.StringDtype(),\n",
    "    'price': pd.Int64Dtype(),\n",
    "    'nameOfSociety': pd.StringDtype(),\n",
    "    'projectName': pd.StringDtype(),\n",
    "    'carpetArea': pd.Int64Dtype(),\n",
    "    'coveredArea': pd.Int64Dtype(),\n",
    "    'carpetAreaSqft': pd.Int64Dtype(),\n",
    "    'possessionStatus': pd.StringDtype(),\n",
    "    'developerName': pd.StringDtype(),\n",
    "    'flooringType': pd.StringDtype(),\n",
    "    'floorNumber': pd.Int64Dtype(),\n",
    "    'unitCountonFloor': pd.Int64Dtype(),\n",
    "    'totalFloorNumber': pd.Int64Dtype(),\n",
    "    'electricityStatus': pd.StringDtype(),\n",
    "    'waterStatus': pd.StringDtype(),\n",
    "    'longitude': pd.Float64Dtype(),\n",
    "    'latitude': pd.Float64Dtype(),\n",
    "    'transactionType': 'category',\n",
    "    'facing': pd.StringDtype(),\n",
    "    'ownershipType': pd.StringDtype(),\n",
    "    'carParking': pd.StringDtype(),\n",
    "    'furnished': 'category',\n",
    "    'bedrooms': pd.Int64Dtype(),\n",
    "    'bathrooms': pd.Int64Dtype(),\n",
    "    'numberOfBalconied': pd.Int64Dtype(),\n",
    "    'propertyType': 'category',\n",
    "    'additionalRooms': pd.StringDtype(),\n",
    "    'bookingAmountExact': pd.Int64Dtype(),\n",
    "    'maintenanceChargesFrequency': 'category',\n",
    "    'maintenanceCharges': pd.Int64Dtype(),\n",
    "    'ageofcons': 'category',\n",
    "    'isVerified': 'category',\n",
    "    'listingTypeDesc': 'category',\n",
    "    'premiumProperty': pd.BooleanDtype(),\n",
    "    'noOfLifts': pd.Int64Dtype(),\n",
    "    'propertyAmenities': pd.StringDtype(),\n",
    "    'facilitiesDesc': pd.StringDtype(),\n",
    "    'uuid': pd.StringDtype(),\n",
    "    'flooringType_Vitrified': pd.BooleanDtype(),\n",
    "    'flooringType_CeramicTiles': pd.BooleanDtype(),\n",
    "    'flooringType_Marble': pd.BooleanDtype(),\n",
    "    'flooringType_NormalTilesKotahStone': pd.BooleanDtype(),\n",
    "    'flooringType_Granite': pd.BooleanDtype(),\n",
    "    'flooringType_Wooden': pd.BooleanDtype(),\n",
    "    'flooringType_Mosaic': pd.BooleanDtype(),\n",
    "    'flooringType_Marbonite': pd.BooleanDtype(),\n",
    "    'additionalRoom_PujaRoom': pd.BooleanDtype(),\n",
    "    'additionalRoom_Study': pd.BooleanDtype(),\n",
    "    'additionalRoom_Store': pd.BooleanDtype(),\n",
    "    'additionalRoom_ServantRoom': pd.BooleanDtype(),\n",
    "    'carParking_Open': pd.Int64Dtype(),\n",
    "    'carParking_Covered': pd.Int64Dtype(),\n",
    "    'ReservedParking': pd.BooleanDtype(),\n",
    "}\n",
    "\n",
    "COLUMNS_TO_DROP = [\n",
    "    'coveredArea',\n",
    "    'ReservedParking',\n",
    "] + [\n",
    "        'unitCountonFloor',\n",
    "        'electricityStatus',\n",
    "        'waterStatus',\n",
    "        'facing',\n",
    "        'bookingAmountExact',\n",
    "        'isVerified',\n",
    "        'listingTypeDesc',\n",
    "        'maintenanceCharges',\n",
    "        'maintenanceChargesFrequency',\n",
    "        'latitude',\n",
    "        'longitude',\n",
    "        'carParking_Open',\n",
    "        'carParking_Covered',\n",
    "        'numberOfBalconied',\n",
    "        'premiumProperty',\n",
    "        'projectName',\n",
    "        'nameOfSociety',\n",
    "        'url',\n",
    "        'uuid',\n",
    "        'carpetAreaSqft',\n",
    "        'noOfLifts',\n",
    "        'ownershipType',\n",
    "        'possessionStatus',\n",
    "        'propertyType',\n",
    "\n",
    "        'flooringType_Vitrified',\n",
    "        'flooringType_CeramicTiles',\n",
    "        'flooringType_Marble',\n",
    "        'flooringType_NormalTilesKotahStone',\n",
    "        'flooringType_Granite',\n",
    "        'flooringType_Wooden',\n",
    "        'flooringType_Mosaic',\n",
    "        'flooringType_Marbonite',\n",
    "\n",
    "        'additionalRoom_PujaRoom',\n",
    "        'additionalRoom_Study',\n",
    "        'additionalRoom_Store',\n",
    "        'additionalRoom_ServantRoom',\n",
    "        \n",
    "        'landMarks', \n",
    "        'locality', \n",
    "        'developerName']\n",
    "\n",
    "################################################################################\n",
    "# ONLY USING THE RAW SETs, NOT IMPUTED SET\n",
    "################################################################################\n",
    "df_train = pd.read_csv(\n",
    "    'Data/train.csv',\n",
    "    dtype = dtype_mapping,\n",
    "    index_col=0\n",
    ")\n",
    "df_train.drop(COLUMNS_TO_DROP, axis=1, inplace=True)\n",
    "\n",
    "df_test = pd.read_csv(\n",
    "    'Data/test.csv',\n",
    "    dtype = dtype_mapping,\n",
    "    index_col=0\n",
    ")\n",
    "df_test.drop(COLUMNS_TO_DROP, axis=1, inplace=True)\n",
    "\n",
    "################################################################################\n",
    "# DROPPING ALL ROWS WITH MISSING VALUES\n",
    "################################################################################\n",
    "\n",
    "df_train.dropna(axis=0, inplace=True)\n",
    "df_test.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"carpetArea\": pd.Int64Dtype(),\n",
    "    \"floorNumber\": pd.Int64Dtype(),\n",
    "    \"totalFloorNumber\": pd.Int64Dtype(),\n",
    "    \"bedrooms\": pd.Int64Dtype(),\n",
    "    \"bathrooms\": pd.Int64Dtype(),\n",
    "    \"localityName\": 'category',\n",
    "    \"transactionType\": 'category',\n",
    "    \"furnished\": 'category',\n",
    "    \"ageofcons\": 'category',\n",
    "}\n",
    "\n",
    "df = pd.concat([df_train, df_test], ignore_index=False).astype(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# DROPPING LOCALITY FOR NEAREST NEIGHBORS\n",
    "########################################################################\n",
    "\n",
    "# df.drop(columns=['localityName'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 21392 entries, 74208793 to 75682303\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype   \n",
      "---  ------            --------------  -----   \n",
      " 0   localityName      21392 non-null  category\n",
      " 1   price             21392 non-null  Int64   \n",
      " 2   carpetArea        21392 non-null  Int64   \n",
      " 3   floorNumber       21392 non-null  Int64   \n",
      " 4   totalFloorNumber  21392 non-null  Int64   \n",
      " 5   transactionType   21392 non-null  category\n",
      " 6   furnished         21392 non-null  category\n",
      " 7   bedrooms          21392 non-null  Int64   \n",
      " 8   bathrooms         21392 non-null  Int64   \n",
      " 9   ageofcons         21392 non-null  category\n",
      "dtypes: Int64(6), category(4)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Encoding for Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting and transforming data...\n",
      "Data transformed. Shape: (21392, 17)\n",
      "Applying feature weights...\n",
      "Reordering columns...\n",
      "\n",
      "--- Final Encoded Vectors ---\n",
      "Shape: (21392, 17)\n",
      "Columns: ['carpetArea', 'bedrooms', 'bathrooms', 'floorNumber', 'totalFloorNumber', 'transactionType_New Property', 'transactionType_Resale', 'furnished_Furnished', 'furnished_Semi-Furnished', 'furnished_Unfurnished', 'ageofcons_10 to 15 years', 'ageofcons_15 to 20 years', 'ageofcons_5 to 10 years', 'ageofcons_Above 20 years', 'ageofcons_Less than 5 years', 'ageofcons_New Construction', 'ageofcons_Under Construction']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import numpy as np # For numerical operations if needed later\n",
    "\n",
    "# 1. Define feature lists based on type\n",
    "numerical_cols = [\n",
    "    \"carpetArea\",\n",
    "    \"bedrooms\",\n",
    "    \"bathrooms\",\n",
    "    \"floorNumber\",\n",
    "    \"totalFloorNumber\",\n",
    "]\n",
    "categorical_cols = [\n",
    "    # \"localityName\",\n",
    "    \"transactionType\",\n",
    "    \"furnished\",\n",
    "    \"ageofcons\",\n",
    "]\n",
    "\n",
    "# 2. Define the desired final order (matching user input expectation)\n",
    "# Note: Categorical features will be expanded by OneHotEncoder\n",
    "user_input_order = [\n",
    "    \"carpetArea\",\n",
    "    \"bedrooms\",\n",
    "    \"bathrooms\",\n",
    "    \"floorNumber\",\n",
    "    \"totalFloorNumber\",\n",
    "    # \"localityName\",\n",
    "    \"transactionType\",\n",
    "    \"furnished\",\n",
    "    \"ageofcons\",\n",
    "]\n",
    "\n",
    "# 3. Define weights (currently all 1.0)\n",
    "# We'll apply these *after* initial scaling/encoding\n",
    "feature_weights = {\n",
    "    \"carpetArea\": 1.0,\n",
    "    \"bedrooms\": 1.0,\n",
    "    \"bathrooms\": 1.0,\n",
    "    \"floorNumber\": 1.0,\n",
    "    \"totalFloorNumber\": 1.0,\n",
    "    # \"localityName\": 1.0, # Weight applies to all generated OHE columns\n",
    "    \"transactionType\": 1.0, # Weight applies to all generated OHE columns\n",
    "    \"furnished\": 1.0, # Weight applies to all generated OHE columns\n",
    "    \"ageofcons\": 1.0, # Weight applies to all generated OHE columns\n",
    "}\n",
    "\n",
    "# --- Preprocessing ---\n",
    "\n",
    "# Separate features (X) and property IDs (index)\n",
    "# Exclude 'price' column\n",
    "features_to_encode = numerical_cols + categorical_cols\n",
    "X = df[features_to_encode]\n",
    "property_ids = df.index # Preserve property IDs\n",
    "\n",
    "# Create the ColumnTransformer\n",
    "# - Numerical features: Standard Scaling\n",
    "# - Categorical features: One-Hot Encoding\n",
    "#   - handle_unknown='ignore': If user input has a category not seen in training,\n",
    "#     it will be encoded as all zeros for that feature. Important for robustness.\n",
    "#   - sparse_output=False: Output a dense numpy array, easier to work with.\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\n",
    "            \"num\",\n",
    "            StandardScaler(),\n",
    "            numerical_cols,\n",
    "        ),\n",
    "        (\n",
    "            \"cat\",\n",
    "            OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
    "            categorical_cols,\n",
    "        ),\n",
    "    ],\n",
    "    remainder=\"passthrough\", # Keep other columns if any (shouldn't be any here)\n",
    "    verbose_feature_names_out=False, # Keep original names for num features\n",
    ")\n",
    "\n",
    "# Fit the preprocessor on the data and transform it\n",
    "print(\"Fitting and transforming data...\")\n",
    "X_encoded = preprocessor.fit_transform(X)\n",
    "print(f\"Data transformed. Shape: {X_encoded.shape}\")\n",
    "\n",
    "# Get the feature names after transformation (important for OHE)\n",
    "# This preserves numerical names and creates names like 'localityName_XYZ'\n",
    "encoded_feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame with the encoded data and correct column names\n",
    "encoded_df = pd.DataFrame(\n",
    "    X_encoded, columns=encoded_feature_names, index=property_ids\n",
    ")\n",
    "\n",
    "# --- Apply Weighting ---\n",
    "print(\"Applying feature weights...\")\n",
    "weighted_df = encoded_df.copy() # Start with the encoded data\n",
    "\n",
    "for feature_name, weight in feature_weights.items():\n",
    "    if weight == 1.0: # No need to multiply if weight is 1\n",
    "        continue\n",
    "\n",
    "    # Find columns corresponding to this original feature\n",
    "    # For numerical, it's just the name.\n",
    "    # For categorical, it's the name + '_' + category value\n",
    "    if feature_name in numerical_cols:\n",
    "        cols_to_weight = [feature_name]\n",
    "    elif feature_name in categorical_cols:\n",
    "        # Find all columns starting with the categorical feature name + \"_\"\n",
    "        # (default separator) or exactly the feature name if OHE created it differently\n",
    "        # (less likely with verbose_feature_names_out=False)\n",
    "        cols_to_weight = [\n",
    "            col\n",
    "            for col in encoded_feature_names\n",
    "            if col.startswith(feature_name + \"_\") or col == feature_name\n",
    "        ]\n",
    "    else:\n",
    "        cols_to_weight = [] # Should not happen with current setup\n",
    "\n",
    "    if not cols_to_weight:\n",
    "        print(f\"Warning: No columns found for weighting feature '{feature_name}'\")\n",
    "        continue\n",
    "\n",
    "    # Apply the weight by multiplying the selected columns\n",
    "    weighted_df[cols_to_weight] *= weight\n",
    "\n",
    "# --- Reorder Columns to Match User Input Structure ---\n",
    "# We need to reconstruct the final order, expanding the categorical names\n",
    "print(\"Reordering columns...\")\n",
    "final_column_order = []\n",
    "current_encoded_cols = weighted_df.columns.tolist()\n",
    "\n",
    "for feature in user_input_order:\n",
    "    if feature in numerical_cols:\n",
    "        final_column_order.append(feature)\n",
    "    elif feature in categorical_cols:\n",
    "        # Find all columns that were generated from this categorical feature\n",
    "        generated_cols = [\n",
    "            col\n",
    "            for col in current_encoded_cols\n",
    "            if col.startswith(feature + \"_\") or col == feature # Handle potential edge cases\n",
    "        ]\n",
    "        # Sort them alphabetically for consistency (optional but good practice)\n",
    "        generated_cols.sort()\n",
    "        final_column_order.extend(generated_cols)\n",
    "\n",
    "# Create the final DataFrame with the desired column order\n",
    "final_encoded_vectors = weighted_df[final_column_order]\n",
    "\n",
    "# --- Output ---\n",
    "print(\"\\n--- Final Encoded Vectors ---\")\n",
    "print(f\"Shape: {final_encoded_vectors.shape}\")\n",
    "print(\"Columns:\", final_encoded_vectors.columns.tolist())\n",
    "\n",
    "\n",
    "# --- Important for Backend ---\n",
    "# You will need to SAVE:\n",
    "# 1. The `final_encoded_vectors` DataFrame (or its numpy array version).\n",
    "#    This contains the vectors you'll search against.\n",
    "#    Example: final_encoded_vectors.to_pickle(\"property_vectors.pkl\")\n",
    "#             or np.save(\"property_vectors.npy\", final_encoded_vectors.values)\n",
    "#             and save property_ids separately if using numpy array.\n",
    "#\n",
    "# 2. The fitted `preprocessor` object. You NEED this to encode the user's input\n",
    "#    in the exact same way before performing the nearest neighbor search.\n",
    "#    Example: import joblib\n",
    "#             joblib.dump(preprocessor, 'preprocessor.joblib')\n",
    "#\n",
    "# 3. The `final_column_order` list (or derive it again in the backend) if needed\n",
    "#    for verification, although the preprocessor handles the transformation order.\n",
    "#\n",
    "# 4. The `property_ids` (which are the index of `final_encoded_vectors`).\n",
    "#    You need these to map the indices returned by NearestNeighbors back to actual IDs.\n",
    "#    Example: (already saved if using pickle for the DataFrame)\n",
    "#             or save separately: pd.Series(property_ids).to_pickle(\"property_ids.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 21392 entries, 74208793 to 75682303\n",
      "Data columns (total 17 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   carpetArea                    21392 non-null  float64\n",
      " 1   bedrooms                      21392 non-null  float64\n",
      " 2   bathrooms                     21392 non-null  float64\n",
      " 3   floorNumber                   21392 non-null  float64\n",
      " 4   totalFloorNumber              21392 non-null  float64\n",
      " 5   transactionType_New Property  21392 non-null  float64\n",
      " 6   transactionType_Resale        21392 non-null  float64\n",
      " 7   furnished_Furnished           21392 non-null  float64\n",
      " 8   furnished_Semi-Furnished      21392 non-null  float64\n",
      " 9   furnished_Unfurnished         21392 non-null  float64\n",
      " 10  ageofcons_10 to 15 years      21392 non-null  float64\n",
      " 11  ageofcons_15 to 20 years      21392 non-null  float64\n",
      " 12  ageofcons_5 to 10 years       21392 non-null  float64\n",
      " 13  ageofcons_Above 20 years      21392 non-null  float64\n",
      " 14  ageofcons_Less than 5 years   21392 non-null  float64\n",
      " 15  ageofcons_New Construction    21392 non-null  float64\n",
      " 16  ageofcons_Under Construction  21392 non-null  float64\n",
      "dtypes: float64(17)\n",
      "memory usage: 3.4 MB\n"
     ]
    }
   ],
   "source": [
    "final_encoded_vectors.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting NearestNeighbors model (k=10, metric='cosine')...\n",
      "NearestNeighbors model fitted successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import joblib # For saving the model later\n",
    "\n",
    "# --- Assume 'final_encoded_vectors' DataFrame exists from the previous step ---\n",
    "# It should have property IDs as the index and encoded features as columns.\n",
    "# Example:\n",
    "# final_encoded_vectors = pd.read_pickle(\"property_vectors.pkl\") # If saved\n",
    "\n",
    "# --- Assume 'property_ids' exists (which is the index of final_encoded_vectors) ---\n",
    "property_ids = final_encoded_vectors.index\n",
    "\n",
    "# --- Configuration ---\n",
    "N_NEIGHBORS = 10 # How many neighbors to find by default\n",
    "METRIC = 'cosine' # Distance metric ('cosine', 'euclidean'/'l2', 'manhattan'/'l1')\n",
    "\n",
    "# --- Fit Nearest Neighbors Model ---\n",
    "\n",
    "print(f\"Fitting NearestNeighbors model (k={N_NEIGHBORS}, metric='{METRIC}')...\")\n",
    "\n",
    "# 1. Initialize the model\n",
    "#    n_jobs=-1 uses all available CPU cores for potentially faster fitting/querying\n",
    "nn_model = NearestNeighbors(\n",
    "    n_neighbors=N_NEIGHBORS, metric=METRIC, algorithm='auto', n_jobs=-1\n",
    ")\n",
    "\n",
    "# 2. Fit the model on the encoded data vectors\n",
    "#    It's generally recommended to pass the underlying NumPy array (.values)\n",
    "nn_model.fit(final_encoded_vectors.values)\n",
    "\n",
    "print(\"NearestNeighbors model fitted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Trial Run: Find neighbors for a sample property ---\n",
    "\n",
    "# # 1. Choose a sample property to find neighbors for (e.g., the first one)\n",
    "# sample_index_position = 0 # Taking the first property in the DataFrame\n",
    "# sample_property_id = property_ids[sample_index_position]\n",
    "# sample_vector = final_encoded_vectors.iloc[[sample_index_position]] # Keep as DataFrame row initially\n",
    "\n",
    "# print(f\"\\n--- Finding neighbors for sample property ID: {sample_property_id} ---\")\n",
    "# print(f\"Sample Vector (head): \\n{sample_vector.iloc[:, :5]}\") # Show first few features\n",
    "\n",
    "# # 2. Prepare the sample vector for kneighbors (needs to be 2D NumPy array)\n",
    "# sample_vector_np = sample_vector.values # Get NumPy array (already 2D)\n",
    "\n",
    "# # 3. Use the fitted model to find neighbors\n",
    "# #    kneighbors returns distances and indices\n",
    "# distances, indices = nn_model.kneighbors(sample_vector_np)\n",
    "\n",
    "# print(f\"\\nRaw distances: {distances}\")\n",
    "# print(f\"Raw indices: {indices}\")\n",
    "\n",
    "# # The `indices` array contains the row positions (0-based) in the\n",
    "# # original `final_encoded_vectors` data that are the nearest neighbors.\n",
    "# # Since we queried with one sample, indices[0] contains the list of neighbor indices.\n",
    "\n",
    "# # 4. Extract the indices for our single sample query\n",
    "# neighbor_indices = indices[0]\n",
    "# print(f\"\\nIndices of the {N_NEIGHBORS} nearest neighbors: {neighbor_indices}\")\n",
    "\n",
    "# # 5. Map these indices back to the actual Property IDs\n",
    "# #    We use the original `property_ids` Series/Index we stored earlier\n",
    "# retrieved_neighbor_ids = property_ids[neighbor_indices].tolist()\n",
    "\n",
    "# print(f\"\\nRetrieved Property IDs of neighbors: {retrieved_neighbor_ids}\")\n",
    "\n",
    "# # --- Verification (Optional) ---\n",
    "# # The first neighbor (index 0) should usually be the sample property itself,\n",
    "# # unless there's an exact duplicate vector elsewhere.\n",
    "# if retrieved_neighbor_ids[0] == sample_property_id:\n",
    "#     print(\"\\nVerification: The first neighbor is the sample property itself (expected).\")\n",
    "# else:\n",
    "#     print(\"\\nVerification: The first neighbor is NOT the sample property itself.\")\n",
    "\n",
    "\n",
    "# # --- Important for Backend ---\n",
    "# # Now you need to SAVE the fitted `nn_model` object.\n",
    "# # Example:\n",
    "# # joblib.dump(nn_model, 'nearest_neighbors_model.joblib')\n",
    "# #\n",
    "# # Remember you also need the saved `preprocessor` and the `property_ids`\n",
    "# # (or the `final_encoded_vectors` DataFrame which includes the IDs as index)\n",
    "# # from the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np # Only needed if you were saving numpy arrays directly\n",
    "\n",
    "# It's good practice to define filenames as constants\n",
    "NN_MODEL_FILE = 'PipelinesAndModels/nearest_neighbors_model.joblib'\n",
    "RECOMMENDATION_PREPROCESSOR_FILE = 'PipelinesAndModels/recommendation_preprocessor.joblib'\n",
    "PROPERTY_VECTORS_FILE = 'PipelinesAndModels/property_vectors.pkl' # Using pickle for the DataFrame\n",
    "\n",
    "joblib.dump(nn_model, NN_MODEL_FILE, compress=3)\n",
    "\n",
    "joblib.dump(preprocessor, RECOMMENDATION_PREPROCESSOR_FILE, compress=3)\n",
    "\n",
    "final_encoded_vectors.to_pickle(PROPERTY_VECTORS_FILE)\n",
    "\n",
    "# --- Optional: Save Property IDs separately (if needed, but redundant if saving the DataFrame) ---\n",
    "# property_ids = final_encoded_vectors.index\n",
    "# PROPERTY_IDS_FILE = 'property_ids.pkl'\n",
    "# print(f\"Saving property IDs separately to: {PROPERTY_IDS_FILE}\")\n",
    "# pd.Series(property_ids).to_pickle(PROPERTY_IDS_FILE)\n",
    "# print(\"-> Saved property_ids.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling property Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking which properties are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhagy\\AppData\\Local\\Temp\\ipykernel_40176\\3462660137.py:4: DtypeWarning: Columns (10,11,30,31,32,34,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  rawData = pd.read_csv(\"../Data/rawExtractedPropertyDetails.csv\")\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "rawData = pd.read_csv(\"../Data/rawExtractedPropertyDetails.csv\")\n",
    "rawData['propertyId'] = rawData['propertyId'].astype(str)\n",
    "rawData.set_index('propertyId', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74208793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://www.magicbricks.com/propertyDetails/3-BHK-1662-Sq-ft-Multistorey-Apartment-FOR-Sale-Hinjewadi-in-Pune&id=4d423734323038373933'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = 0\n",
    "print(rawData.loc[df.index, ['url']].reset_index().iloc[id]['propertyId'])\n",
    "rawData.loc[df.index, ['url']].reset_index().iloc[id]['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['74208793', '73773015', '75162077', '76084143', '75658157', '48337347',\n",
       "       '74400799', '70265331', '75679247', '73281529', '73508741', '74837269',\n",
       "       '75692605', '75577751', '75665103', '74903023', '75933165', '73774411',\n",
       "       '75181979', '75746521', '75687865', '75691897', '72278837', '72991527',\n",
       "       '75657681', '75658553', '75198967', '74598267', '75709545', '75665171',\n",
       "       '74185523', '75206021', '76071257', '75694581', '76015789', '75688537',\n",
       "       '75147705', '74212763', '75658603', '73279171', '75382247', '73693493',\n",
       "       '75666349', '75668555', '63269545', '62164211', '75672063', '70861971',\n",
       "       '74918157', '74702487', '75668101', '71333765', '74717153', '75671737',\n",
       "       '74654451', '73625611', '75702115', '71242815', '74328807', '73877431',\n",
       "       '72510057', '75665359', '75617881', '75658549', '75378819', '71772115',\n",
       "       '75885301', '76141693', '75915281', '70762573', '71833131', '76172989',\n",
       "       '74729393', '76114639', '75664943', '75689699', '75685689', '75560657',\n",
       "       '74547651', '75674245', '64910947', '75679327', '75885977', '74438551',\n",
       "       '75663847', '75678135', '76149051', '73701963', '74233743', '71908491',\n",
       "       '72231675', '42857437', '75670809', '75667171', '75680031', '72255021',\n",
       "       '75692863', '75785999', '52729273', '75599071'],\n",
       "      dtype='string', name='propertyId')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_urls = rawData.loc[df.index[:100], 'url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Example: Assume property_urls is your pandas Series with propertyId as index and URL as values.\n",
    "# For example:\n",
    "# property_urls = pd.Series({\n",
    "#     101: \"https://example.com/property/101\",\n",
    "#     102: \"https://example.com/property/102\",\n",
    "#     ...\n",
    "# })\n",
    "\n",
    "# Set up Chrome options (you can add more options if needed)\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # run in headless mode if you don't need a GUI\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "chrome_options.page_load_strategy = \"eager\"\n",
    "\n",
    "# Initialize the webdriver (path to chromedriver may be needed)\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# Dictionary to store results:\n",
    "# True: property exists, False: property does not exist\n",
    "results = {}\n",
    "\n",
    "# Counter for requests to enforce sleep after every 100 requests\n",
    "request_count = 0\n",
    "\n",
    "for property_id, url in property_urls.items():\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        # Allow the page some time to load\n",
    "        # time.sleep(2)\n",
    "\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "        )\n",
    "        # Check if the <body> tag has a class 'error'\n",
    "        body_element = driver.find_element(By.TAG_NAME, \"body\")\n",
    "        body_class = body_element.get_attribute(\"class\")\n",
    "        \n",
    "        # Check for the specific error structure: body.error and a nested main tag with class \"content error\"\n",
    "        if \"error\" in body_class.split():\n",
    "            try:\n",
    "                # Try to locate the main tag with class \"content error\" inside body\n",
    "                driver.find_element(By.CSS_SELECTOR, \"main.content.error\")\n",
    "                # If found, mark property as not existing\n",
    "                results[property_id] = False\n",
    "            except NoSuchElementException:\n",
    "                # The structure doesn't match the error pattern; assume property is valid.\n",
    "                results[property_id] = True\n",
    "        else:\n",
    "            results[property_id] = True\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle any exceptions (e.g., network issues, selector issues, etc.)\n",
    "        print(f\"Error processing property {property_id}: {e}\")\n",
    "        results[property_id] = None  # or you could set it to False, or log the error\n",
    "\n",
    "    request_count += 1\n",
    "\n",
    "    # After every 100 requests, sleep for a minute to avoid overloading the server\n",
    "    if request_count % 1000 == 0:\n",
    "        print(f\"Processed {request_count} requests, sleeping for a minute...\")\n",
    "        time.sleep(15)\n",
    "\n",
    "# Close the driver when done\n",
    "driver.quit()\n",
    "\n",
    "# Optionally, convert the results dictionary to a pandas DataFrame or Series for further processing\n",
    "results_series = pd.Series(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     51\n",
       "False    49\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_series.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving All the recommendations metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "imagePaths = {\n",
    "    'prefix': \"https://img.staticmb.com\",\n",
    "    'imagePaths': {}\n",
    "}\n",
    "noImages = 0\n",
    "for propertyId in df.index:\n",
    "    with open(f'../Data/propertyDetails/{propertyId}.json', 'r', encoding='utf-8') as f:\n",
    "        propertyDetails = json.load(f)\n",
    "\n",
    "    if propertyDetails.get('propertyDetailInfoBeanData') is None:\n",
    "        noImages += 1\n",
    "        continue\n",
    "\n",
    "    temp = propertyDetails['propertyDetailInfoBeanData']['propertyDetail']['detailBean'].get('allImgPath')\n",
    "\n",
    "    if temp is None:\n",
    "        noImages += 1\n",
    "        continue\n",
    "\n",
    "    imagePaths['imagePaths'][propertyId] = [path.removeprefix('https://img.staticmb.com') for path in temp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1708"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/imagePaths.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(imagePaths, f, ensure_ascii=False, indent=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 21392 entries, 74208793 to 75682303\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype   \n",
      "---  ------            --------------  -----   \n",
      " 0   localityName      21392 non-null  category\n",
      " 1   price             21392 non-null  Int64   \n",
      " 2   carpetArea        21392 non-null  Int64   \n",
      " 3   floorNumber       21392 non-null  Int64   \n",
      " 4   totalFloorNumber  21392 non-null  Int64   \n",
      " 5   transactionType   21392 non-null  category\n",
      " 6   furnished         21392 non-null  category\n",
      " 7   bedrooms          21392 non-null  Int64   \n",
      " 8   bathrooms         21392 non-null  Int64   \n",
      " 9   ageofcons         21392 non-null  category\n",
      "dtypes: Int64(6), category(4)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pricePerSqft'] = df['price'] / df['carpetArea']\n",
    "df['pricePerSqft'] = df['pricePerSqft'].round(0).astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv('../Data/cleaned_data.csv')\n",
    "temp['propertyId'] = temp['propertyId'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nameOfSociety'] = temp.set_index('propertyId').loc[df.index, 'nameOfSociety'].copy().astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "noImages = 0\n",
    "df['imagePaths'] = pd.NA\n",
    "for propertyId in df.index:\n",
    "    with open(f'../Data/propertyDetails/{propertyId}.json', 'r', encoding='utf-8') as f:\n",
    "        propertyDetails = json.load(f)\n",
    "\n",
    "    if propertyDetails.get('propertyDetailInfoBeanData') is None:\n",
    "        noImages += 1\n",
    "        continue\n",
    "\n",
    "    temp = propertyDetails['propertyDetailInfoBeanData']['propertyDetail']['detailBean'].get('allImgPath')\n",
    "\n",
    "    if temp is None:\n",
    "        noImages += 1\n",
    "        continue\n",
    "\n",
    "    # imagePaths['imagePaths'][propertyId] = [path.removeprefix('https://img.staticmb.com') for path in temp]\n",
    "    df.at[propertyId, 'imagePaths'] = temp # [path.removeprefix('https://img.staticmb.com') for path in temp]\n",
    "\n",
    "noURLs = 0\n",
    "df['url'] = pd.NA\n",
    "for propertyId in df.index:\n",
    "    with open(f'../Data/propertyDetails/{propertyId}.json', 'r', encoding='utf-8') as f:\n",
    "        propertyDetails = json.load(f)\n",
    "\n",
    "    if propertyDetails.get('propertyDetailInfoBeanData') is None:\n",
    "        noURLs += 1\n",
    "        continue\n",
    "\n",
    "    temp = propertyDetails['propertyDetailInfoBeanData']['propertyDetail']['detailBean'].get('url')\n",
    "\n",
    "    if temp is None:\n",
    "        noURLs += 1\n",
    "        continue\n",
    "\n",
    "    # imagePaths['imagePaths'][propertyId] = [path.removeprefix('https://img.staticmb.com') for path in temp]\n",
    "    df.at[propertyId, 'url'] = temp # [path.removeprefix('https://img.staticmb.com') for path in temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lastUpdatedDate'] = '21 Dec, 2024'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('Data/recommendations.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 21392 entries, 74208793 to 75682303\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype   \n",
      "---  ------            --------------  -----   \n",
      " 0   localityName      21392 non-null  category\n",
      " 1   price             21392 non-null  Int64   \n",
      " 2   carpetArea        21392 non-null  Int64   \n",
      " 3   floorNumber       21392 non-null  Int64   \n",
      " 4   totalFloorNumber  21392 non-null  Int64   \n",
      " 5   transactionType   21392 non-null  category\n",
      " 6   furnished         21392 non-null  category\n",
      " 7   bedrooms          21392 non-null  Int64   \n",
      " 8   bathrooms         21392 non-null  Int64   \n",
      " 9   ageofcons         21392 non-null  category\n",
      " 10  imagePaths        19684 non-null  object  \n",
      " 11  url               21390 non-null  object  \n",
      " 12  lastUpdatedDate   21392 non-null  object  \n",
      " 13  pricePerSqft      21392 non-null  Int64   \n",
      " 14  nameOfSociety     21392 non-null  object  \n",
      "dtypes: Int64(7), category(4), object(4)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "request_body = {\n",
    "    'carpetArea': 800,\n",
    "    'bedrooms': 2,\n",
    "    'bathrooms': 2,\n",
    "    'floorNumber': 4,\n",
    "    'totalFloorNumber': 8,\n",
    "    'localityName': 'EON Free Zone, Kharadi',\n",
    "    'transactionType': 'New Property',\n",
    "    'furnished': 'Semi-Furnished',\n",
    "    'ageofcons': 'Under Construction'\n",
    "}\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/recommend\", json=request_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recommendations': [{'propertyId': '75432267',\n",
       "   'localityName': 'Ravet, Pimpri Chinchwad',\n",
       "   'price': 6600000,\n",
       "   'carpetArea': 762,\n",
       "   'floorNumber': 4,\n",
       "   'totalFloorNumber': 7,\n",
       "   'transactionType': 'New Property',\n",
       "   'furnished': 'Semi-Furnished',\n",
       "   'bedrooms': 2,\n",
       "   'bathrooms': 2,\n",
       "   'ageofcons': 'Under Construction',\n",
       "   'imagePaths': ['https://img.staticmb.com/mbphoto/property/cropped_images/2024/Oct/12/Photo_h300_w450/75432267_6_apture17_300_450.jpg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Oct/12/Photo_h300_w450/75432267_2_apture16_300_450.jpg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Oct/12/Photo_h300_w450/75432267_3_apture15_300_450.jpg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Oct/12/Photo_h300_w450/75432267_5_apture18_300_450.jpg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Oct/12/Photo_h300_w450/75432267_7_apture14_300_450.jpg'],\n",
       "   'url': 'https://www.magicbricks.com/propertyDetails/2-BHK-1029-Sq-ft-Multistorey-Apartment-FOR-Sale-Ravet-in-Pune-r1&id=4d423735343332323637',\n",
       "   'lastUpdatedDate': '21 Dec, 2024',\n",
       "   'pricePerSqft': 8661,\n",
       "   'nameOfSociety': 'Glorious Tathastu'},\n",
       "  {'propertyId': '71906391',\n",
       "   'localityName': 'Mamurdi, Dehu Road',\n",
       "   'price': 6450000,\n",
       "   'carpetArea': 742,\n",
       "   'floorNumber': 4,\n",
       "   'totalFloorNumber': 7,\n",
       "   'transactionType': 'New Property',\n",
       "   'furnished': 'Semi-Furnished',\n",
       "   'bedrooms': 2,\n",
       "   'bathrooms': 2,\n",
       "   'ageofcons': 'Under Construction',\n",
       "   'imagePaths': ['https://img.staticmb.com/mbphoto/property/cropped_images/2024/Mar/17/Photo_h300_w450/71906391_1_hatsAppImage20240117at11.29.536bd2f874_300_450.jpg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Mar/17/Photo_h300_w450/71906391_4_hatsAppImage20240117at11.29.5367c983da_300_450.jpg'],\n",
       "   'url': 'https://www.magicbricks.com/propertyDetails/2-BHK-1038-Sq-ft-Multistorey-Apartment-FOR-Sale-Kiwale-in-Pune&id=4d423731393036333931',\n",
       "   'lastUpdatedDate': '21 Dec, 2024',\n",
       "   'pricePerSqft': 8693,\n",
       "   'nameOfSociety': 'Shelter Marvel'},\n",
       "  {'propertyId': '72315251',\n",
       "   'localityName': 'Rahatani',\n",
       "   'price': 7400000,\n",
       "   'carpetArea': 759,\n",
       "   'floorNumber': 3,\n",
       "   'totalFloorNumber': 8,\n",
       "   'transactionType': 'New Property',\n",
       "   'furnished': 'Semi-Furnished',\n",
       "   'bedrooms': 2,\n",
       "   'bathrooms': 2,\n",
       "   'ageofcons': 'Under Construction',\n",
       "   'imagePaths': ['https://img.staticmb.com/mbphoto/property/cropped_images/2024/Apr/16/Photo_h300_w450/72315251_8_rojectPhoto6LegacyImperialPhaseIPune53346493636724701080_300_450.jpg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Apr/16/Photo_h300_w450/72315251_6_rojectPhoto7LegacyImperialPhaseIPune53346493665564701080_300_450.jpg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Apr/12/Photo_h300_w450/72315251_6_4963509334701080_300_450.jpg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Apr/12/Photo_h300_w450/72315251_8_545037710lobalEnriseByGlobalGroupRahataniImage24701080_300_450.jpg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Apr/12/Photo_h300_w450/72315251_4_496350917creenshot202301051319194701080_300_450.jpg'],\n",
       "   'url': 'https://www.magicbricks.com/propertyDetails/2-BHK-1096-Sq-ft-Multistorey-Apartment-FOR-Sale-Rahatni-in-Pune&id=4d423732333135323531',\n",
       "   'lastUpdatedDate': '21 Dec, 2024',\n",
       "   'pricePerSqft': 9750,\n",
       "   'nameOfSociety': 'Global Enrise'},\n",
       "  {'propertyId': '71077421',\n",
       "   'localityName': 'Mamurdi, Dehu Road',\n",
       "   'price': 5500000,\n",
       "   'carpetArea': 742,\n",
       "   'floorNumber': 5,\n",
       "   'totalFloorNumber': 7,\n",
       "   'transactionType': 'New Property',\n",
       "   'furnished': 'Semi-Furnished',\n",
       "   'bedrooms': 2,\n",
       "   'bathrooms': 2,\n",
       "   'ageofcons': 'Under Construction',\n",
       "   'imagePaths': ['https://img.staticmb.com/mbphoto/property/cropped_images/2024/Jan/25/Photo_h300_w450/71077421_2_arvelelevation142470632_300_450.jpeg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Jan/25/Photo_h300_w450/71077421_10_rojectPhoto11MarvelPune5416551600800_300_450.jpg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Jan/25/Photo_h300_w450/71077421_1_arvelelevation142470633_300_450.jpeg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Jan/25/Photo_h300_w450/71077421_4_rojectPhoto8MarvelPune541655112001600_300_450.jpg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Jan/25/Photo_h300_w450/71077421_8_loorPlan3MarvelPune541655112001600_300_450.jpg'],\n",
       "   'url': 'https://www.magicbricks.com/propertyDetails/2-BHK-1112-Sq-ft-Multistorey-Apartment-FOR-Sale-Kiwale-in-Pune&id=4d423731303737343231',\n",
       "   'lastUpdatedDate': '21 Dec, 2024',\n",
       "   'pricePerSqft': 7412,\n",
       "   'nameOfSociety': 'Shelter Marvel'},\n",
       "  {'propertyId': '70979237',\n",
       "   'localityName': 'Pimple Saudagar, Pimpri Chinchwad',\n",
       "   'price': 11000000,\n",
       "   'carpetArea': 858,\n",
       "   'floorNumber': 5,\n",
       "   'totalFloorNumber': 7,\n",
       "   'transactionType': 'New Property',\n",
       "   'furnished': 'Semi-Furnished',\n",
       "   'bedrooms': 2,\n",
       "   'bathrooms': 2,\n",
       "   'ageofcons': 'Under Construction',\n",
       "   'imagePaths': ['https://img.staticmb.com/mbphoto/property/cropped_images/2024/Jan/18/Photo_h300_w450/70979237_1_rojectPhoto11SaiAuraPune541652512001600_300_450.jpg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Jan/18/Photo_h300_w450/70979237_2_rojectPhoto6SaiAuraPune541652512001600_300_450.jpg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Jan/18/Photo_h300_w450/70979237_3_rojectPhoto5SaiAuraPune541652512001600_300_450.jpg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Jan/18/Photo_h300_w450/70979237_4_rojectPhoto10SaiAuraPune541652512001600_300_450.jpg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Jan/18/Photo_h300_w450/70979237_7_rojectPhoto3SaiAuraPune541652512001600_300_450.jpg'],\n",
       "   'url': 'https://www.magicbricks.com/propertyDetails/2-BHK-1258-Sq-ft-Multistorey-Apartment-FOR-Sale-Pimple-Saudagar-Gaon-in-Pune&id=4d423730393739323337',\n",
       "   'lastUpdatedDate': '21 Dec, 2024',\n",
       "   'pricePerSqft': 12821,\n",
       "   'nameOfSociety': 'Sai Aura'},\n",
       "  {'propertyId': '75614091',\n",
       "   'localityName': 'Wakad',\n",
       "   'price': 9200000,\n",
       "   'carpetArea': 798,\n",
       "   'floorNumber': 5,\n",
       "   'totalFloorNumber': 10,\n",
       "   'transactionType': 'New Property',\n",
       "   'furnished': 'Semi-Furnished',\n",
       "   'bedrooms': 2,\n",
       "   'bathrooms': 2,\n",
       "   'ageofcons': 'Under Construction',\n",
       "   'imagePaths': ['https://img.staticmb.com/mbphoto/property/cropped_images/2024/Oct/23/Photo_h300_w450/75614091_3_hatsAppImage20241011at7.12.55PM_300_450.jpeg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Oct/23/Photo_h300_w450/75614091_4_hatsAppImage20241011at7.12.55PM1_300_450.jpeg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Oct/23/Photo_h300_w450/75614091_5_hatsAppImage20241011at7.12.55PM2_300_450.jpeg'],\n",
       "   'url': 'https://www.magicbricks.com/propertyDetails/2-BHK-1077-Sq-ft-Multistorey-Apartment-FOR-Sale-Wakad-in-Pune&id=4d423735363134303931',\n",
       "   'lastUpdatedDate': '21 Dec, 2024',\n",
       "   'pricePerSqft': 11529,\n",
       "   'nameOfSociety': 'Rohan Viti'},\n",
       "  {'propertyId': '72372649',\n",
       "   'localityName': 'Dhanori',\n",
       "   'price': 5868248,\n",
       "   'carpetArea': 756,\n",
       "   'floorNumber': 5,\n",
       "   'totalFloorNumber': 10,\n",
       "   'transactionType': 'New Property',\n",
       "   'furnished': 'Semi-Furnished',\n",
       "   'bedrooms': 2,\n",
       "   'bathrooms': 2,\n",
       "   'ageofcons': 'Under Construction',\n",
       "   'imagePaths': ['https://img.staticmb.com/mbphoto/property/cropped_images/2024/Apr/16/Photo_h300_w450/72372649_6_hatsAppImage20221001at14.02.271_300_450.jpeg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Apr/16/Photo_h300_w450/72372649_10_hatsAppImage20221001at14.02.272_300_450.jpeg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Apr/16/Photo_h300_w450/72372649_11_hatsAppImage20221001at14.02.261_300_450.jpeg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Apr/16/Photo_h300_w450/72372649_20_hatsAppImage20221001at14.02.25_300_450.jpeg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Apr/16/Photo_h300_w450/72372649_18_hatsAppImage20221001at14.02.27_300_450.jpeg'],\n",
       "   'url': 'https://www.magicbricks.com/propertyDetails/2-BHK-1021-Sq-ft-Multistorey-Apartment-FOR-Sale-Dhanori-in-Pune&id=4d423732333732363439',\n",
       "   'lastUpdatedDate': '21 Dec, 2024',\n",
       "   'pricePerSqft': 7762,\n",
       "   'nameOfSociety': 'Choic Goodwill Metropolis East'},\n",
       "  {'propertyId': '75908039',\n",
       "   'localityName': 'Dhanori',\n",
       "   'price': 5995555,\n",
       "   'carpetArea': 750,\n",
       "   'floorNumber': 5,\n",
       "   'totalFloorNumber': 10,\n",
       "   'transactionType': 'New Property',\n",
       "   'furnished': 'Semi-Furnished',\n",
       "   'bedrooms': 2,\n",
       "   'bathrooms': 2,\n",
       "   'ageofcons': 'Under Construction',\n",
       "   'imagePaths': ['https://img.staticmb.com/mbphoto/property/cropped_images/2024/Nov/10/Photo_h300_w450/75908039_4_71147652bhkindhanori03600900_300_450.jpg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Nov/10/Photo_h300_w450/75908039_8_62578675bhkindhanori01600900_300_450.jpg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Nov/10/Photo_h300_w450/75908039_3_711476510iverdale3BHKWeb02600900_300_450.jpg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Nov/10/Photo_h300_w450/75908039_1_rojectPhoto7GoodwillBreezaPune5123887500850_300_450.jpg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Nov/10/Photo_h300_w450/75908039_2_80471014ront1600900_300_450.jpg'],\n",
       "   'url': 'https://www.magicbricks.com/propertyDetails/2-BHK-1012-Sq-ft-Multistorey-Apartment-FOR-Sale-Dhanori-in-Pune&id=4d423735393038303339',\n",
       "   'lastUpdatedDate': '21 Dec, 2024',\n",
       "   'pricePerSqft': 7994,\n",
       "   'nameOfSociety': 'Choice Goodwill Metropolis East Phase 1'},\n",
       "  {'propertyId': '72373671',\n",
       "   'localityName': 'Dhanori',\n",
       "   'price': 5995555,\n",
       "   'carpetArea': 750,\n",
       "   'floorNumber': 5,\n",
       "   'totalFloorNumber': 10,\n",
       "   'transactionType': 'New Property',\n",
       "   'furnished': 'Semi-Furnished',\n",
       "   'bedrooms': 2,\n",
       "   'bathrooms': 2,\n",
       "   'ageofcons': 'Under Construction',\n",
       "   'imagePaths': ['https://img.staticmb.com/mbphoto/property/cropped_images/2024/Apr/16/Photo_h300_w450/72373671_1_hatsAppImage20221001at14.02.271_300_450.jpeg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Apr/16/Photo_h300_w450/72373671_6_hatsAppImage20221001at14.02.261_300_450.jpeg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Apr/16/Photo_h300_w450/72373671_15_hatsAppImage20221001at14.02.272_300_450.jpeg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Apr/16/Photo_h300_w450/72373671_18_hatsAppImage20221001at14.02.25_300_450.jpeg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Apr/16/Photo_h300_w450/72373671_5_hatsAppImage20221001at14.02.27_300_450.jpeg'],\n",
       "   'url': 'https://www.magicbricks.com/propertyDetails/2-BHK-1012-Sq-ft-Multistorey-Apartment-FOR-Sale-Dhanori-in-Pune&id=4d423732333733363731',\n",
       "   'lastUpdatedDate': '21 Dec, 2024',\n",
       "   'pricePerSqft': 7994,\n",
       "   'nameOfSociety': 'Choice Goodwill Metropolis East Phase 1'},\n",
       "  {'propertyId': '75908329',\n",
       "   'localityName': 'Dhanori',\n",
       "   'price': 6505555,\n",
       "   'carpetArea': 741,\n",
       "   'floorNumber': 5,\n",
       "   'totalFloorNumber': 10,\n",
       "   'transactionType': 'New Property',\n",
       "   'furnished': 'Semi-Furnished',\n",
       "   'bedrooms': 2,\n",
       "   'bathrooms': 2,\n",
       "   'ageofcons': 'Under Construction',\n",
       "   'imagePaths': ['https://img.staticmb.com/mbphoto/property/cropped_images/2024/Nov/10/Photo_h300_w450/75908329_4_itePhotos13GoodwillBreezaPune512388715002000_300_450.jpg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Nov/10/Photo_h300_w450/75908329_14_71147652bhkindhanori03600900_300_450.jpg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Nov/10/Photo_h300_w450/75908329_18_62578675bhkindhanori01600900_300_450.jpg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Nov/10/Photo_h300_w450/75908329_13_711476510iverdale3BHKWeb02600900_300_450.jpg',\n",
       "    'https://img.staticmb.com/mbphoto/property/cropped_images/2024/Nov/10/Photo_h300_w450/75908329_5_rojectPhoto47PrideWorldCityPune507198812001600_300_450.jpg'],\n",
       "   'url': 'https://www.magicbricks.com/propertyDetails/2-BHK-1001-Sq-ft-Multistorey-Apartment-FOR-Sale-Dhanori-in-Pune&id=4d423735393038333239',\n",
       "   'lastUpdatedDate': '21 Dec, 2024',\n",
       "   'pricePerSqft': 8779,\n",
       "   'nameOfSociety': 'Choice Goodwill Metropolis East Phase 1'}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
